Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
c8418dad-b7dd-4a9c-b636-e2553af5e965
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
76ab0408-5b84-47a3-9c13-1bffe105bd7e
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
8801d0ad-305a-4d4e-a6f4-09c8a66d43e1
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.7029      0.0823     0.0732     9.7336
00100     2.1181      0.2574     0.2901     55.4955
00200     1.6862      0.4451     0.4998     54.6599
00300     1.2762      0.6118     0.5969     55.4980
00400     1.3119      0.5886     0.6494     55.1284
00500     1.1093      0.6582     0.6810     54.0048
00600     1.0925      0.6751     0.7103     54.9941
00700     0.8718      0.7468     0.7291     55.2307
00800     0.9129      0.7300     0.7424     54.7911
00900     0.7743      0.7806     0.7536     54.3517
01000     0.9996      0.6835     0.7536     54.1251
01100     0.8509      0.7595     0.7650     55.9491
01200     0.8472      0.7447     0.7726     54.6058
01300     0.7220      0.7764     0.7863     56.1379
01400     0.7942      0.7553     0.7863     54.9429
01500     0.7074      0.7890     0.7863     54.1636
01600     0.7813      0.7722     0.7877     55.7859
01700     0.8019      0.7637     0.7877     55.9410
01800     0.7740      0.7722     0.7877     54.8207
01900     0.7051      0.7848     0.7877     54.9597
02000     0.7389      0.7932     0.7906     55.9963
02100     0.7383      0.7911     0.7935     55.6973
02200     0.7134      0.7764     0.7935     55.2776
02300     0.7356      0.7806     0.7937     54.9907
02400     0.7662      0.7806     0.7956     56.0092
02500     0.6681      0.7827     0.8043     55.6966
02600     0.6648      0.8101     0.8043     54.9799
02700     0.7370      0.7806     0.8043     55.9226
02800     0.6290      0.8165     0.8099     55.1959
02900     0.6596      0.8207     0.8114     54.7150
03000     0.7526      0.7764     0.8114     56.3447
03100     0.7045      0.7954     0.8114     54.7207
03200     0.6516      0.8165     0.8114     55.6596
03300     0.6582      0.8143     0.8114     55.1317
03400     0.7155      0.7848     0.8252     54.6210
03500     0.6500      0.8059     0.8252     55.4982
03600     0.6349      0.8059     0.8252     55.2802
03700     0.6734      0.7869     0.8252     55.7694
03800     0.6955      0.8122     0.8252     55.5214
03900     0.6448      0.7996     0.8252     53.7462
04000     0.6907      0.8017     0.8252     55.9287
04100     0.6386      0.8059     0.8252     54.4460
04200     0.6838      0.7932     0.8252     54.1392
04300     0.6371      0.8143     0.8252     55.4657
04400     0.5443      0.8418     0.8252     53.9255
04500     0.6331      0.8186     0.8252     55.3219
04600     0.6200      0.8080     0.8252     56.3441
04700     0.6248      0.7975     0.8252     55.4174
04800     0.7228      0.7932     0.8252     55.4394
04900     0.6752      0.7954     0.8252     54.2081
05000     0.6571      0.8059     0.8252     55.8368
05100     0.6364      0.7954     0.8252     54.5693
05200     0.6475      0.7975     0.8265     55.1230
05300     0.6782      0.8122     0.8265     55.5259
05400     0.6514      0.8038     0.8265     55.7335
05500     0.6460      0.7996     0.8265     55.1446
05600     0.6383      0.7975     0.8265     56.5911
05700     0.6457      0.7975     0.8265     56.1626
05800     0.6465      0.7869     0.8265     54.3390
05900     0.6552      0.8017     0.8267     55.9531
06000     0.6524      0.8080     0.8267     54.4092
06100     0.5716      0.8439     0.8272     55.2827
06200     0.6386      0.8122     0.8272     55.3323
06300     0.6293      0.7932     0.8272     54.6441
06400     0.6112      0.7932     0.8304     55.0065
06500     0.5697      0.8333     0.8304     55.9150
06600     0.6399      0.7975     0.8304     55.4953
06700     0.5703      0.8312     0.8313     55.2177
06800     0.7642      0.7595     0.8313     55.8339
06900     0.5745      0.8249     0.8389     55.1978
07000     0.6663      0.8059     0.8389     54.9687
07100     0.6117      0.8291     0.8389     55.3482
07200     0.5710      0.8270     0.8389     55.4713
07300     0.6093      0.8228     0.8389     55.1142
07400     0.6936      0.7869     0.8389     56.8473
07500     0.5496      0.8629     0.8389     55.4327
07600     0.6426      0.7975     0.8389     55.1085
07700     0.5405      0.8460     0.8389     56.4426
07800     0.6154      0.8186     0.8389     54.9131
07900     0.5707      0.8354     0.8389     56.9983
08000     0.6334      0.8080     0.8389     56.0407
08100     0.5663      0.8207     0.8389     54.0932
08200     0.5382      0.8376     0.8389     55.2344
08300     0.5053      0.8565     0.8389     57.1752
08400     0.6702      0.8059     0.8389     56.1492
08500     0.6061      0.8101     0.8389     55.7590
08600     0.5385      0.8397     0.8389     55.5987
08700     0.6262      0.8017     0.8389     57.6700
08800     0.5422      0.8228     0.8389     57.0443
08900     0.6224      0.8186     0.8389     55.3405
09000     0.6020      0.8059     0.8423     56.1404
09100     0.6735      0.8101     0.8423     55.8593
09200     0.5987      0.8059     0.8423     54.4795
09300     0.5446      0.8397     0.8423     55.4381
09400     0.5655      0.8270     0.8423     55.2264
09500     0.5741      0.8418     0.8423     55.2494
09600     0.5761      0.8312     0.8423     55.2367
09700     0.5767      0.8270     0.8423     56.7766
09800     0.6528      0.7975     0.8423     54.8468
09900     0.5933      0.8249     0.8423     56.2372
10000     0.5834      0.8143     0.8423     56.4036
10100     0.5703      0.8354     0.8423     55.1013
10200     0.5772      0.8439     0.8423     54.9506
10300     0.6390      0.8101     0.8423     53.9157
10400     0.5900      0.8143     0.8423     54.3847
10500     0.4874      0.8565     0.8441     53.7353
10600     0.5023      0.8629     0.8441     54.9008
10700     0.5935      0.8228     0.8449     54.9060
10800     0.5719      0.8376     0.8449     55.6581
10900     0.5214      0.8186     0.8449     56.6255
11000     0.6092      0.8270     0.8449     56.0080
11100     0.5521      0.8333     0.8449     55.5458
11200     0.5778      0.8207     0.8449     55.5303
11300     0.6166      0.8038     0.8494     54.2616
11400     0.5635      0.8354     0.8494     54.5383
11500     0.5767      0.8143     0.8494     55.3760
11600     0.5125      0.8439     0.8494     55.2434
11700     0.5414      0.8481     0.8494     56.3829
11800     0.5504      0.8270     0.8494     56.4210
11900     0.6407      0.8186     0.8494     54.7172
12000     0.5389      0.8376     0.8494     55.0480
12100     0.5240      0.8418     0.8494     55.9663
12200     0.5440      0.8418     0.8494     55.3303
12300     0.6290      0.8249     0.8494     55.4083
12400     0.4607      0.8776     0.8494     55.5886
12500     0.5121      0.8565     0.8494     55.8809
12600     0.5067      0.8481     0.8494     54.6951
12700     0.5716      0.8270     0.8494     54.4709
12800     0.5205      0.8460     0.8494     55.7455
12900     0.5588      0.8523     0.8494     54.9307
13000     0.6184      0.8249     0.8494     54.6489
13100     0.6323      0.8122     0.8494     54.7239
13200     0.5998      0.8122     0.8494     54.9997
13300     0.5512      0.8333     0.8494     54.5819
13400     0.5745      0.8354     0.8494     54.7332
13500     0.5631      0.8376     0.8497     55.4368
13600     0.5692      0.8291     0.8497     55.4294
13700     0.5468      0.8502     0.8497     54.9984
13800     0.5367      0.8439     0.8497     55.7229
13900     0.5833      0.8228     0.8497     57.3127
14000     0.5338      0.8523     0.8497     55.6221
14100     0.5726      0.8270     0.8497     56.3862
14200     0.5429      0.8418     0.8497     55.8312
14300     0.5239      0.8502     0.8497     55.5392
14400     0.4895      0.8671     0.8497     55.3111
14500     0.5254      0.8397     0.8497     54.5239
14600     0.4571      0.8692     0.8497     54.7693
14700     0.5466      0.8397     0.8497     55.6312
14800     0.5344      0.8439     0.8497     55.2474
14900     0.5889      0.8312     0.8497     56.3718
15000     0.5434      0.8080     0.8509     54.6740
15100     0.5553      0.8460     0.8509     57.1446
15200     0.5084      0.8502     0.8509     55.9788
15300     0.4921      0.8439     0.8509     54.9033
15400     0.5333      0.8439     0.8509     54.6055
15500     0.4659      0.8650     0.8509     55.6525
15600     0.4984      0.8565     0.8509     55.8097
15700     0.5171      0.8523     0.8509     54.8690
15800     0.5109      0.8460     0.8509     55.4596
15900     0.5077      0.8544     0.8509     54.3966
16000     0.4814      0.8819     0.8520     55.7339
16100     0.5386      0.8439     0.8520     54.5864
16200     0.5480      0.8312     0.8523     55.6056
16300     0.6280      0.8038     0.8523     56.5197
16400     0.5399      0.8523     0.8523     57.1422
16500     0.5879      0.8333     0.8523     55.0229
16600     0.5703      0.8249     0.8523     55.5853
16700     0.4893      0.8565     0.8523     52.5437
16800     0.5506      0.8333     0.8523     54.3316
16900     0.5776      0.8228     0.8523     56.2359
17000     0.4828      0.8586     0.8523     55.4369
17100     0.5938      0.8122     0.8523     55.2782
17200     0.5216      0.8586     0.8523     56.0271
17300     0.6144      0.8059     0.8523     55.7595
17400     0.5639      0.8143     0.8523     55.5545
17500     0.5287      0.8481     0.8525     55.6608
17600     0.5602      0.8291     0.8532     54.8579
17700     0.5510      0.8333     0.8532     54.7753
17800     0.4960      0.8460     0.8532     55.0204
17900     0.5444      0.8354     0.8532     56.3984
18000     0.5225      0.8376     0.8532     55.7478
18100     0.5445      0.8249     0.8532     55.2964
18200     0.4819      0.8713     0.8532     55.1350
18300     0.5176      0.8523     0.8532     56.6673
18400     0.5106      0.8481     0.8532     57.0101
18500     0.5916      0.8249     0.8540     54.5956
18600     0.4952      0.8460     0.8540     56.6213
18700     0.5426      0.8439     0.8540     55.3673
18800     0.5945      0.8228     0.8540     59.7534
18900     0.5226      0.8629     0.8540     56.3538
19000     0.4959      0.8755     0.8540     55.1140
19100     0.5063      0.8523     0.8540     57.1953
19200     0.5471      0.8333     0.8540     55.2958
19300     0.4232      0.8650     0.8540     54.4344
19400     0.5546      0.8397     0.8540     55.5531
19500     0.5703      0.8333     0.8540     55.2161
19600     0.5064      0.8586     0.8540     55.8729
19700     0.5550      0.8207     0.8540     56.0509
19800     0.4713      0.8713     0.8550     56.7549
19900     0.5543      0.8354     0.8550     55.5456
20000     0.5427      0.8312     0.8550     56.2161
20100     0.5120      0.8608     0.8550     54.2503
20199     0.5853      0.8333     0.8550     54.9830
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4484      0.8713     0.8480     9.3584
00100     0.4447      0.8671     0.8482     53.5293
00200     0.5046      0.8565     0.8504     53.7381
00300     0.4377      0.8755     0.8511     54.1797
00400     0.4428      0.8713     0.8511     55.4303
00500     0.4523      0.8650     0.8530     54.8321
00600     0.4813      0.8565     0.8530     56.1487
00700     0.5274      0.8439     0.8548     55.3251
00800     0.4611      0.8523     0.8548     55.4760
00900     0.3447      0.9008     0.8548     57.3632
01000     0.4209      0.8882     0.8548     54.4896
01100     0.4877      0.8671     0.8550     55.5274
01200     0.4695      0.8692     0.8550     56.3170
01300     0.4223      0.8713     0.8550     56.3906
01400     0.4544      0.8565     0.8550     54.4601
01500     0.4676      0.8776     0.8561     54.4838
01600     0.4716      0.8565     0.8561     55.7772
01700     0.4343      0.8755     0.8561     54.8503
01800     0.4819      0.8586     0.8561     57.3579
01900     0.4869      0.8671     0.8574     56.3681
02000     0.4865      0.8544     0.8574     54.6458
02100     0.4454      0.8692     0.8574     55.1008
02200     0.4985      0.8544     0.8574     55.5634
02300     0.5376      0.8249     0.8574     54.6664
02400     0.4493      0.8544     0.8574     55.3743
02500     0.4910      0.8608     0.8574     56.7146
02600     0.4200      0.8776     0.8574     56.1365
02700     0.4353      0.8755     0.8574     55.4268
02800     0.4578      0.8629     0.8574     55.2018
02900     0.4503      0.8608     0.8574     53.7245
03000     0.4955      0.8418     0.8574     54.1291
03100     0.4630      0.8650     0.8574     55.2305
03200     0.4115      0.8819     0.8574     55.4054
03300     0.4095      0.8903     0.8574     54.3374
03400     0.4311      0.8903     0.8574     54.9392
03500     0.4283      0.8882     0.8574     55.3709
03600     0.4688      0.8544     0.8574     55.9961
03700     0.4137      0.8692     0.8574     54.7495
03800     0.4208      0.8713     0.8574     55.0598
03900     0.5615      0.8418     0.8574     55.0161
04000     0.4092      0.8861     0.8574     56.2436
04100     0.3890      0.9072     0.8574     54.4132
04200     0.4261      0.8924     0.8574     54.2847
04300     0.4534      0.8586     0.8574     55.5844
04400     0.4869      0.8734     0.8574     53.8747
04500     0.4770      0.8544     0.8574     54.8741
04600     0.4159      0.8734     0.8574     55.2922
04700     0.4047      0.8945     0.8574     56.2641
04800     0.4158      0.8882     0.8574     55.4396
04900     0.4745      0.8586     0.8583     55.0984
05000     0.4583      0.8608     0.8583     55.5159
05100     0.4278      0.8734     0.8583     55.8075
05200     0.4843      0.8586     0.8583     55.0666
05300     0.4354      0.8797     0.8583     54.5899
05400     0.4554      0.8565     0.8583     54.4710
05500     0.3621      0.9030     0.8583     53.9421
05600     0.4311      0.8629     0.8583     55.5180
05700     0.5054      0.8544     0.8583     55.0129
05800     0.5370      0.8354     0.8583     55.4074
05900     0.4978      0.8671     0.8583     54.9125
06000     0.4053      0.8882     0.8583     54.6827
06100     0.4957      0.8586     0.8583     56.8361
06200     0.5052      0.8354     0.8583     56.7206
06300     0.3437      0.8987     0.8583     54.3228
06400     0.4128      0.8755     0.8583     54.8805
06500     0.4965      0.8481     0.8583     55.2870
06600     0.4571      0.8713     0.8587     55.1790
06700     0.4166      0.8840     0.8587     54.7763
06800     0.4778      0.8586     0.8604     55.5180
06900     0.4256      0.8776     0.8604     55.1155
07000     0.4297      0.8755     0.8604     55.5089
07100     0.4313      0.8945     0.8604     56.4759
07200     0.4496      0.8650     0.8604     56.0839
07300     0.4230      0.8819     0.8604     55.3794
07400     0.4375      0.8797     0.8604     54.5603
07500     0.4504      0.8650     0.8604     56.3497
07600     0.4667      0.8608     0.8604     55.8127
07700     0.4249      0.8692     0.8604     54.9338
07800     0.4404      0.8608     0.8604     56.9740
07900     0.4343      0.8755     0.8604     55.6969
08000     0.4642      0.8713     0.8604     55.4251
08100     0.4206      0.8797     0.8604     54.2165
08200     0.3841      0.8903     0.8604     55.6956
08300     0.3679      0.8987     0.8604     56.5909
08400     0.4154      0.8734     0.8604     55.9562
08500     0.4602      0.8713     0.8604     55.6337
08600     0.4850      0.8523     0.8604     56.8284
08700     0.4217      0.8776     0.8604     54.2876
08800     0.4389      0.8734     0.8604     55.5831
08900     0.3730      0.8966     0.8604     54.4202
09000     0.4116      0.8924     0.8604     54.3788
09100     0.4042      0.8776     0.8604     55.6490
09200     0.4146      0.8882     0.8604     55.8216
09300     0.4920      0.8481     0.8604     56.7088
09400     0.4480      0.8692     0.8604     57.5017
09500     0.4389      0.8903     0.8604     55.2563
09600     0.4270      0.8861     0.8604     55.7475
09700     0.3968      0.8924     0.8604     56.4517
09800     0.4377      0.8734     0.8604     59.4010
09900     0.4548      0.8629     0.8604     59.2222
Start testing:
Test Accuracy: 0.8317
