Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
b6de7615-4859-4637-a259-799a340e3446
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
32dd6334-ed2c-406a-884d-29c051c7b56d
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
95d65a49-3749-47a1-b4dd-8e502be1e2fa
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
4f576316-2084-4349-930f-2409e81c842a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8255      0.0696     0.0875     9.7765
00100     2.3697      0.2152     0.2559     66.6650
00200     1.8009      0.4262     0.4615     66.6026
00300     1.4694      0.5253     0.5532     69.1031
00400     1.3468      0.5802     0.6037     68.2219
00500     1.2060      0.6139     0.6491     66.6149
00600     1.0788      0.6561     0.6947     68.1197
00700     0.9565      0.7194     0.7194     66.0473
00800     0.9531      0.7131     0.7357     67.7022
00900     0.9639      0.6899     0.7371     66.8057
01000     0.9243      0.7278     0.7523     66.3583
01100     0.8864      0.7405     0.7523     68.6884
01200     0.8954      0.7215     0.7614     67.8519
01300     0.7754      0.7975     0.7662     68.3571
01400     0.8754      0.7447     0.7748     66.6522
01500     0.8060      0.7426     0.7792     66.1194
01600     0.7922      0.7468     0.7859     68.5733
01700     0.7090      0.8038     0.7859     67.0214
01800     0.7849      0.7405     0.7859     67.2436
01900     0.7381      0.7785     0.7952     68.3701
02000     0.7575      0.7806     0.8018     66.5014
02100     0.6967      0.7996     0.8018     67.8534
02200     0.7147      0.7785     0.8018     66.6205
02300     0.7552      0.7595     0.8018     66.5609
02400     0.6703      0.7954     0.8018     66.7153
02500     0.7861      0.7869     0.8042     67.7219
02600     0.7828      0.7574     0.8042     67.7203
02700     0.6875      0.7827     0.8042     66.4010
02800     0.6922      0.7785     0.8113     65.9902
02900     0.8076      0.7700     0.8113     65.7487
03000     0.6867      0.7911     0.8117     66.9269
03100     0.7112      0.7806     0.8117     65.5050
03200     0.6484      0.8038     0.8117     68.3036
03300     0.6280      0.8228     0.8131     66.3010
03400     0.7446      0.7722     0.8131     67.9735
03500     0.7169      0.7954     0.8151     69.3465
03600     0.7181      0.7848     0.8151     66.6528
03700     0.7082      0.7700     0.8161     67.3913
03800     0.6523      0.7954     0.8161     68.7109
03900     0.7310      0.7658     0.8161     67.7020
04000     0.6780      0.8059     0.8161     68.5232
04100     0.6149      0.8080     0.8161     66.2847
04200     0.6539      0.8017     0.8161     67.2508
04300     0.6813      0.8038     0.8161     65.2347
04400     0.6685      0.8101     0.8161     65.9869
04500     0.5887      0.8122     0.8161     65.5617
04600     0.6627      0.7911     0.8196     69.9969
04700     0.5730      0.8291     0.8208     69.4639
04800     0.6080      0.8312     0.8208     70.6691
04900     0.5687      0.8270     0.8208     69.7932
05000     0.6545      0.8101     0.8208     71.0405
05100     0.6813      0.7848     0.8301     67.8900
05200     0.6438      0.8101     0.8301     69.3988
05300     0.6445      0.8143     0.8301     71.7560
05400     0.6090      0.8376     0.8301     68.8330
05500     0.6525      0.8080     0.8301     68.1680
05600     0.5802      0.8228     0.8301     68.8604
05700     0.6629      0.8080     0.8301     68.7090
05800     0.7013      0.7932     0.8301     69.8665
05900     0.6151      0.8059     0.8301     71.4751
06000     0.6438      0.8101     0.8301     67.9039
06100     0.6476      0.7975     0.8301     70.2655
06200     0.6768      0.7911     0.8301     69.4776
06300     0.5563      0.8270     0.8301     67.9370
06400     0.5980      0.8059     0.8301     68.5774
06500     0.6088      0.8207     0.8301     71.6303
06600     0.6467      0.8143     0.8301     69.2076
06700     0.6733      0.7975     0.8301     70.6623
06800     0.6243      0.8122     0.8301     68.4772
06900     0.6086      0.8038     0.8301     68.6261
07000     0.6558      0.8101     0.8301     68.3191
07100     0.6345      0.7975     0.8301     68.5082
07200     0.6458      0.7890     0.8301     67.8805
07300     0.7077      0.7911     0.8301     68.1530
07400     0.6272      0.8059     0.8301     67.4903
07500     0.5651      0.8376     0.8301     70.0289
07600     0.6609      0.8080     0.8301     68.3151
07700     0.5413      0.8502     0.8301     69.0629
07800     0.5687      0.8101     0.8301     68.5477
07900     0.6548      0.8017     0.8301     69.5558
08000     0.5879      0.8228     0.8301     69.8315
08100     0.7135      0.7827     0.8301     69.4812
08200     0.4915      0.8544     0.8301     67.7231
08300     0.5330      0.8228     0.8301     69.2878
08400     0.6302      0.8059     0.8301     68.7601
08500     0.6289      0.8143     0.8301     69.0208
08600     0.6283      0.8122     0.8301     69.2290
08700     0.5384      0.8481     0.8308     68.7557
08800     0.6491      0.8101     0.8308     69.2279
08900     0.6284      0.8080     0.8308     68.3747
09000     0.5852      0.8228     0.8308     69.0861
09100     0.6059      0.8165     0.8308     69.6046
09200     0.6392      0.8122     0.8308     69.6405
09300     0.5314      0.8481     0.8308     68.9832
09400     0.6249      0.8186     0.8308     69.4868
09500     0.6789      0.7806     0.8308     70.0916
09600     0.5165      0.8418     0.8308     69.1742
09700     0.5742      0.8291     0.8308     68.6535
09800     0.5831      0.8397     0.8308     68.0634
09900     0.5551      0.8291     0.8308     70.7005
10000     0.5422      0.8502     0.8308     70.4839
10100     0.6322      0.8165     0.8308     68.6042
10200     0.5548      0.8270     0.8308     69.9561
10300     0.5340      0.8376     0.8308     69.2865
10400     0.5486      0.8228     0.8308     69.3537
10500     0.5781      0.8228     0.8308     69.8940
10600     0.5392      0.8418     0.8308     67.9698
10700     0.5614      0.8312     0.8308     70.1648
10800     0.5626      0.8270     0.8308     70.9188
10900     0.5712      0.8249     0.8308     68.6044
11000     0.4652      0.8629     0.8308     68.4550
11100     0.5191      0.8397     0.8339     69.4545
11200     0.4844      0.8608     0.8339     68.8401
11300     0.5666      0.8376     0.8339     68.9643
11400     0.6105      0.8186     0.8339     68.6388
11500     0.5381      0.8376     0.8339     67.8707
11600     0.5863      0.8333     0.8339     68.9124
11700     0.5956      0.8101     0.8339     68.5163
11800     0.6074      0.8165     0.8339     67.8476
11900     0.5419      0.8418     0.8339     67.9419
12000     0.4642      0.8565     0.8339     68.6679
12100     0.5462      0.8565     0.8339     70.1469
12200     0.5001      0.8481     0.8339     70.3266
12300     0.5835      0.8270     0.8339     67.4049
12400     0.5741      0.8312     0.8339     68.7947
12500     0.5602      0.8291     0.8339     68.5018
12600     0.5903      0.8291     0.8339     70.4212
12700     0.6220      0.8249     0.8339     70.4367
12800     0.5020      0.8523     0.8339     70.4426
12900     0.6341      0.8143     0.8339     69.3856
13000     0.5253      0.8312     0.8339     68.9088
13100     0.5945      0.8080     0.8339     70.8029
13200     0.4959      0.8502     0.8339     67.8717
13300     0.5532      0.8418     0.8339     70.7735
13400     0.5549      0.8333     0.8358     68.1065
13500     0.5780      0.8207     0.8358     69.6890
13600     0.5315      0.8523     0.8358     69.0766
13700     0.6118      0.8312     0.8358     69.5072
13800     0.5464      0.8143     0.8358     69.8688
13900     0.5267      0.8481     0.8358     70.2976
14000     0.5116      0.8840     0.8358     69.4913
14100     0.5631      0.8397     0.8358     70.0590
14200     0.4959      0.8565     0.8358     67.8213
14300     0.5667      0.8312     0.8358     68.0948
14400     0.5727      0.8397     0.8358     68.3978
14500     0.5909      0.8291     0.8358     71.8528
14600     0.5416      0.8291     0.8358     70.1075
14700     0.6152      0.8059     0.8395     70.5600
14800     0.5957      0.8291     0.8395     70.0998
14900     0.5359      0.8481     0.8395     69.4008
15000     0.5415      0.8333     0.8395     69.0882
15100     0.5521      0.8270     0.8395     69.1956
15200     0.5819      0.8207     0.8395     70.5921
15300     0.5936      0.8186     0.8395     69.3087
15400     0.5357      0.8312     0.8395     69.9040
15500     0.6597      0.8017     0.8395     68.8341
15600     0.5323      0.8312     0.8395     69.4707
15700     0.5323      0.8333     0.8395     68.3047
15800     0.6626      0.8017     0.8395     72.8397
15900     0.4782      0.8629     0.8395     70.3531
16000     0.5591      0.8270     0.8395     70.2708
16100     0.6321      0.7975     0.8395     68.7025
16200     0.5862      0.8165     0.8395     68.9686
16300     0.5564      0.8291     0.8395     68.6960
16400     0.5359      0.8418     0.8395     68.1799
16500     0.4681      0.8671     0.8395     69.8560
16600     0.5304      0.8460     0.8395     69.2389
16700     0.5017      0.8544     0.8395     70.1794
16800     0.5094      0.8397     0.8395     69.4999
16900     0.5511      0.8333     0.8395     70.2792
17000     0.6207      0.8080     0.8395     70.6653
17100     0.5197      0.8586     0.8395     68.7555
17200     0.6350      0.8017     0.8395     68.6114
17300     0.6232      0.8143     0.8395     69.1852
17400     0.5817      0.8059     0.8395     69.6487
17500     0.6298      0.8122     0.8395     68.5256
17600     0.5849      0.8291     0.8395     68.0809
17700     0.5031      0.8502     0.8395     69.7248
17800     0.4999      0.8312     0.8395     67.6798
17900     0.5147      0.8481     0.8395     68.6708
18000     0.5081      0.8565     0.8395     70.4282
18100     0.5206      0.8586     0.8395     67.9803
18200     0.5567      0.8418     0.8395     69.5028
18300     0.5121      0.8481     0.8395     69.5350
18400     0.5904      0.8418     0.8395     68.7611
18500     0.4879      0.8376     0.8395     68.0130
18600     0.5831      0.8312     0.8395     68.5504
18700     0.5163      0.8439     0.8395     71.7448
18800     0.5491      0.8312     0.8395     69.8129
18900     0.6012      0.8143     0.8395     69.2236
19000     0.5098      0.8544     0.8395     68.3506
19100     0.4133      0.8924     0.8395     69.6647
19200     0.5075      0.8608     0.8395     70.0739
19300     0.5235      0.8544     0.8395     69.4673
19400     0.5341      0.8249     0.8395     69.1136
19500     0.4979      0.8544     0.8395     68.9615
19600     0.5406      0.8439     0.8395     70.2078
19700     0.5417      0.8460     0.8395     69.4105
19800     0.5743      0.8312     0.8395     72.4287
19900     0.6319      0.7996     0.8395     71.6126
20000     0.5815      0.8481     0.8395     70.4518
20100     0.5377      0.8565     0.8395     68.6435
20199     0.6007      0.8186     0.8395     69.6532
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.5068      0.8586     0.8344     9.8711
00100     0.3732      0.8797     0.8344     69.1977
00200     0.5324      0.8270     0.8360     70.2128
00300     0.4916      0.8608     0.8360     69.3807
00400     0.3962      0.8882     0.8360     71.3094
00500     0.4451      0.8544     0.8360     69.3147
00600     0.4581      0.8608     0.8360     70.2477
00700     0.4127      0.8861     0.8360     69.2332
00800     0.4020      0.8819     0.8360     70.6719
00900     0.4795      0.8608     0.8360     71.5242
01000     0.4367      0.8734     0.8360     70.4497
01100     0.4814      0.8397     0.8360     74.2196
01200     0.5217      0.8397     0.8360     71.8871
01300     0.4458      0.8819     0.8360     73.9290
01400     0.5339      0.8460     0.8368     70.5238
01500     0.4444      0.8734     0.8369     71.4301
01600     0.5001      0.8418     0.8369     70.1633
01700     0.4679      0.8713     0.8369     71.4523
01800     0.3871      0.8861     0.8369     70.6929
01900     0.3939      0.8861     0.8369     70.7364
02000     0.5038      0.8629     0.8369     69.5250
02100     0.4669      0.8608     0.8369     68.6076
02200     0.4319      0.8713     0.8369     72.4903
02300     0.4530      0.8819     0.8369     72.3360
02400     0.3919      0.8903     0.8369     69.7106
02500     0.4910      0.8502     0.8369     70.3474
02600     0.4887      0.8629     0.8409     70.2577
02700     0.4251      0.8903     0.8409     69.4268
02800     0.4392      0.8671     0.8409     69.2781
02900     0.4859      0.8481     0.8409     68.8661
03000     0.4766      0.8671     0.8409     70.2573
03100     0.4578      0.8502     0.8409     71.5140
03200     0.4563      0.8713     0.8409     71.6297
03300     0.3964      0.8840     0.8409     72.0596
03400     0.4452      0.8565     0.8409     72.3666
03500     0.4937      0.8418     0.8409     72.3133
03600     0.4527      0.8692     0.8409     71.8029
03700     0.5544      0.8376     0.8409     70.8952
03800     0.4380      0.8671     0.8409     71.6423
03900     0.3909      0.8861     0.8409     69.5344
04000     0.4814      0.8481     0.8409     69.6424
04100     0.4749      0.8629     0.8409     71.1358
04200     0.4805      0.8544     0.8437     70.5697
04300     0.4235      0.8819     0.8437     70.8113
04400     0.4006      0.8797     0.8437     69.7258
04500     0.4810      0.8586     0.8437     68.7546
04600     0.4635      0.8544     0.8437     69.0322
04700     0.4916      0.8629     0.8437     71.8477
04800     0.4280      0.8776     0.8437     72.2914
04900     0.4793      0.8586     0.8437     68.7503
05000     0.4641      0.8586     0.8437     69.7593
05100     0.3981      0.8924     0.8437     68.4805
05200     0.4965      0.8502     0.8437     68.2381
05300     0.4347      0.8692     0.8437     69.7633
05400     0.4808      0.8481     0.8437     68.8752
05500     0.4062      0.8776     0.8437     69.4268
05600     0.4490      0.8755     0.8437     69.1638
05700     0.4945      0.8586     0.8437     68.3747
05800     0.4177      0.8840     0.8437     67.4631
05900     0.4875      0.8608     0.8437     71.6934
06000     0.4608      0.8671     0.8437     69.6486
06100     0.5003      0.8397     0.8437     69.3187
06200     0.4360      0.8734     0.8437     68.1946
06300     0.4615      0.8734     0.8437     68.8326
06400     0.4261      0.8987     0.8437     70.3987
06500     0.4542      0.8734     0.8437     70.1722
06600     0.4282      0.8755     0.8437     69.5465
06700     0.4742      0.8692     0.8437     69.2119
06800     0.5077      0.8418     0.8437     71.5532
06900     0.3518      0.9008     0.8437     69.7913
07000     0.4735      0.8544     0.8437     69.5940
07100     0.4738      0.8460     0.8437     69.4379
07200     0.4366      0.8861     0.8437     69.7874
07300     0.5199      0.8397     0.8437     70.4192
07400     0.4894      0.8586     0.8437     69.3457
07500     0.3612      0.8966     0.8437     68.4945
07600     0.4912      0.8418     0.8437     68.3395
07700     0.4489      0.8671     0.8437     67.2858
07800     0.4270      0.8776     0.8437     69.2778
07900     0.5372      0.8228     0.8437     68.9835
08000     0.4548      0.8797     0.8437     69.0226
08100     0.4425      0.8797     0.8437     69.0520
08200     0.4336      0.8713     0.8437     68.5027
08300     0.3975      0.8945     0.8437     69.4495
08400     0.4063      0.8776     0.8437     68.5349
08500     0.4418      0.8565     0.8437     68.7452
08600     0.4881      0.8608     0.8437     68.7833
08700     0.4283      0.8797     0.8437     69.5677
08800     0.5009      0.8565     0.8437     69.4481
08900     0.4888      0.8713     0.8437     70.3096
09000     0.4751      0.8586     0.8437     68.4575
09100     0.4416      0.8861     0.8437     69.0702
09200     0.4308      0.8713     0.8437     68.8653
09300     0.4930      0.8565     0.8437     69.2941
09400     0.5119      0.8692     0.8437     70.9736
09500     0.4680      0.8544     0.8437     69.1799
09600     0.4421      0.8734     0.8437     71.5421
09700     0.5082      0.8481     0.8437     68.4092
09800     0.4284      0.8755     0.8437     69.3383
09900     0.4475      0.8629     0.8437     69.7709
Start testing:
Test Accuracy: 0.8317
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=193012823, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
7542a13b-a914-448b-8b36-1509f48d4a8b
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8015      0.0759     0.0586     11.4843
00100     1.3443      0.5802     0.6048     55.4947
00200     0.8450      0.7321     0.7660     55.8038
00300     0.6825      0.7743     0.8173     56.4522
00400     0.5739      0.8228     0.8289     55.5538
00500     0.5142      0.8312     0.8439     55.9558
00600     0.4865      0.8523     0.8522     55.9632
00700     0.4919      0.8439     0.8601     54.7782
00800     0.4240      0.8671     0.8709     55.8663
00900     0.4102      0.8924     0.8795     55.2012
01000     0.3340      0.9072     0.8795     54.9599
01100     0.3539      0.9156     0.8815     55.5233
01200     0.4015      0.8861     0.8866     54.7367
01300     0.2936      0.9219     0.8866     54.9872
01400     0.3133      0.9198     0.8908     55.9857
01500     0.3374      0.9030     0.8908     55.5647
01600     0.3250      0.9198     0.8988     55.8173
01700     0.3081      0.9177     0.8988     55.5407
01800     0.2763      0.9093     0.8988     55.8398
01900     0.3138      0.9135     0.9012     55.8511
02000     0.2834      0.9093     0.9012     55.8320
02100     0.2799      0.9325     0.9012     55.1969
02200     0.2504      0.9325     0.9012     56.2132
02300     0.2377      0.9367     0.9012     55.2795
02400     0.2895      0.9177     0.9028     56.1483
02500     0.2745      0.9156     0.9028     55.7393
02600     0.2729      0.9198     0.9028     55.6445
02700     0.2177      0.9409     0.9028     55.1409
02800     0.2341      0.9367     0.9046     55.3838
02900     0.3140      0.9219     0.9046     55.3912
03000     0.2656      0.9262     0.9046     56.1007
03100     0.2208      0.9367     0.9062     55.6772
03200     0.1620      0.9641     0.9062     56.4404
03300     0.2416      0.9283     0.9062     55.8359
03400     0.2401      0.9304     0.9062     55.7856
03500     0.2027      0.9430     0.9062     56.0914
03600     0.2002      0.9409     0.9062     55.4624
03700     0.1960      0.9494     0.9062     55.5516
03800     0.1790      0.9578     0.9062     56.0142
03900     0.2242      0.9346     0.9089     55.7391
04000     0.2036      0.9430     0.9089     55.5465
04100     0.1955      0.9451     0.9089     55.3177
04200     0.1623      0.9620     0.9110     55.7976
04300     0.2645      0.9262     0.9110     56.1380
04400     0.2209      0.9409     0.9110     54.8453
04500     0.1779      0.9578     0.9110     55.7198
04600     0.2456      0.9430     0.9110     56.3725
04700     0.1774      0.9515     0.9110     54.8605
04800     0.2071      0.9430     0.9110     56.3802
04900     0.1998      0.9515     0.9110     55.8597
05000     0.1698      0.9536     0.9110     55.5614
05100     0.1614      0.9620     0.9110     55.4522
05200     0.2032      0.9536     0.9110     55.8136
05300     0.2048      0.9515     0.9110     55.2253
05400     0.1564      0.9641     0.9110     55.3180
05500     0.2155      0.9283     0.9110     55.5357
05600     0.1787      0.9494     0.9110     56.4215
05700     0.1795      0.9620     0.9110     55.8544
05800     0.2338      0.9409     0.9110     55.7017
05900     0.1845      0.9515     0.9110     55.9847
06000     0.2027      0.9494     0.9110     55.8653
06100     0.1629      0.9578     0.9110     55.8766
06200     0.1605      0.9662     0.9110     55.7836
06300     0.1700      0.9641     0.9110     55.3841
06400     0.1839      0.9578     0.9110     56.1076
06500     0.1516      0.9662     0.9110     55.6161
06600     0.1893      0.9451     0.9110     54.7975
06700     0.1703      0.9641     0.9110     55.6336
06800     0.1487      0.9620     0.9110     55.5545
06900     0.1863      0.9557     0.9110     54.9510
07000     0.1736      0.9599     0.9110     55.4420
07100     0.1741      0.9515     0.9117     55.1496
07200     0.1673      0.9578     0.9117     55.9639
07300     0.1529      0.9599     0.9117     55.8234
07400     0.1844      0.9430     0.9117     55.3131
07500     0.1963      0.9536     0.9117     56.6127
07600     0.1885      0.9536     0.9117     55.7104
07700     0.1592      0.9620     0.9117     55.3661
07800     0.1539      0.9620     0.9138     56.0339
07900     0.1348      0.9705     0.9138     55.8640
08000     0.1567      0.9620     0.9138     55.4821
08100     0.1812      0.9515     0.9138     55.4013
08200     0.1986      0.9473     0.9138     55.4402
08300     0.1604      0.9684     0.9138     56.3189
08400     0.1859      0.9494     0.9138     55.6423
08500     0.1452      0.9684     0.9138     55.8868
08600     0.1567      0.9557     0.9138     55.8992
08700     0.2035      0.9430     0.9138     55.6786
08800     0.1973      0.9494     0.9138     56.1128
08900     0.1761      0.9515     0.9138     55.2019
09000     0.1432      0.9620     0.9138     55.7065
09100     0.1343      0.9726     0.9138     56.1864
09200     0.1966      0.9409     0.9138     55.4359
09300     0.1297      0.9684     0.9138     55.2703
09400     0.1796      0.9557     0.9138     55.7180
09500     0.1026      0.9789     0.9138     55.3186
09600     0.1606      0.9641     0.9138     55.6403
09700     0.1878      0.9578     0.9138     56.4120
09800     0.1913      0.9578     0.9138     55.7053
09900     0.1520      0.9684     0.9138     55.8403
10000     0.1124      0.9726     0.9138     55.2182
10100     0.1359      0.9662     0.9138     55.3895
10200     0.1472      0.9620     0.9138     55.8524
10300     0.1448      0.9662     0.9138     56.1274
10400     0.1218      0.9705     0.9138     56.0101
10500     0.1376      0.9662     0.9138     55.3270
10600     0.1240      0.9747     0.9138     55.3850
10700     0.1889      0.9557     0.9138     55.0819
10800     0.1352      0.9684     0.9138     55.1067
10900     0.1364      0.9684     0.9138     55.0950
11000     0.1462      0.9599     0.9138     56.5636
11100     0.1202      0.9684     0.9138     55.4524
11200     0.1652      0.9641     0.9138     55.9219
11300     0.1298      0.9705     0.9138     55.2807
11400     0.1348      0.9641     0.9138     55.1204
11500     0.1205      0.9641     0.9138     55.4543
11600     0.1599      0.9599     0.9138     55.7950
11700     0.1543      0.9515     0.9138     56.0324
11800     0.1047      0.9747     0.9138     55.4729
11900     0.1067      0.9747     0.9138     55.2833
12000     0.1637      0.9599     0.9138     56.2884
12100     0.1243      0.9662     0.9138     56.2180
12200     0.1355      0.9662     0.9138     55.4795
12300     0.1369      0.9684     0.9138     55.3611
12400     0.1049      0.9768     0.9138     56.1285
12500     0.1105      0.9705     0.9138     55.0439
12600     0.1131      0.9747     0.9138     56.2480
12700     0.1310      0.9789     0.9138     55.5696
12800     0.1559      0.9684     0.9138     56.2456
12900     0.1250      0.9641     0.9138     54.8254
13000     0.1174      0.9662     0.9138     55.3666
13100     0.1401      0.9557     0.9138     55.6134
13200     0.1561      0.9705     0.9138     55.3497
13300     0.1415      0.9662     0.9138     54.9204
13400     0.1610      0.9599     0.9138     55.4454
13500     0.0859      0.9810     0.9138     55.1278
13600     0.1554      0.9747     0.9138     56.4273
13700     0.1226      0.9747     0.9138     55.2330
13800     0.1197      0.9747     0.9138     55.4199
13900     0.1012      0.9810     0.9138     55.7005
14000     0.1506      0.9705     0.9138     56.2110
14100     0.1224      0.9641     0.9138     55.6302
14200     0.1415      0.9684     0.9138     55.7981
14300     0.1277      0.9641     0.9138     55.1849
14400     0.1220      0.9684     0.9138     56.1131
14500     0.1149      0.9726     0.9138     55.1437
14600     0.1199      0.9726     0.9138     55.3824
14700     0.0944      0.9810     0.9138     55.9505
14800     0.1063      0.9726     0.9138     55.7905
14900     0.0909      0.9831     0.9138     55.3106
15000     0.0839      0.9873     0.9138     56.1950
15100     0.1110      0.9789     0.9138     55.8061
15200     0.1036      0.9747     0.9138     56.0706
15300     0.1083      0.9747     0.9138     55.6217
15400     0.1337      0.9662     0.9138     55.3054
15500     0.1358      0.9599     0.9138     56.0055
15600     0.1138      0.9599     0.9138     55.7844
15700     0.1651      0.9536     0.9138     55.6672
15800     0.1265      0.9662     0.9138     56.1869
15900     0.0912      0.9831     0.9138     55.7239
16000     0.1022      0.9747     0.9138     56.1538
16100     0.1693      0.9515     0.9138     55.3121
16200     0.1165      0.9705     0.9138     55.7329
16300     0.0959      0.9747     0.9138     56.3845
16400     0.1136      0.9726     0.9138     55.7052
16500     0.0795      0.9916     0.9138     55.1536
16600     0.1341      0.9641     0.9138     55.6363
16700     0.1310      0.9684     0.9138     56.9685
16800     0.1282      0.9662     0.9138     56.7403
16900     0.1353      0.9684     0.9138     55.8257
17000     0.1049      0.9789     0.9138     55.2201
17100     0.1016      0.9831     0.9138     56.4911
17200     0.1490      0.9578     0.9138     55.3994
17300     0.1240      0.9726     0.9138     56.3331
17400     0.1098      0.9768     0.9138     55.3400
17500     0.1022      0.9768     0.9138     55.6581
17600     0.1144      0.9747     0.9138     56.1543
17700     0.0954      0.9810     0.9138     55.5023
17800     0.1315      0.9726     0.9138     54.8305
17900     0.1202      0.9747     0.9138     56.2659
18000     0.1286      0.9705     0.9138     55.1196
18100     0.0875      0.9852     0.9138     55.4942
18200     0.0717      0.9873     0.9138     55.8578
18300     0.1303      0.9599     0.9138     55.2189
18400     0.0890      0.9831     0.9138     56.0063
18500     0.1003      0.9726     0.9138     55.5982
18600     0.1123      0.9684     0.9138     55.1491
18700     0.1538      0.9494     0.9138     55.6261
18800     0.1089      0.9789     0.9138     55.3920
18900     0.1130      0.9768     0.9138     55.5879
19000     0.0931      0.9810     0.9138     55.7671
19100     0.0862      0.9873     0.9138     55.4895
19200     0.1008      0.9789     0.9138     56.8908
19300     0.1467      0.9620     0.9138     55.1915
19400     0.1088      0.9726     0.9138     56.3496
19500     0.1186      0.9789     0.9138     57.2039
19600     0.0967      0.9873     0.9138     55.0198
19700     0.1392      0.9684     0.9138     55.0334
19800     0.1320      0.9747     0.9138     55.7064
19900     0.1276      0.9684     0.9138     56.3702
20000     0.1148      0.9747     0.9138     55.1571
20100     0.1082      0.9747     0.9138     54.8691
20199     0.1353      0.9705     0.9138     53.3548
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.1096      0.9810     0.9092     9.2227
00100     0.1026      0.9789     0.9092     54.5150
00200     0.1105      0.9789     0.9092     54.8045
00300     0.0785      0.9831     0.9092     55.4028
00400     0.1038      0.9852     0.9092     55.0174
00500     0.0794      0.9810     0.9092     54.3148
00600     0.0855      0.9789     0.9092     54.5511
00700     0.1031      0.9768     0.9092     54.4912
00800     0.0825      0.9895     0.9092     54.4099
00900     0.0862      0.9789     0.9092     54.9092
01000     0.0896      0.9831     0.9092     54.6203
01100     0.0875      0.9852     0.9092     55.1776
01200     0.0751      0.9873     0.9092     54.9595
01300     0.0985      0.9831     0.9092     54.8110
01400     0.1258      0.9641     0.9092     54.8776
01500     0.1194      0.9747     0.9092     54.4203
01600     0.1090      0.9810     0.9092     54.7802
01700     0.0605      0.9916     0.9092     55.5655
01800     0.0978      0.9789     0.9092     54.4826
01900     0.0876      0.9768     0.9092     54.8575
02000     0.0988      0.9789     0.9092     54.6948
02100     0.0965      0.9810     0.9092     54.4707
02200     0.0880      0.9810     0.9092     55.4951
02300     0.1097      0.9810     0.9092     55.3518
02400     0.0620      0.9937     0.9092     55.1028
02500     0.0630      0.9916     0.9092     55.0131
02600     0.1004      0.9810     0.9092     55.3750
02700     0.0930      0.9810     0.9092     55.1660
02800     0.0763      0.9873     0.9092     54.3137
02900     0.0856      0.9831     0.9092     54.5740
03000     0.0892      0.9810     0.9092     55.1170
03100     0.0814      0.9810     0.9092     54.5824
03200     0.0826      0.9852     0.9092     54.8018
03300     0.1110      0.9768     0.9092     54.9354
03400     0.1521      0.9620     0.9092     54.5711
03500     0.1290      0.9789     0.9092     55.5975
03600     0.0900      0.9810     0.9092     54.7412
03700     0.0839      0.9831     0.9092     54.6417
03800     0.0861      0.9789     0.9092     55.4890
03900     0.1112      0.9768     0.9092     54.3873
04000     0.0835      0.9852     0.9092     55.1894
04100     0.1016      0.9810     0.9092     55.6872
04200     0.0927      0.9789     0.9092     55.3745
04300     0.0790      0.9873     0.9092     55.0760
04400     0.0844      0.9810     0.9092     54.7559
04500     0.0818      0.9831     0.9092     54.5911
04600     0.0759      0.9873     0.9092     55.0480
04700     0.1001      0.9810     0.9092     55.4656
04800     0.0816      0.9852     0.9092     54.6939
04900     0.0897      0.9810     0.9092     55.2161
05000     0.0938      0.9789     0.9092     55.0565
05100     0.0855      0.9789     0.9092     55.4931
05200     0.0735      0.9852     0.9092     54.5433
05300     0.0673      0.9916     0.9092     55.7198
05400     0.0965      0.9789     0.9092     55.3646
05500     0.0840      0.9831     0.9092     54.6592
05600     0.0712      0.9873     0.9092     54.9200
05700     0.0812      0.9810     0.9092     55.4139
05800     0.0774      0.9852     0.9092     54.9154
05900     0.0795      0.9831     0.9092     55.4096
06000     0.0944      0.9789     0.9092     54.9793
06100     0.0640      0.9916     0.9092     55.2383
06200     0.1007      0.9810     0.9092     55.3156
06300     0.0977      0.9747     0.9092     54.7426
06400     0.0802      0.9873     0.9092     54.8341
06500     0.0777      0.9873     0.9092     54.9538
06600     0.1079      0.9684     0.9092     55.0597
06700     0.0767      0.9852     0.9092     54.9068
06800     0.0907      0.9747     0.9092     54.9158
06900     0.0691      0.9852     0.9092     54.6716
07000     0.0771      0.9873     0.9092     55.8504
07100     0.0978      0.9768     0.9092     54.8724
07200     0.1032      0.9789     0.9092     55.9662
07300     0.0833      0.9852     0.9092     56.3483
07400     0.0602      0.9916     0.9092     56.5593
07500     0.0654      0.9916     0.9092     57.4936
07600     0.0786      0.9831     0.9092     55.7641
07700     0.0714      0.9852     0.9092     55.9067
07800     0.0732      0.9852     0.9092     56.0176
07900     0.1299      0.9747     0.9092     54.5508
08000     0.0788      0.9789     0.9092     55.3167
08100     0.1192      0.9705     0.9092     55.5509
08200     0.0845      0.9852     0.9092     55.5453
08300     0.0696      0.9873     0.9092     55.5586
08400     0.1033      0.9831     0.9092     55.1351
08500     0.0957      0.9873     0.9092     54.8409
08600     0.0864      0.9831     0.9092     55.6152
08700     0.0659      0.9916     0.9092     54.5162
08800     0.1005      0.9789     0.9092     54.5491
08900     0.0914      0.9852     0.9092     56.1283
09000     0.0944      0.9831     0.9092     55.4960
09100     0.1040      0.9726     0.9092     56.0055
09200     0.0781      0.9831     0.9092     54.4516
09300     0.0962      0.9789     0.9092     54.6583
09400     0.0845      0.9831     0.9092     55.3470
09500     0.0923      0.9831     0.9092     55.1382
09600     0.0989      0.9768     0.9092     54.7921
09700     0.1023      0.9810     0.9092     55.0422
09800     0.0817      0.9916     0.9092     54.7242
09900     0.0625      0.9937     0.9092     55.4612
Start testing:
Test Accuracy: 0.9075
