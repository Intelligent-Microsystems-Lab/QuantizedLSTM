Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
e8d0bf59-1fe3-49c5-bbaa-0ba9f4ac886f
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
7a836e3f-f07e-46a2-889a-3ebf36a156de
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
456f8606-aaf3-481e-87f3-aec888102bc3
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).to(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
4530bbb2-e641-4539-b587-fe2e3a402ae5
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8259      0.0675     0.0890     11.0863
00100     2.3457      0.2489     0.2918     55.3648
00200     1.8198      0.4219     0.4539     54.8554
00300     1.4509      0.5316     0.5436     54.8190
00400     1.3001      0.5992     0.6170     55.0090
00500     1.1765      0.6456     0.6605     54.2081
00600     1.0991      0.6667     0.6824     55.7965
00700     0.9632      0.7173     0.7214     54.1951
00800     0.9728      0.7110     0.7279     54.6910
00900     1.0147      0.6814     0.7408     54.7869
01000     0.9084      0.7278     0.7538     55.2589
01100     0.9521      0.7300     0.7538     55.4452
01200     0.9248      0.7342     0.7651     54.7152
01300     0.8151      0.7658     0.7740     57.7296
01400     0.9295      0.7131     0.7778     60.6913
01500     0.7769      0.7532     0.7785     60.1126
01600     0.8381      0.7532     0.7785     58.0964
01700     0.7491      0.7637     0.7875     57.1872
01800     0.8056      0.7532     0.7875     55.4492
01900     0.7213      0.7890     0.7989     55.7166
02000     0.7685      0.7764     0.7989     55.2080
02100     0.6860      0.7890     0.7989     55.6759
02200     0.6989      0.7932     0.7990     58.0425
02300     0.7793      0.7426     0.7990     54.9975
02400     0.6605      0.8249     0.7992     56.5164
02500     0.7697      0.7743     0.8053     54.8437
02600     0.7951      0.7722     0.8088     55.6220
02700     0.7111      0.7827     0.8111     54.9536
02800     0.6761      0.7890     0.8151     55.6844
02900     0.8101      0.7468     0.8151     55.6915
03000     0.7127      0.7890     0.8151     56.1198
03100     0.7414      0.7700     0.8222     55.4959
03200     0.6842      0.7954     0.8222     55.0822
03300     0.6146      0.8291     0.8222     55.2586
03400     0.7170      0.7764     0.8222     54.3432
03500     0.7206      0.7743     0.8239     56.2316
03600     0.6694      0.7890     0.8239     54.7992
03700     0.7065      0.7722     0.8239     55.3811
03800     0.6892      0.7890     0.8239     55.0900
03900     0.7338      0.7827     0.8239     55.7770
04000     0.6615      0.7911     0.8239     55.1064
04100     0.6149      0.8207     0.8239     54.7167
04200     0.7120      0.7616     0.8263     54.4358
04300     0.6517      0.8080     0.8263     55.2481
04400     0.6687      0.7869     0.8263     53.8559
04500     0.6248      0.8228     0.8263     55.1416
04600     0.6741      0.8080     0.8297     55.8152
04700     0.5553      0.8354     0.8297     54.3161
04800     0.6068      0.8165     0.8297     55.3622
04900     0.6090      0.8143     0.8354     54.9424
05000     0.7100      0.7869     0.8354     55.5645
05100     0.6635      0.8122     0.8354     56.0720
05200     0.6149      0.8186     0.8354     54.9914
05300     0.6598      0.8270     0.8354     54.5120
05400     0.6609      0.8038     0.8354     54.7304
05500     0.6254      0.8143     0.8354     55.1275
05600     0.5882      0.8249     0.8354     54.9710
05700     0.6782      0.7890     0.8354     54.2796
05800     0.6865      0.7996     0.8354     55.0064
05900     0.5624      0.8270     0.8354     56.0855
06000     0.6599      0.7869     0.8354     55.2458
06100     0.5873      0.8418     0.8354     55.7393
06200     0.5856      0.8228     0.8354     55.7261
06300     0.5998      0.8270     0.8354     56.2536
06400     0.5699      0.8270     0.8363     55.7221
06500     0.7126      0.7911     0.8363     55.1881
06600     0.6159      0.8186     0.8363     54.9298
06700     0.6122      0.8228     0.8363     55.0942
06800     0.5570      0.8186     0.8433     55.1443
06900     0.5850      0.8439     0.8433     55.2419
07000     0.6663      0.8249     0.8433     55.8350
07100     0.6723      0.7975     0.8433     54.5341
07200     0.5719      0.8354     0.8433     55.3569
07300     0.6726      0.7827     0.8433     55.1595
07400     0.5826      0.8207     0.8433     55.6819
07500     0.5611      0.8165     0.8433     55.6739
07600     0.6301      0.8207     0.8433     54.3847
07700     0.5317      0.8228     0.8438     54.6572
07800     0.5542      0.8312     0.8438     54.9830
07900     0.6663      0.7996     0.8438     54.6687
08000     0.6367      0.7954     0.8438     56.2935
08100     0.6479      0.8059     0.8438     55.4968
08200     0.5705      0.8228     0.8438     57.0250
08300     0.5328      0.8376     0.8438     54.9903
08400     0.6031      0.8270     0.8438     55.2376
08500     0.5940      0.8165     0.8438     54.7788
08600     0.6123      0.8038     0.8438     55.4805
08700     0.5714      0.8312     0.8438     55.4445
08800     0.6154      0.8059     0.8438     54.8399
08900     0.6235      0.8165     0.8438     54.9453
09000     0.5306      0.8586     0.8438     55.1556
09100     0.5223      0.8376     0.8438     54.9851
09200     0.6205      0.8207     0.8438     54.1926
09300     0.5154      0.8608     0.8438     54.1097
09400     0.5438      0.8376     0.8438     55.0089
09500     0.6483      0.7932     0.8438     55.7877
09600     0.5612      0.8249     0.8438     55.6625
09700     0.5506      0.8312     0.8438     56.6481
09800     0.5934      0.8186     0.8438     54.8536
09900     0.5531      0.8439     0.8438     55.7564
10000     0.5423      0.8481     0.8438     56.1065
10100     0.5832      0.8249     0.8438     56.6522
10200     0.5603      0.8376     0.8438     54.4915
10300     0.5295      0.8523     0.8438     54.8162
10400     0.5183      0.8376     0.8438     56.0649
10500     0.5318      0.8376     0.8449     56.5033
10600     0.5292      0.8418     0.8449     55.4971
10700     0.5398      0.8460     0.8449     55.8028
10800     0.5767      0.8460     0.8449     55.0775
10900     0.4900      0.8586     0.8449     54.5691
11000     0.4893      0.8565     0.8449     54.8713
11100     0.5811      0.8207     0.8454     54.7425
11200     0.4541      0.8608     0.8454     55.3841
11300     0.5662      0.8228     0.8454     56.1269
11400     0.5745      0.8291     0.8454     56.0877
11500     0.5656      0.8291     0.8454     56.2768
11600     0.5717      0.8249     0.8463     55.4044
11700     0.6053      0.8228     0.8463     54.6899
11800     0.5508      0.8439     0.8463     55.0919
11900     0.5277      0.8460     0.8463     54.4869
12000     0.5371      0.8418     0.8463     55.1808
12100     0.5229      0.8586     0.8463     54.6386
12200     0.5114      0.8249     0.8463     54.9617
12300     0.5722      0.8291     0.8463     55.9931
12400     0.5830      0.8228     0.8463     56.3761
12500     0.5574      0.8397     0.8463     56.4320
12600     0.5006      0.8502     0.8463     55.9275
12700     0.5878      0.8270     0.8463     56.4052
12800     0.5169      0.8502     0.8463     55.5451
12900     0.5255      0.8291     0.8463     55.1809
13000     0.5069      0.8397     0.8463     56.3248
13100     0.5440      0.8376     0.8463     55.7150
13200     0.5331      0.8481     0.8463     55.4336
13300     0.5526      0.8460     0.8463     54.9324
13400     0.6217      0.8101     0.8463     55.0262
13500     0.5282      0.8312     0.8463     55.7662
13600     0.5581      0.8418     0.8463     54.2876
13700     0.4879      0.8544     0.8474     54.6739
13800     0.4979      0.8544     0.8474     55.0667
13900     0.4988      0.8544     0.8474     55.0236
14000     0.5214      0.8586     0.8474     56.4416
14100     0.5754      0.8291     0.8474     52.5102
14200     0.5006      0.8502     0.8474     53.8069
14300     0.5062      0.8692     0.8474     54.5244
14400     0.5847      0.8270     0.8474     55.1577
14500     0.6208      0.8270     0.8474     54.0514
14600     0.5823      0.8270     0.8474     54.1453
14700     0.5105      0.8397     0.8474     55.2513
14800     0.5921      0.8249     0.8474     54.6625
14900     0.5414      0.8376     0.8474     54.6511
15000     0.5187      0.8586     0.8474     54.8333
15100     0.5229      0.8629     0.8474     54.4442
15200     0.5552      0.8312     0.8474     55.6773
15300     0.5376      0.8439     0.8496     54.9011
15400     0.5614      0.8228     0.8496     54.7319
15500     0.6124      0.8080     0.8496     55.0729
15600     0.5422      0.8502     0.8496     55.2752
15700     0.5391      0.8376     0.8496     54.2693
15800     0.6067      0.7911     0.8496     56.0603
15900     0.4941      0.8629     0.8523     54.6839
16000     0.5067      0.8397     0.8523     54.6753
16100     0.6211      0.7996     0.8523     55.7564
16200     0.5489      0.8333     0.8523     55.6233
16300     0.6135      0.7996     0.8523     56.0440
16400     0.5462      0.8228     0.8523     55.1861
16500     0.4969      0.8460     0.8523     54.9915
16600     0.5270      0.8397     0.8523     56.3789
16700     0.4896      0.8502     0.8523     56.0266
16800     0.5142      0.8460     0.8523     55.6163
16900     0.5920      0.8122     0.8523     55.2773
17000     0.5899      0.8143     0.8523     55.1905
17100     0.5544      0.8460     0.8523     55.1625
17200     0.6136      0.8122     0.8523     55.3525
17300     0.5675      0.8080     0.8523     54.6776
17400     0.5237      0.8460     0.8523     54.8590
17500     0.6028      0.8186     0.8523     55.2457
17600     0.5788      0.8354     0.8523     56.8844
17700     0.5221      0.8418     0.8523     55.5605
17800     0.5471      0.8291     0.8523     55.0584
17900     0.5162      0.8586     0.8523     55.4393
18000     0.5593      0.8397     0.8523     56.2466
18100     0.4965      0.8544     0.8523     56.7428
18200     0.5932      0.8165     0.8523     56.4726
18300     0.5100      0.8544     0.8523     54.8988
18400     0.5557      0.8333     0.8523     55.1212
18500     0.4756      0.8629     0.8523     54.7662
18600     0.6143      0.8059     0.8523     54.8851
18700     0.5346      0.8523     0.8523     55.3463
18800     0.5143      0.8418     0.8523     56.0163
18900     0.5510      0.8291     0.8523     56.4744
19000     0.4697      0.8755     0.8523     55.8330
19100     0.4970      0.8523     0.8523     55.4752
19200     0.4931      0.8481     0.8523     55.6193
19300     0.5934      0.8228     0.8523     54.9140
19400     0.5476      0.8397     0.8523     54.3217
19500     0.5153      0.8481     0.8523     54.8993
19600     0.5373      0.8502     0.8523     54.2999
19700     0.4896      0.8671     0.8523     55.9294
19800     0.5943      0.8059     0.8523     54.8168
19900     0.5540      0.8397     0.8523     54.7645
20000     0.6412      0.8122     0.8523     56.3265
20100     0.5278      0.8755     0.8523     56.4227
20199     0.5997      0.8228     0.8523     56.1187
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4877      0.8650     0.8501     8.7192
00100     0.3432      0.9072     0.8550     57.4019
00200     0.4952      0.8460     0.8550     54.5843
00300     0.4868      0.8523     0.8550     54.5915
00400     0.4142      0.8861     0.8550     54.6339
00500     0.4099      0.8776     0.8564     54.5663
00600     0.4850      0.8713     0.8564     55.1097
00700     0.4204      0.8819     0.8564     54.7736
00800     0.3951      0.8966     0.8564     56.3455
00900     0.4889      0.8608     0.8564     55.8639
01000     0.3903      0.9008     0.8564     55.5737
01100     0.4743      0.8481     0.8564     54.1944
01200     0.5139      0.8502     0.8564     54.1835
01300     0.4407      0.8734     0.8564     55.1069
01400     0.4921      0.8565     0.8564     56.0103
01500     0.4544      0.8523     0.8564     54.5463
01600     0.4858      0.8650     0.8565     55.1766
01700     0.4833      0.8650     0.8565     55.1248
01800     0.3986      0.8882     0.8565     54.8796
01900     0.3965      0.8755     0.8565     55.6454
02000     0.4548      0.8565     0.8572     55.3582
02100     0.4212      0.8797     0.8572     55.0520
02200     0.3992      0.8903     0.8583     56.4407
02300     0.4033      0.8819     0.8583     55.9654
02400     0.3840      0.8903     0.8583     55.1291
02500     0.4785      0.8523     0.8583     54.8180
02600     0.4585      0.8608     0.8583     56.1144
02700     0.3744      0.8882     0.8592     55.9331
02800     0.4405      0.8629     0.8592     55.3675
02900     0.4101      0.8755     0.8592     54.9018
03000     0.4581      0.8565     0.8592     55.0923
03100     0.4817      0.8586     0.8592     55.6034
03200     0.4060      0.8797     0.8592     55.6257
03300     0.3918      0.8840     0.8592     56.2762
03400     0.4032      0.8861     0.8592     56.2328
03500     0.4878      0.8692     0.8601     55.5469
03600     0.4333      0.8692     0.8601     54.5378
03700     0.5389      0.8291     0.8607     55.1124
03800     0.4351      0.8882     0.8607     54.6860
03900     0.3891      0.8903     0.8607     55.5155
04000     0.4978      0.8608     0.8607     55.1643
04100     0.4258      0.8629     0.8607     54.6949
04200     0.4432      0.8692     0.8607     55.8663
04300     0.4125      0.8797     0.8607     55.1606
04400     0.4118      0.8755     0.8607     57.5083
04500     0.4446      0.8671     0.8607     56.5838
04600     0.4885      0.8544     0.8607     55.6030
04700     0.4820      0.8481     0.8607     54.7213
04800     0.4018      0.9051     0.8607     54.8260
04900     0.4852      0.8608     0.8607     55.9239
05000     0.4449      0.8565     0.8607     55.2286
05100     0.4081      0.8861     0.8607     55.4952
05200     0.4429      0.8586     0.8607     53.5665
05300     0.4078      0.8819     0.8607     55.9949
05400     0.4966      0.8629     0.8607     56.3170
05500     0.4027      0.8819     0.8607     54.9639
05600     0.4263      0.8776     0.8607     55.8355
05700     0.4578      0.8544     0.8607     57.0708
05800     0.4352      0.8840     0.8607     55.8296
05900     0.4433      0.8734     0.8607     56.3068
06000     0.4352      0.8840     0.8607     55.6668
06100     0.4735      0.8650     0.8607     55.4028
06200     0.3734      0.8966     0.8607     56.2153
06300     0.4439      0.8713     0.8607     54.5745
06400     0.4326      0.8713     0.8607     54.1842
06500     0.4646      0.8481     0.8607     55.5124
06600     0.4518      0.8692     0.8607     54.6803
06700     0.4895      0.8565     0.8607     55.8520
06800     0.4984      0.8523     0.8607     54.6019
06900     0.3544      0.8966     0.8607     54.5569
07000     0.4082      0.8776     0.8607     55.4507
07100     0.4242      0.8882     0.8607     55.1628
07200     0.4391      0.8692     0.8607     54.1203
07300     0.4836      0.8523     0.8607     55.6641
07400     0.4326      0.8819     0.8607     54.4404
07500     0.3791      0.8966     0.8607     55.3309
07600     0.4154      0.8755     0.8607     54.5633
07700     0.4446      0.8755     0.8607     54.5580
07800     0.4452      0.8755     0.8621     55.8879
07900     0.5207      0.8186     0.8621     53.8019
08000     0.4680      0.8797     0.8621     56.3900
08100     0.4268      0.8882     0.8621     55.9160
08200     0.4170      0.8840     0.8621     54.6089
08300     0.3979      0.8987     0.8621     55.6050
08400     0.3661      0.9072     0.8621     54.2685
08500     0.4031      0.8776     0.8621     54.8289
08600     0.5099      0.8523     0.8621     54.9771
08700     0.3975      0.8882     0.8621     54.9621
08800     0.4776      0.8671     0.8621     54.8952
08900     0.4057      0.8797     0.8621     55.2575
09000     0.4483      0.8671     0.8621     55.4516
09100     0.4416      0.8713     0.8621     54.7717
09200     0.4576      0.8586     0.8621     54.7045
09300     0.4617      0.8692     0.8621     55.2485
09400     0.4502      0.8650     0.8621     55.3996
09500     0.4621      0.8586     0.8621     54.2626
09600     0.4885      0.8481     0.8621     55.4853
09700     0.5244      0.8376     0.8621     55.5932
09800     0.4554      0.8755     0.8621     54.8739
09900     0.4455      0.8713     0.8621     55.4173
Start testing:
Test Accuracy: 0.8360
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=193012823, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
7254e637-e6ca-4fc2-8a82-cd726bdcffec
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8017      0.0759     0.0609     11.0787
00100     1.3148      0.5696     0.6121     65.5764
00200     0.8566      0.7257     0.7633     68.4989
00300     0.6709      0.8059     0.8107     68.5081
00400     0.6077      0.8186     0.8303     67.9615
00500     0.5143      0.8418     0.8365     67.8390
00600     0.4895      0.8565     0.8572     67.8912
00700     0.4925      0.8481     0.8652     67.2362
00800     0.4586      0.8819     0.8652     68.5579
00900     0.4153      0.8966     0.8732     68.0409
01000     0.3687      0.8945     0.8790     68.1934
01100     0.3350      0.9072     0.8790     67.8312
01200     0.3762      0.8840     0.8794     67.8216
01300     0.3138      0.9219     0.8872     68.3292
01400     0.3272      0.9114     0.8883     67.4491
01500     0.3225      0.8987     0.8883     67.1204
01600     0.3031      0.9219     0.8914     68.4695
01700     0.3179      0.9114     0.8932     67.7621
01800     0.3278      0.8882     0.8932     66.8964
01900     0.3158      0.9198     0.8951     68.2056
02000     0.3127      0.9156     0.9012     68.4924
02100     0.2415      0.9346     0.9012     67.3711
02200     0.2546      0.9430     0.9012     68.0369
02300     0.2674      0.9325     0.9012     68.3892
02400     0.2969      0.9241     0.9012     68.3618
02500     0.2649      0.9219     0.9012     67.7597
02600     0.2671      0.9156     0.9012     67.3197
02700     0.1985      0.9430     0.9012     68.0537
02800     0.1999      0.9473     0.9012     67.7323
02900     0.2541      0.9346     0.9016     67.9591
03000     0.2660      0.9241     0.9016     68.7486
03100     0.2257      0.9304     0.9042     67.5748
03200     0.1629      0.9641     0.9042     67.7562
03300     0.2714      0.9135     0.9090     67.6712
03400     0.2434      0.9388     0.9090     67.1159
03500     0.1604      0.9620     0.9090     68.2639
03600     0.1985      0.9388     0.9090     67.9665
03700     0.1978      0.9620     0.9090     68.0036
03800     0.1979      0.9346     0.9090     67.5255
03900     0.2345      0.9346     0.9090     67.5100
04000     0.2021      0.9494     0.9090     68.4913
04100     0.1821      0.9494     0.9090     67.8326
04200     0.1707      0.9557     0.9090     67.1375
04300     0.2248      0.9409     0.9090     67.4320
04400     0.2242      0.9262     0.9090     67.7970
04500     0.1695      0.9515     0.9090     67.3905
04600     0.2689      0.9241     0.9090     68.7747
04700     0.1701      0.9536     0.9091     67.5266
04800     0.1947      0.9451     0.9091     66.8718
04900     0.1844      0.9557     0.9109     67.4541
05000     0.1630      0.9662     0.9109     68.1092
05100     0.1798      0.9536     0.9109     68.3037
05200     0.1894      0.9515     0.9109     67.7601
05300     0.2045      0.9451     0.9109     67.6257
05400     0.1440      0.9641     0.9109     67.3816
05500     0.1946      0.9430     0.9109     67.7060
05600     0.1812      0.9578     0.9109     68.0017
05700     0.1734      0.9620     0.9109     67.9612
05800     0.1751      0.9557     0.9109     68.1783
05900     0.1759      0.9641     0.9109     68.1182
06000     0.1887      0.9557     0.9109     67.9654
06100     0.1796      0.9536     0.9109     66.7220
06200     0.1772      0.9578     0.9109     68.0753
06300     0.1543      0.9620     0.9109     68.4141
06400     0.1817      0.9515     0.9109     68.0418
06500     0.1865      0.9599     0.9109     67.9110
06600     0.1590      0.9578     0.9109     67.5521
06700     0.1502      0.9662     0.9109     68.2087
06800     0.1832      0.9473     0.9109     67.5640
06900     0.2080      0.9451     0.9109     67.9204
07000     0.1677      0.9641     0.9109     68.8222
07100     0.1593      0.9641     0.9109     68.6637
07200     0.1584      0.9578     0.9109     68.0447
07300     0.1515      0.9684     0.9109     67.5125
07400     0.1683      0.9578     0.9113     67.5854
07500     0.1770      0.9599     0.9113     68.1598
07600     0.1564      0.9536     0.9113     67.8524
07700     0.1338      0.9641     0.9113     67.4919
07800     0.1592      0.9620     0.9113     67.8273
07900     0.1714      0.9578     0.9113     68.4740
08000     0.1557      0.9662     0.9113     68.3558
08100     0.1723      0.9578     0.9113     67.9773
08200     0.2139      0.9451     0.9113     68.6019
08300     0.1722      0.9578     0.9113     68.6185
08400     0.2054      0.9430     0.9113     67.5111
08500     0.1155      0.9747     0.9113     67.4593
08600     0.1690      0.9473     0.9113     68.0716
08700     0.1852      0.9599     0.9113     67.9092
08800     0.1510      0.9662     0.9113     67.8125
08900     0.1910      0.9536     0.9113     67.1736
09000     0.1263      0.9726     0.9113     67.7299
09100     0.1632      0.9599     0.9113     68.2046
09200     0.1708      0.9536     0.9113     67.0970
09300     0.1298      0.9768     0.9115     67.7335
09400     0.1710      0.9620     0.9115     67.4024
09500     0.1331      0.9726     0.9115     67.5950
09600     0.1253      0.9705     0.9115     68.9575
09700     0.1653      0.9684     0.9115     68.2228
09800     0.1536      0.9536     0.9115     67.9486
09900     0.1077      0.9789     0.9138     68.1518
10000     0.1540      0.9641     0.9138     67.9660
10100     0.1108      0.9789     0.9138     67.6152
10200     0.1360      0.9641     0.9138     67.7479
10300     0.1379      0.9726     0.9164     68.2895
10400     0.1079      0.9768     0.9164     68.6423
10500     0.1312      0.9726     0.9176     68.0285
10600     0.1142      0.9831     0.9176     67.7965
10700     0.1784      0.9536     0.9176     68.1205
10800     0.1107      0.9768     0.9176     67.8203
10900     0.1611      0.9620     0.9176     68.4710
11000     0.1342      0.9599     0.9176     68.7683
11100     0.1161      0.9726     0.9176     67.8612
11200     0.1626      0.9641     0.9176     67.8015
11300     0.1260      0.9726     0.9176     67.4425
11400     0.1309      0.9620     0.9176     68.3255
11500     0.0995      0.9705     0.9176     68.3189
11600     0.1496      0.9620     0.9176     68.2917
11700     0.1464      0.9620     0.9176     67.6866
11800     0.1239      0.9662     0.9176     68.1564
11900     0.1356      0.9599     0.9176     67.5212
12000     0.1567      0.9641     0.9176     67.5108
12100     0.1463      0.9599     0.9176     68.3261
12200     0.1235      0.9705     0.9176     68.0872
12300     0.1452      0.9662     0.9176     68.0260
12400     0.1029      0.9768     0.9176     68.6349
12500     0.1036      0.9789     0.9176     68.1969
12600     0.1184      0.9726     0.9176     67.8018
12700     0.1231      0.9684     0.9176     67.3627
12800     0.1446      0.9705     0.9176     68.4217
12900     0.1056      0.9768     0.9176     68.3974
13000     0.1281      0.9747     0.9176     67.7856
13100     0.1123      0.9705     0.9176     67.3075
13200     0.1171      0.9705     0.9176     68.4455
13300     0.1335      0.9747     0.9176     68.4743
13400     0.1464      0.9684     0.9176     67.9220
13500     0.0952      0.9852     0.9176     68.0257
13600     0.1479      0.9684     0.9176     68.0843
13700     0.1350      0.9599     0.9176     68.1167
13800     0.1093      0.9726     0.9176     67.9461
13900     0.0793      0.9873     0.9176     68.1450
14000     0.1335      0.9726     0.9176     67.8069
14100     0.1094      0.9705     0.9176     67.8223
14200     0.1048      0.9873     0.9176     68.6365
14300     0.1534      0.9599     0.9176     68.5606
14400     0.1091      0.9789     0.9176     68.5193
14500     0.1150      0.9726     0.9176     68.1658
14600     0.1326      0.9747     0.9176     67.0863
14700     0.0840      0.9873     0.9176     67.8815
14800     0.1452      0.9641     0.9176     67.5403
14900     0.1104      0.9726     0.9176     67.7658
15000     0.1057      0.9789     0.9176     67.7391
15100     0.1204      0.9726     0.9176     67.8686
15200     0.0947      0.9726     0.9176     67.4171
15300     0.1384      0.9641     0.9176     67.9276
15400     0.1135      0.9747     0.9176     67.8226
15500     0.0965      0.9810     0.9176     67.5190
15600     0.1193      0.9705     0.9176     68.8047
15700     0.1314      0.9684     0.9176     68.6505
15800     0.1167      0.9726     0.9176     68.5909
15900     0.0872      0.9831     0.9176     67.9224
16000     0.1218      0.9705     0.9176     69.2566
16100     0.1277      0.9705     0.9176     67.5510
16200     0.1357      0.9662     0.9176     67.8655
16300     0.0995      0.9705     0.9176     68.6565
16400     0.1367      0.9578     0.9176     68.3262
16500     0.0927      0.9831     0.9176     68.9309
16600     0.1033      0.9789     0.9176     68.5278
16700     0.1094      0.9747     0.9176     67.7113
16800     0.1261      0.9705     0.9176     68.0818
16900     0.1273      0.9662     0.9176     67.2899
17000     0.1142      0.9768     0.9176     67.7799
17100     0.1186      0.9726     0.9176     67.9332
17200     0.1178      0.9662     0.9176     67.7502
17300     0.0858      0.9873     0.9176     68.2688
17400     0.0906      0.9831     0.9176     68.0917
17500     0.0965      0.9726     0.9176     67.2103
17600     0.1141      0.9747     0.9176     68.5408
17700     0.0944      0.9852     0.9176     68.4692
17800     0.1221      0.9705     0.9176     68.2528
17900     0.1025      0.9852     0.9176     68.5577
18000     0.1187      0.9705     0.9176     67.8347
18100     0.0962      0.9789     0.9176     67.9407
18200     0.0722      0.9873     0.9176     68.9304
18300     0.1014      0.9726     0.9176     67.3669
18400     0.0929      0.9831     0.9176     68.3939
18500     0.1084      0.9726     0.9176     67.4149
18600     0.1300      0.9726     0.9176     67.6131
18700     0.1168      0.9726     0.9176     69.2494
18800     0.1215      0.9789     0.9176     67.5838
18900     0.1469      0.9705     0.9176     67.3810
19000     0.0936      0.9789     0.9176     67.9929
19100     0.1247      0.9789     0.9176     69.1006
19200     0.1293      0.9726     0.9176     69.2381
19300     0.1291      0.9662     0.9176     67.2328
19400     0.1021      0.9810     0.9176     68.1676
19500     0.0838      0.9831     0.9176     68.2576
19600     0.1296      0.9684     0.9176     67.3103
19700     0.1545      0.9705     0.9176     66.7903
19800     0.1292      0.9768     0.9176     67.3988
19900     0.1132      0.9768     0.9176     67.3045
20000     0.0976      0.9831     0.9176     67.6021
20100     0.0707      0.9873     0.9176     68.2570
20199     0.1154      0.9684     0.9176     67.1590
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.0994      0.9810     0.9084     9.8651
00100     0.0901      0.9831     0.9084     68.4381
00200     0.0991      0.9789     0.9107     67.9063
00300     0.0709      0.9873     0.9135     67.4683
00400     0.0859      0.9789     0.9135     68.3318
00500     0.0868      0.9831     0.9135     68.6202
00600     0.0852      0.9810     0.9135     68.4148
00700     0.0957      0.9810     0.9135     68.1856
00800     0.0816      0.9873     0.9135     67.8809
00900     0.1322      0.9641     0.9135     68.3241
01000     0.0799      0.9873     0.9135     67.4022
01100     0.0651      0.9916     0.9135     68.3665
01200     0.0766      0.9852     0.9135     67.7375
01300     0.1079      0.9747     0.9135     68.3760
01400     0.1106      0.9747     0.9135     67.2147
01500     0.1045      0.9810     0.9135     67.4231
01600     0.1128      0.9768     0.9135     67.9045
01700     0.0903      0.9831     0.9135     68.7566
01800     0.1017      0.9747     0.9135     68.4324
01900     0.0674      0.9916     0.9135     68.6694
02000     0.1030      0.9726     0.9135     68.2161
02100     0.0767      0.9873     0.9135     67.4491
02200     0.0709      0.9852     0.9135     69.2111
02300     0.1283      0.9684     0.9135     68.2401
02400     0.0539      0.9937     0.9135     67.6219
02500     0.0623      0.9937     0.9135     68.1955
02600     0.0803      0.9852     0.9135     67.8123
02700     0.0918      0.9852     0.9135     68.4067
02800     0.0875      0.9810     0.9135     68.1244
02900     0.0773      0.9873     0.9135     68.3694
03000     0.0688      0.9873     0.9135     68.4183
03100     0.0996      0.9747     0.9135     67.0386
03200     0.0634      0.9873     0.9135     67.9099
03300     0.0936      0.9852     0.9135     69.1588
03400     0.1055      0.9726     0.9135     68.9635
03500     0.1146      0.9726     0.9135     68.9534
03600     0.0843      0.9852     0.9135     68.4316
03700     0.0672      0.9852     0.9135     68.6279
03800     0.0765      0.9873     0.9135     67.7996
03900     0.0785      0.9916     0.9135     67.8136
04000     0.0825      0.9852     0.9135     68.0596
04100     0.0733      0.9831     0.9135     68.1610
04200     0.0805      0.9831     0.9135     67.2823
04300     0.0781      0.9895     0.9135     67.6506
04400     0.0884      0.9768     0.9135     68.2107
04500     0.0678      0.9873     0.9135     68.4584
04600     0.0810      0.9852     0.9135     68.1631
04700     0.0832      0.9810     0.9135     67.9455
04800     0.0759      0.9831     0.9135     68.2904
04900     0.0680      0.9916     0.9135     68.3364
05000     0.0836      0.9852     0.9135     68.4689
05100     0.0933      0.9810     0.9135     68.5852
05200     0.0854      0.9810     0.9135     68.9938
05300     0.1046      0.9789     0.9135     67.8533
05400     0.1159      0.9747     0.9135     68.1305
05500     0.0684      0.9873     0.9135     68.9804
05600     0.0695      0.9810     0.9135     68.5640
05700     0.0766      0.9852     0.9135     68.7728
05800     0.0751      0.9831     0.9135     68.9166
05900     0.0740      0.9895     0.9135     68.8380
06000     0.1053      0.9726     0.9135     67.9590
06100     0.0649      0.9916     0.9135     68.6771
06200     0.0751      0.9852     0.9135     69.0689
06300     0.0832      0.9831     0.9135     68.0122
06400     0.0592      0.9937     0.9135     67.6636
06500     0.0633      0.9895     0.9135     68.3907
06600     0.0851      0.9789     0.9135     67.8347
06700     0.0960      0.9789     0.9135     68.8997
06800     0.0916      0.9852     0.9135     68.9808
06900     0.0731      0.9831     0.9135     68.2772
07000     0.0807      0.9852     0.9135     68.5618
07100     0.0947      0.9747     0.9135     68.4416
07200     0.0904      0.9789     0.9135     67.0602
07300     0.0991      0.9747     0.9135     68.9012
07400     0.0560      0.9916     0.9135     68.3723
07500     0.0888      0.9831     0.9135     68.6991
07600     0.0694      0.9852     0.9135     69.0309
07700     0.0676      0.9895     0.9135     68.2864
07800     0.0725      0.9873     0.9135     68.4689
07900     0.1190      0.9705     0.9135     67.7954
08000     0.0830      0.9831     0.9135     67.9009
08100     0.1027      0.9726     0.9135     68.3872
08200     0.0722      0.9895     0.9135     68.4315
08300     0.0592      0.9895     0.9135     68.5732
08400     0.1263      0.9726     0.9135     68.9960
08500     0.0937      0.9810     0.9135     69.2698
08600     0.0821      0.9852     0.9135     69.0250
08700     0.0744      0.9852     0.9135     67.7148
08800     0.0917      0.9810     0.9135     68.3732
08900     0.0753      0.9831     0.9135     68.3041
09000     0.0724      0.9810     0.9135     67.9264
09100     0.0913      0.9789     0.9135     69.0786
09200     0.0789      0.9768     0.9135     69.1772
09300     0.0979      0.9789     0.9135     68.8007
09400     0.1018      0.9789     0.9135     68.7290
09500     0.0762      0.9852     0.9135     68.5869
09600     0.0847      0.9852     0.9135     67.8750
09700     0.0848      0.9873     0.9135     68.0132
09800     0.0808      0.9831     0.9135     68.1108
09900     0.0591      0.9895     0.9135     68.3731
Start testing:
Test Accuracy: 0.9073
