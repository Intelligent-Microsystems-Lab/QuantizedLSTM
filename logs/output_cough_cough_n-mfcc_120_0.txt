Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(batch_size=512, cy_div=2, cy_scale=2, dataloader_num_workers=4, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', epochs=20000, fp_train=0, global_beta=1.5, hidden=200, hop_length=320, init_factor=2, learning_rate=0.0005, lr_divide=10000, n_mfcc=120, noise_injection=0.1, quant_act=4, quant_inp=4, quant_w=None, sample_rate=16000, std_scale=2, testing_percentage=10, validation_percentage=10, validation_size=1000, win_length=400, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
3fa64536-78cc-4bc9-ad91-3cd594acb048
Start Training:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 324, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "KWS_LSTM.py", line 266, in forward
    output = quant_pass(torch.nn.ReLU(outputFC), self.ab, True)
  File "KWS_LSTM.py", line 113, in forward
    x = clip(x, wb)
  File "KWS_LSTM.py", line 78, in clip
    return torch.clamp(x, float(minv), float(maxv))
TypeError: clamp(): argument 'input' (position 1) must be Tensor, not ReLU
