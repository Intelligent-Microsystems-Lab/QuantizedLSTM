Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
e05c0a00-7c61-48b9-895b-631c7510f238
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
ce2406b9-13c0-44c4-8fff-bd0413b992ad
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
e80d785a-93d6-4b8c-ae0b-797c2d76dcf5
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.7033      0.0886     0.0709     10.4073
00100     2.1147      0.2637     0.2872     69.4210
00200     1.7319      0.4093     0.4588     68.8938
00300     1.3069      0.6076     0.5768     69.6545
00400     1.3461      0.5781     0.6408     69.2181
00500     1.1466      0.6414     0.6709     68.1343
00600     1.1095      0.6667     0.7032     69.2316
00700     0.9170      0.7405     0.7210     69.4584
00800     0.9550      0.7152     0.7301     70.3975
00900     0.7779      0.7722     0.7517     69.5867
01000     0.9519      0.7110     0.7517     70.0222
01100     0.8800      0.7468     0.7639     69.3741
01200     0.8555      0.7511     0.7639     68.0773
01300     0.7579      0.7616     0.7734     68.5995
01400     0.7913      0.7658     0.7741     69.8947
01500     0.7580      0.7848     0.7741     70.9730
01600     0.8131      0.7616     0.7833     68.7170
01700     0.7826      0.7658     0.7833     68.4009
01800     0.7849      0.7511     0.7833     71.0882
01900     0.7797      0.7658     0.7847     68.9458
02000     0.7843      0.7616     0.7864     66.3094
02100     0.7827      0.7722     0.7884     67.5348
02200     0.7498      0.7848     0.7947     67.6013
02300     0.7099      0.7848     0.7960     68.2847
02400     0.7493      0.7616     0.7960     67.2245
02500     0.7391      0.7700     0.7972     66.5084
02600     0.7228      0.7722     0.8046     67.3851
02700     0.7885      0.7405     0.8101     67.3004
02800     0.6405      0.8122     0.8101     66.5569
02900     0.6929      0.8038     0.8101     67.5530
03000     0.7569      0.7722     0.8121     68.4089
03100     0.7125      0.7890     0.8121     68.5824
03200     0.6689      0.8122     0.8122     68.7996
03300     0.6529      0.8059     0.8122     67.4077
03400     0.6868      0.8017     0.8122     67.5504
03500     0.7214      0.7722     0.8122     68.1970
03600     0.6551      0.8080     0.8163     67.9968
03700     0.6957      0.7911     0.8163     69.8563
03800     0.7009      0.8059     0.8163     68.0337
03900     0.6774      0.7679     0.8163     66.6545
04000     0.6574      0.8080     0.8234     68.0209
04100     0.6821      0.7975     0.8234     66.3509
04200     0.7073      0.7722     0.8234     66.6282
04300     0.6812      0.7869     0.8234     68.4275
04400     0.5365      0.8312     0.8234     68.2149
04500     0.6632      0.8059     0.8234     67.6473
04600     0.6574      0.8038     0.8234     67.6024
04700     0.6484      0.8038     0.8234     66.4076
04800     0.7468      0.7806     0.8286     68.9161
04900     0.6806      0.8080     0.8286     68.0585
05000     0.6404      0.8186     0.8286     67.2009
05100     0.7094      0.8038     0.8323     66.9681
05200     0.6990      0.7869     0.8323     67.9752
05300     0.6800      0.8080     0.8323     68.2244
05400     0.6591      0.7996     0.8323     68.5070
05500     0.6978      0.8017     0.8323     68.0235
05600     0.6262      0.8122     0.8323     69.8922
05700     0.5668      0.8228     0.8323     67.6737
05800     0.6284      0.8228     0.8323     67.2961
05900     0.6479      0.8059     0.8323     68.7351
06000     0.6202      0.8165     0.8323     68.1069
06100     0.5977      0.8376     0.8323     67.4843
06200     0.6193      0.8228     0.8323     69.6959
06300     0.6141      0.8186     0.8323     70.3278
06400     0.5951      0.8080     0.8323     69.1975
06500     0.6126      0.8165     0.8323     67.3073
06600     0.6678      0.8017     0.8323     67.0827
06700     0.5657      0.8460     0.8323     66.8649
06800     0.6676      0.8038     0.8323     69.9031
06900     0.5560      0.8502     0.8323     67.1944
07000     0.6594      0.7890     0.8323     68.0100
07100     0.6140      0.8228     0.8323     68.2497
07200     0.5586      0.8270     0.8323     68.7513
07300     0.5951      0.8418     0.8323     69.0929
07400     0.7093      0.7954     0.8323     67.6921
07500     0.5899      0.8207     0.8323     68.3716
07600     0.6301      0.7890     0.8323     69.1679
07700     0.5775      0.8312     0.8323     66.9558
07800     0.6277      0.8059     0.8323     69.8838
07900     0.5696      0.8376     0.8323     68.3126
08000     0.6771      0.8101     0.8326     68.3559
08100     0.6217      0.8143     0.8326     66.4331
08200     0.5551      0.8460     0.8326     67.6167
08300     0.5570      0.8439     0.8326     67.2435
08400     0.6453      0.7975     0.8326     66.4847
08500     0.6103      0.8017     0.8326     67.6536
08600     0.5943      0.8376     0.8326     67.7176
08700     0.6859      0.7848     0.8326     67.2945
08800     0.5526      0.8165     0.8326     68.5954
08900     0.6068      0.8165     0.8326     68.0808
09000     0.6548      0.7911     0.8326     68.2363
09100     0.6056      0.8186     0.8374     67.8204
09200     0.5716      0.8228     0.8374     67.3464
09300     0.5752      0.8270     0.8374     68.3046
09400     0.5991      0.8228     0.8374     67.4577
09500     0.5836      0.8207     0.8374     66.7679
09600     0.6466      0.8122     0.8374     67.3697
09700     0.6331      0.8080     0.8374     68.9811
09800     0.5889      0.8080     0.8374     67.1907
09900     0.5926      0.8165     0.8374     70.6918
10000     0.5947      0.8165     0.8374     67.8938
10100     0.6192      0.8101     0.8409     70.2239
10200     0.5938      0.8333     0.8409     67.5229
10300     0.6957      0.8059     0.8424     67.3742
10400     0.5555      0.8397     0.8424     67.7762
10500     0.4862      0.8713     0.8424     68.1517
10600     0.5520      0.8270     0.8424     68.7191
10700     0.6017      0.8354     0.8447     67.6539
10800     0.5912      0.8312     0.8447     66.9358
10900     0.5547      0.8439     0.8447     69.1706
11000     0.5418      0.8418     0.8447     68.7773
11100     0.5460      0.8312     0.8447     68.1492
11200     0.5869      0.8122     0.8447     68.2054
11300     0.6650      0.8038     0.8447     67.7076
11400     0.6016      0.8143     0.8447     68.5166
11500     0.5920      0.8228     0.8447     66.6805
11600     0.4941      0.8629     0.8447     68.9248
11700     0.5388      0.8418     0.8447     67.9573
11800     0.5489      0.8376     0.8447     69.0502
11900     0.5826      0.8270     0.8447     68.8327
12000     0.6073      0.8101     0.8447     68.2410
12100     0.5149      0.8565     0.8447     67.8342
12200     0.6281      0.8101     0.8447     67.2686
12300     0.6271      0.8207     0.8447     67.7784
12400     0.5381      0.8418     0.8447     67.3206
12500     0.5504      0.8439     0.8447     70.1707
12600     0.5133      0.8376     0.8447     69.5031
12700     0.5690      0.8376     0.8447     68.0212
12800     0.5350      0.8397     0.8447     67.8473
12900     0.5700      0.8586     0.8447     71.2865
13000     0.5912      0.8165     0.8447     68.8713
13100     0.6555      0.7975     0.8447     67.8876
13200     0.6034      0.8080     0.8447     67.8789
13300     0.6115      0.8207     0.8447     68.4296
13400     0.6354      0.8186     0.8447     67.3915
13500     0.5559      0.8354     0.8447     68.3526
13600     0.4892      0.8608     0.8447     66.7758
13700     0.5877      0.8080     0.8447     66.3959
13800     0.5001      0.8629     0.8447     66.8802
13900     0.5928      0.8354     0.8447     68.9245
14000     0.5654      0.8354     0.8447     67.3618
14100     0.6187      0.8186     0.8447     67.3332
14200     0.5556      0.8270     0.8447     68.0781
14300     0.5599      0.8101     0.8447     68.9033
14400     0.5176      0.8460     0.8447     71.2897
14500     0.5272      0.8460     0.8447     67.3978
14600     0.5092      0.8481     0.8447     68.7515
14700     0.5522      0.8418     0.8447     68.2632
14800     0.5787      0.8228     0.8447     67.3609
14900     0.5710      0.8376     0.8447     67.1591
15000     0.5783      0.8101     0.8453     67.0308
15100     0.6007      0.8228     0.8453     68.8830
15200     0.5036      0.8523     0.8453     67.6259
15300     0.5128      0.8439     0.8453     67.7812
15400     0.5900      0.8291     0.8453     67.4361
15500     0.4965      0.8671     0.8453     67.6317
15600     0.5159      0.8544     0.8453     68.0440
15700     0.5466      0.8376     0.8453     68.8016
15800     0.5275      0.8397     0.8453     68.3290
15900     0.5186      0.8502     0.8453     68.7282
16000     0.5288      0.8523     0.8453     67.9996
16100     0.5903      0.8312     0.8453     67.2725
16200     0.5002      0.8502     0.8453     69.2555
16300     0.6357      0.7954     0.8453     67.9413
16400     0.6091      0.8333     0.8453     67.1944
16500     0.6374      0.8228     0.8453     67.8125
16600     0.5319      0.8544     0.8453     68.1592
16700     0.4702      0.8734     0.8453     67.9044
16800     0.4989      0.8586     0.8461     67.0299
16900     0.6094      0.8291     0.8461     69.7640
17000     0.5372      0.8418     0.8461     67.1667
17100     0.6882      0.7722     0.8461     68.7946
17200     0.5695      0.8565     0.8461     68.5786
17300     0.6724      0.8165     0.8461     68.9666
17400     0.5870      0.8101     0.8461     69.0071
17500     0.5426      0.8376     0.8461     69.0512
17600     0.6009      0.8207     0.8461     67.8025
17700     0.5331      0.8397     0.8461     67.5099
17800     0.5035      0.8586     0.8461     67.6845
17900     0.5318      0.8397     0.8461     67.1822
18000     0.5092      0.8397     0.8461     67.5439
18100     0.4935      0.8713     0.8461     68.6164
18200     0.5325      0.8481     0.8461     66.9142
18300     0.5336      0.8544     0.8461     67.4564
18400     0.5319      0.8418     0.8461     68.7863
18500     0.5657      0.8207     0.8461     68.1392
18600     0.5118      0.8586     0.8461     68.7969
18700     0.6059      0.8291     0.8461     70.8192
18800     0.5729      0.8376     0.8461     70.7148
18900     0.5444      0.8671     0.8461     67.5024
19000     0.5006      0.8565     0.8461     67.3050
19100     0.5133      0.8544     0.8461     67.4814
19200     0.5581      0.8270     0.8461     68.8355
19300     0.5092      0.8544     0.8461     69.3774
19400     0.5892      0.8249     0.8461     67.7616
19500     0.5782      0.8143     0.8461     67.5177
19600     0.5043      0.8565     0.8461     67.8692
19700     0.5897      0.8186     0.8490     67.7671
19800     0.5070      0.8312     0.8490     70.0875
19900     0.6344      0.8186     0.8490     69.3839
20000     0.6430      0.7975     0.8490     67.9933
20100     0.5185      0.8439     0.8512     69.5700
20199     0.5823      0.8228     0.8512     69.0522
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4842      0.8544     0.8456     9.8941
00100     0.4381      0.8671     0.8523     67.9955
00200     0.4548      0.8734     0.8523     67.4424
00300     0.4269      0.8797     0.8525     67.0421
00400     0.5103      0.8502     0.8525     66.6858
00500     0.4657      0.8523     0.8527     67.9543
00600     0.5052      0.8565     0.8546     67.2933
00700     0.5130      0.8397     0.8546     67.3744
00800     0.4741      0.8840     0.8547     70.1908
00900     0.3711      0.8987     0.8547     67.8540
01000     0.4316      0.8734     0.8567     66.9639
01100     0.5635      0.8376     0.8576     68.3141
01200     0.5032      0.8544     0.8576     67.0044
01300     0.4395      0.8734     0.8576     68.8846
01400     0.4361      0.8840     0.8578     66.6340
01500     0.4626      0.8608     0.8578     68.9178
01600     0.5279      0.8481     0.8578     66.1593
01700     0.4634      0.8608     0.8578     69.1831
01800     0.4258      0.8734     0.8578     68.3161
01900     0.5018      0.8734     0.8578     66.7662
02000     0.4675      0.8565     0.8578     68.7587
02100     0.4295      0.8671     0.8578     66.8681
02200     0.5464      0.8249     0.8578     66.7232
02300     0.5139      0.8460     0.8578     66.8196
02400     0.4744      0.8734     0.8578     69.0370
02500     0.5236      0.8418     0.8578     68.8140
02600     0.3982      0.8819     0.8578     67.2416
02700     0.4512      0.8439     0.8578     67.7627
02800     0.4605      0.8755     0.8578     66.3482
02900     0.4561      0.8671     0.8578     67.0508
03000     0.5280      0.8481     0.8578     67.9201
03100     0.4510      0.8650     0.8578     67.4643
03200     0.4019      0.8987     0.8578     67.2839
03300     0.4280      0.8882     0.8578     67.8553
03400     0.4775      0.8586     0.8578     69.2447
03500     0.4314      0.8755     0.8578     68.6566
03600     0.4638      0.8671     0.8578     66.8820
03700     0.4259      0.8840     0.8587     68.3559
03800     0.4072      0.8840     0.8587     68.4161
03900     0.5317      0.8397     0.8587     68.7726
04000     0.4527      0.8629     0.8587     69.8772
04100     0.3958      0.8861     0.8587     69.7463
04200     0.4272      0.8819     0.8587     68.4613
04300     0.4117      0.8924     0.8587     68.8566
04400     0.4800      0.8608     0.8587     68.0055
04500     0.4769      0.8586     0.8587     68.6154
04600     0.4299      0.8840     0.8587     68.8526
04700     0.4113      0.8755     0.8587     67.6261
04800     0.4559      0.8544     0.8587     68.4840
04900     0.4718      0.8713     0.8587     68.2186
05000     0.4927      0.8397     0.8587     67.8305
05100     0.4508      0.8713     0.8587     67.9295
05200     0.4679      0.8629     0.8587     68.3102
05300     0.4809      0.8565     0.8587     67.8783
05400     0.4464      0.8671     0.8587     68.6882
05500     0.3821      0.9030     0.8587     67.6308
05600     0.4535      0.8734     0.8587     70.9667
05700     0.4916      0.8523     0.8587     67.8207
05800     0.5005      0.8502     0.8587     67.1750
05900     0.4728      0.8650     0.8587     69.7506
06000     0.4280      0.8840     0.8587     69.2631
06100     0.4731      0.8565     0.8587     68.8213
06200     0.4893      0.8586     0.8587     69.0638
06300     0.4094      0.8819     0.8587     66.5839
06400     0.4264      0.8734     0.8587     69.0460
06500     0.5296      0.8376     0.8587     68.5516
06600     0.4649      0.8692     0.8587     67.5770
06700     0.4009      0.8797     0.8587     68.1317
06800     0.4988      0.8502     0.8587     67.8476
06900     0.4176      0.8861     0.8587     69.5261
07000     0.4592      0.8671     0.8587     69.2153
07100     0.4529      0.8713     0.8587     67.5505
07200     0.4831      0.8460     0.8587     67.3893
07300     0.4670      0.8713     0.8587     69.7052
07400     0.4157      0.8755     0.8587     70.0080
07500     0.4629      0.8734     0.8587     67.5609
07600     0.5057      0.8586     0.8587     68.6197
07700     0.3954      0.8776     0.8587     67.8239
07800     0.4728      0.8734     0.8587     68.7986
07900     0.4392      0.8924     0.8587     67.5105
08000     0.4703      0.8544     0.8587     69.2752
08100     0.4193      0.8755     0.8587     68.4978
08200     0.4200      0.8840     0.8587     67.4739
08300     0.3999      0.8776     0.8587     68.6509
08400     0.4140      0.8861     0.8587     68.7278
08500     0.4886      0.8502     0.8587     68.6975
08600     0.4847      0.8544     0.8587     67.0398
08700     0.4275      0.8882     0.8587     68.8721
08800     0.4726      0.8629     0.8587     68.8588
08900     0.4214      0.8840     0.8587     68.6878
09000     0.4299      0.8755     0.8587     69.8126
09100     0.4067      0.8797     0.8587     67.4317
09200     0.4302      0.8755     0.8587     68.1148
09300     0.4582      0.8692     0.8587     69.0993
09400     0.4388      0.8629     0.8587     68.0610
09500     0.4382      0.8713     0.8587     67.6055
09600     0.4349      0.8776     0.8587     68.3731
09700     0.4279      0.8903     0.8587     68.2284
09800     0.4252      0.8671     0.8587     68.5250
09900     0.4715      0.8608     0.8587     69.6329
Start testing:
Test Accuracy: 0.8441
