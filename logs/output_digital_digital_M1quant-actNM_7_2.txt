Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=7, quant_actNM=7, quant_inp=7, quant_w=7, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
c68e46f3-5934-4d39-ab57-dd20f6ee2325
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=7, quant_actNM=7, quant_inp=7, quant_w=7, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
08e112b3-34ff-4f69-b087-a0a771080ef8
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=7, quant_actNM=7, quant_inp=7, quant_w=7, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
5f4fff8f-eafd-4a3b-aa31-b327712d38c5
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.6390      0.0612     0.0695     9.5513
00100     2.1888      0.2975     0.3068     56.3259
00200     1.6813      0.4641     0.4587     55.6352
00300     1.4143      0.5401     0.5311     55.9467
00400     1.3380      0.5717     0.5799     54.9976
00500     1.3014      0.5485     0.6127     55.1207
00600     1.1082      0.6498     0.6290     55.4176
00700     1.0978      0.6329     0.6567     55.5798
00800     1.0063      0.6857     0.6884     55.6091
00900     1.0011      0.6772     0.6884     54.5006
01000     0.8671      0.7511     0.6898     55.2392
01100     1.0336      0.6667     0.7025     56.1041
01200     1.0142      0.6751     0.7044     54.5220
01300     0.9399      0.6814     0.7134     57.3161
01400     0.9716      0.7131     0.7229     56.8462
01500     0.9603      0.6857     0.7284     55.3115
01600     0.8715      0.7236     0.7444     55.9208
01700     0.8398      0.7321     0.7444     56.4197
01800     0.7016      0.7616     0.7456     56.4758
01900     0.8341      0.7278     0.7456     55.0302
02000     0.9409      0.7089     0.7545     55.3522
02100     0.7768      0.7637     0.7548     56.3401
02200     0.9050      0.7278     0.7620     56.7793
02300     0.7866      0.7595     0.7627     54.9638
02400     0.7772      0.7300     0.7686     55.5531
02500     0.8506      0.7532     0.7820     55.1602
02600     0.8187      0.7468     0.7820     56.4518
02700     0.8365      0.7342     0.7820     56.3680
02800     0.7682      0.7553     0.7820     55.3749
02900     0.7121      0.7700     0.7820     55.0350
03000     0.7636      0.7257     0.7820     56.7854
03100     0.8031      0.7553     0.7820     55.9199
03200     0.8284      0.7236     0.7820     56.3337
03300     0.9641      0.6920     0.7820     56.2997
03400     0.8055      0.7405     0.7820     56.2138
03500     0.8102      0.7511     0.7820     56.3280
03600     0.7386      0.7511     0.7842     55.6671
03700     0.7667      0.7595     0.7842     54.8810
03800     0.6875      0.7700     0.7842     55.8092
03900     0.7064      0.7700     0.7862     54.6631
04000     0.7356      0.7764     0.7926     55.6249
04100     0.7730      0.7447     0.7926     55.2797
04200     0.7769      0.7595     0.7926     55.1559
04300     0.6658      0.7743     0.7926     55.3841
04400     0.7639      0.7384     0.7926     55.6002
04500     0.8089      0.7447     0.7926     54.4969
04600     0.7075      0.7637     0.7926     55.6717
04700     0.6469      0.7911     0.7933     55.4712
04800     0.6546      0.7911     0.7933     55.6097
04900     0.6972      0.7722     0.7971     55.0864
05000     0.7400      0.7532     0.7971     55.5217
05100     0.7165      0.7679     0.7971     56.7250
05200     0.6948      0.7848     0.7971     54.6449
05300     0.6801      0.7785     0.7971     56.1233
05400     0.7177      0.7806     0.7976     55.5721
05500     0.7741      0.7743     0.7976     56.3061
05600     0.7670      0.7426     0.8028     55.1431
05700     0.7069      0.7363     0.8028     55.4462
05800     0.7324      0.7532     0.8028     55.1253
05900     0.7726      0.7468     0.8028     56.1333
06000     0.6989      0.7468     0.8028     55.8634
06100     0.7178      0.7595     0.8028     55.3329
06200     0.7009      0.7827     0.8028     54.7800
06300     0.6947      0.7869     0.8028     55.3641
06400     0.7025      0.7595     0.8028     55.4515
06500     0.7208      0.7511     0.8028     55.2557
06600     0.6639      0.7785     0.8028     55.7359
06700     0.6690      0.7848     0.8028     56.1087
06800     0.7198      0.7658     0.8028     56.4050
06900     0.6735      0.7806     0.8041     54.9023
07000     0.6599      0.7743     0.8041     55.6899
07100     0.7529      0.7511     0.8044     55.9580
07200     0.6429      0.7996     0.8044     55.6569
07300     0.7363      0.7764     0.8044     54.8531
07400     0.5930      0.8186     0.8044     54.9989
07500     0.5862      0.8059     0.8044     56.4345
07600     0.6516      0.7848     0.8044     54.5602
07700     0.6547      0.7954     0.8075     55.0592
07800     0.6490      0.7890     0.8075     54.9485
07900     0.6793      0.7489     0.8075     55.4872
08000     0.6788      0.7574     0.8075     56.4648
08100     0.5575      0.8249     0.8125     56.5460
08200     0.6476      0.7764     0.8135     55.2453
08300     0.6268      0.8122     0.8135     56.6910
08400     0.6770      0.7595     0.8135     55.3057
08500     0.6482      0.7785     0.8148     55.6842
08600     0.6659      0.7700     0.8148     55.4744
08700     0.6355      0.7679     0.8148     56.6496
08800     0.7256      0.7785     0.8148     56.7499
08900     0.5627      0.8228     0.8148     55.7119
09000     0.5862      0.8143     0.8148     55.4317
09100     0.6059      0.8017     0.8148     55.7791
09200     0.6603      0.7911     0.8183     56.4302
09300     0.6985      0.7658     0.8183     56.2385
09400     0.7417      0.7679     0.8183     58.2589
09500     0.5697      0.8122     0.8183     56.6831
09600     0.6281      0.7975     0.8183     56.0845
09700     0.6028      0.8291     0.8183     55.3088
09800     0.6460      0.7595     0.8183     56.0451
09900     0.6581      0.7827     0.8183     56.7133
10000     0.6439      0.8038     0.8183     55.7770
10100     0.6734      0.7616     0.8183     55.4959
10200     0.5618      0.8122     0.8183     55.1056
10300     0.5884      0.8165     0.8183     55.9027
10400     0.5900      0.8165     0.8217     57.1523
10500     0.6084      0.7848     0.8217     56.9379
10600     0.5543      0.8207     0.8217     55.4489
10700     0.5786      0.8186     0.8217     55.2322
10800     0.6390      0.7911     0.8217     54.9586
10900     0.6523      0.8038     0.8217     55.3250
11000     0.6027      0.7954     0.8217     56.0855
11100     0.6151      0.7975     0.8222     55.5890
11200     0.5629      0.8143     0.8222     58.5731
11300     0.5917      0.7890     0.8222     55.3475
11400     0.5915      0.8186     0.8222     56.2633
11500     0.5837      0.8143     0.8260     55.3776
11600     0.6554      0.7658     0.8260     55.3471
11700     0.6234      0.7890     0.8260     55.2856
11800     0.6987      0.7700     0.8260     55.8072
11900     0.6092      0.8186     0.8260     55.1000
12000     0.5961      0.8207     0.8260     56.5819
12100     0.6795      0.7595     0.8260     55.8198
12200     0.5875      0.7975     0.8260     54.6900
12300     0.5961      0.8038     0.8260     56.4824
12400     0.6022      0.8143     0.8260     55.7202
12500     0.5897      0.8207     0.8260     57.7619
12600     0.6127      0.8165     0.8260     56.4265
12700     0.5966      0.7975     0.8260     54.8953
12800     0.6637      0.7806     0.8260     55.2200
12900     0.5879      0.8059     0.8260     55.2328
13000     0.6315      0.7890     0.8260     55.9890
13100     0.6965      0.7679     0.8260     56.7359
13200     0.5411      0.8165     0.8260     57.8841
13300     0.5839      0.8038     0.8260     54.9090
13400     0.6244      0.7827     0.8260     56.4161
13500     0.6798      0.7468     0.8281     55.0790
13600     0.6393      0.7932     0.8281     55.4855
13700     0.6497      0.7848     0.8281     55.5166
13800     0.6470      0.7932     0.8281     54.4375
13900     0.5244      0.8354     0.8281     56.4291
14000     0.6113      0.8059     0.8281     55.4571
14100     0.5924      0.7954     0.8281     54.9247
14200     0.6972      0.7806     0.8296     59.1777
14300     0.5568      0.8059     0.8296     54.7335
14400     0.5523      0.8312     0.8296     56.7783
14500     0.5936      0.7996     0.8296     55.1478
14600     0.5535      0.8059     0.8296     56.3394
14700     0.5753      0.8038     0.8296     56.0219
14800     0.5995      0.7975     0.8296     55.3628
14900     0.5908      0.8101     0.8296     54.4845
15000     0.5846      0.8059     0.8296     56.0536
15100     0.6078      0.8038     0.8296     54.7803
15200     0.6190      0.7954     0.8296     55.7351
15300     0.6226      0.7890     0.8296     55.2243
15400     0.6469      0.7700     0.8330     56.5207
15500     0.5743      0.8249     0.8330     56.1428
15600     0.5580      0.8059     0.8330     55.7166
15700     0.5837      0.8312     0.8330     55.1516
15800     0.5464      0.8460     0.8330     56.1794
15900     0.5663      0.8059     0.8330     56.4275
16000     0.6391      0.7827     0.8330     56.8631
16100     0.5913      0.7954     0.8330     56.5008
16200     0.5643      0.8017     0.8330     55.6774
16300     0.5794      0.8017     0.8330     55.5868
16400     0.6785      0.7806     0.8330     54.7916
16500     0.4930      0.8354     0.8330     55.8566
16600     0.5714      0.8143     0.8330     55.8962
16700     0.5399      0.8291     0.8330     55.2179
16800     0.6007      0.8017     0.8330     56.3581
16900     0.7292      0.7679     0.8330     55.1212
17000     0.6409      0.7890     0.8330     54.4472
17100     0.6090      0.8059     0.8330     55.3099
17200     0.6309      0.7954     0.8330     56.5181
17300     0.6122      0.8122     0.8330     55.9620
17400     0.6902      0.7743     0.8330     55.6870
17500     0.6084      0.7869     0.8330     55.2348
17600     0.6062      0.8059     0.8330     55.1758
17700     0.5395      0.8207     0.8330     55.8909
17800     0.7658      0.7616     0.8330     54.7177
17900     0.6775      0.7827     0.8330     55.7269
18000     0.5301      0.8376     0.8330     55.7764
18100     0.5608      0.8080     0.8330     54.8407
18200     0.5514      0.8249     0.8330     55.0586
18300     0.6528      0.7890     0.8330     58.6187
18400     0.5645      0.8249     0.8330     56.6962
18500     0.5808      0.8101     0.8330     55.2943
18600     0.5892      0.8270     0.8330     55.2920
18700     0.5779      0.8207     0.8330     58.0449
18800     0.6188      0.7954     0.8330     54.8126
18900     0.5942      0.8101     0.8330     56.6697
19000     0.5942      0.8017     0.8330     56.8988
19100     0.5980      0.8101     0.8330     55.9115
19200     0.6362      0.8038     0.8330     56.1934
19300     0.6408      0.7911     0.8330     55.5903
19400     0.6322      0.7890     0.8330     56.3446
19500     0.5850      0.8080     0.8330     56.1711
19600     0.6709      0.7764     0.8330     55.5434
19700     0.6564      0.7869     0.8330     57.2118
19800     0.7040      0.7679     0.8330     57.7479
19900     0.5389      0.8207     0.8330     56.7422
20000     0.7058      0.8017     0.8330     57.0103
20100     0.5909      0.8122     0.8330     56.2542
20199     0.6386      0.7932     0.8330     54.9934
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.5916      0.8143     0.8287     9.0600
00100     0.5040      0.8312     0.8307     55.4439
00200     0.5083      0.8460     0.8307     54.7923
00300     0.5174      0.8397     0.8307     53.4010
00400     0.5179      0.8333     0.8331     54.8904
00500     0.5286      0.8228     0.8331     55.7475
00600     0.4902      0.8418     0.8331     54.9827
00700     0.5448      0.8228     0.8331     55.4798
00800     0.5321      0.8080     0.8331     55.5532
00900     0.4963      0.8270     0.8331     55.3032
01000     0.4680      0.8544     0.8331     55.1888
01100     0.4346      0.8650     0.8331     56.0708
01200     0.4765      0.8523     0.8331     56.4247
01300     0.4927      0.8460     0.8331     54.9067
01400     0.5039      0.8270     0.8376     56.4119
01500     0.5149      0.8333     0.8376     55.2908
01600     0.4977      0.8502     0.8376     55.2300
01700     0.4770      0.8418     0.8376     57.0174
01800     0.4653      0.8713     0.8376     54.7867
01900     0.3805      0.8755     0.8376     55.4093
02000     0.5544      0.8228     0.8376     54.7644
02100     0.5047      0.8270     0.8384     55.0695
02200     0.4610      0.8523     0.8384     56.7704
02300     0.5474      0.8101     0.8384     55.3219
02400     0.4841      0.8397     0.8384     55.8405
02500     0.4916      0.8481     0.8384     56.3645
02600     0.4369      0.8544     0.8384     56.9469
02700     0.5650      0.8080     0.8384     55.4531
02800     0.4961      0.8439     0.8384     56.1479
02900     0.5320      0.8354     0.8433     55.4714
03000     0.5414      0.8228     0.8433     56.3196
03100     0.5206      0.8354     0.8433     55.8564
03200     0.5364      0.8481     0.8433     55.5408
03300     0.4519      0.8713     0.8433     56.1165
03400     0.5132      0.8270     0.8433     56.5364
03500     0.5494      0.8143     0.8433     56.7025
03600     0.5642      0.8038     0.8433     55.3272
03700     0.5533      0.8228     0.8433     55.9829
03800     0.5511      0.8249     0.8433     56.5919
03900     0.4667      0.8376     0.8433     56.4299
04000     0.4546      0.8650     0.8433     56.6740
04100     0.4986      0.8481     0.8433     55.8430
04200     0.4694      0.8650     0.8433     55.5362
04300     0.4828      0.8249     0.8433     55.4342
04400     0.4403      0.8650     0.8433     56.8845
04500     0.4965      0.8397     0.8433     55.0897
04600     0.5395      0.8249     0.8433     55.0857
04700     0.4952      0.8502     0.8433     55.6840
04800     0.5963      0.8038     0.8433     55.6092
04900     0.5611      0.8186     0.8433     55.8849
05000     0.4795      0.8608     0.8433     55.7867
05100     0.5483      0.8101     0.8433     56.1245
05200     0.4909      0.8418     0.8433     55.3113
05300     0.4997      0.8376     0.8433     55.9368
05400     0.5341      0.8207     0.8433     55.5217
05500     0.5810      0.8017     0.8433     55.4548
05600     0.5646      0.8207     0.8433     55.8856
05700     0.5187      0.8333     0.8433     56.0745
05800     0.5340      0.8312     0.8433     56.2475
05900     0.5293      0.8354     0.8433     56.0275
06000     0.4363      0.8481     0.8433     57.3375
06100     0.4474      0.8608     0.8433     55.3881
06200     0.4395      0.8565     0.8433     56.0228
06300     0.5513      0.8207     0.8433     56.5099
06400     0.4925      0.8397     0.8433     55.8963
06500     0.4487      0.8776     0.8433     56.1567
06600     0.5858      0.8080     0.8433     54.9340
06700     0.6227      0.7932     0.8433     55.6384
06800     0.4919      0.8565     0.8433     56.6643
06900     0.4917      0.8207     0.8433     56.5616
07000     0.5234      0.8333     0.8433     57.0442
07100     0.4919      0.8502     0.8433     56.6017
07200     0.5716      0.8186     0.8433     55.5446
07300     0.4931      0.8418     0.8433     56.6847
07400     0.5276      0.8333     0.8433     56.3514
07500     0.5027      0.8249     0.8433     58.2113
07600     0.4839      0.8312     0.8433     56.1955
07700     0.4650      0.8650     0.8433     55.8801
07800     0.6064      0.8080     0.8433     55.7386
07900     0.5326      0.8439     0.8433     56.7456
08000     0.4217      0.8544     0.8433     55.0120
08100     0.4873      0.8418     0.8433     56.4236
08200     0.4925      0.8544     0.8433     56.0116
08300     0.5179      0.8270     0.8433     58.1723
08400     0.5985      0.7996     0.8433     55.3280
08500     0.4960      0.8481     0.8433     56.7258
08600     0.4292      0.8523     0.8433     54.8340
08700     0.5069      0.8397     0.8433     54.4915
08800     0.4212      0.8671     0.8433     55.7275
08900     0.4743      0.8481     0.8433     55.8261
09000     0.5937      0.8165     0.8433     55.7927
09100     0.4775      0.8544     0.8433     56.2214
09200     0.4679      0.8502     0.8433     55.3289
09300     0.4943      0.8481     0.8433     55.2391
09400     0.5030      0.8333     0.8433     55.6145
09500     0.5303      0.8333     0.8433     56.4540
09600     0.5535      0.8249     0.8433     57.1007
09700     0.4905      0.8565     0.8433     55.1614
09800     0.5605      0.8122     0.8433     55.2764
09900     0.4137      0.8586     0.8433     58.2334
Start testing:
Test Accuracy: 0.8193
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
