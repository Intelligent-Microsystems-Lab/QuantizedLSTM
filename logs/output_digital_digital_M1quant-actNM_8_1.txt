Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
1308b658-a560-4fd9-9557-ca1d36dab46a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
1925c278-2ea7-47a4-86ba-8a9973ab16c2
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
94441624-ea17-4013-a005-5bc2adde6ac9
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.4708      0.1076     0.1339     11.3883
00100     2.2603      0.2384     0.2805     73.3748
00200     1.7041      0.4473     0.4592     72.4455
00300     1.4038      0.5464     0.5542     71.5149
00400     1.3148      0.5464     0.6171     72.9091
00500     1.1624      0.6435     0.6503     71.5051
00600     1.1384      0.6308     0.6870     72.3215
00700     0.9463      0.7046     0.7192     71.8236
00800     0.9627      0.6793     0.7349     73.1041
00900     0.9765      0.6857     0.7501     72.2701
01000     0.9052      0.7046     0.7641     72.5402
01100     0.8733      0.7194     0.7687     72.2976
01200     0.8281      0.7278     0.7687     72.3560
01300     0.8688      0.7173     0.7764     72.2215
01400     0.7768      0.7637     0.7813     72.3615
01500     0.7566      0.7658     0.7837     72.0523
01600     0.7493      0.7658     0.7837     72.2756
01700     0.8511      0.7321     0.7890     72.2715
01800     0.7296      0.7806     0.7910     72.2298
01900     0.6849      0.7827     0.7958     72.5849
02000     0.7769      0.7511     0.7958     72.2234
02100     0.7906      0.7511     0.7981     72.4269
02200     0.7582      0.7489     0.7981     72.1146
02300     0.7528      0.7616     0.7981     73.0420
02400     0.6871      0.7848     0.8077     71.7693
02500     0.6334      0.7827     0.8077     72.4673
02600     0.6146      0.8080     0.8121     73.4305
02700     0.7229      0.7722     0.8157     72.5076
02800     0.6435      0.7954     0.8157     72.0522
02900     0.7328      0.7616     0.8157     72.6095
03000     0.6313      0.7764     0.8157     72.0585
03100     0.7299      0.7806     0.8157     72.0173
03200     0.7013      0.7679     0.8157     72.6345
03300     0.7204      0.7764     0.8157     71.4053
03400     0.6395      0.7869     0.8157     72.3300
03500     0.7069      0.7743     0.8157     72.5201
03600     0.6255      0.8038     0.8157     72.4780
03700     0.6471      0.7954     0.8157     72.3282
03800     0.7010      0.7700     0.8172     72.1477
03900     0.5981      0.8207     0.8172     72.3017
04000     0.6507      0.8017     0.8172     74.0662
04100     0.6581      0.7890     0.8226     71.6963
04200     0.6147      0.8101     0.8226     72.0010
04300     0.6020      0.8207     0.8226     72.1399
04400     0.5731      0.8249     0.8227     72.2290
04500     0.6192      0.7996     0.8227     71.8796
04600     0.5767      0.8249     0.8227     72.8047
04700     0.6403      0.8017     0.8227     72.5195
04800     0.6355      0.8143     0.8227     72.2864
04900     0.6347      0.7996     0.8227     71.6392
05000     0.6238      0.8059     0.8227     71.8881
05100     0.5682      0.8186     0.8227     72.6159
05200     0.6385      0.7911     0.8227     72.7149
05300     0.5599      0.8038     0.8227     72.1051
05400     0.5818      0.8186     0.8227     72.9371
05500     0.5671      0.8017     0.8249     72.7852
05600     0.5856      0.8017     0.8292     72.4554
05700     0.6072      0.8059     0.8292     72.3238
05800     0.5741      0.8186     0.8292     74.0237
05900     0.5435      0.8228     0.8292     72.9293
06000     0.5473      0.8207     0.8292     71.8025
06100     0.6097      0.7975     0.8292     72.6290
06200     0.6220      0.8017     0.8292     73.8082
06300     0.5824      0.8080     0.8292     72.1646
06400     0.6003      0.8017     0.8298     72.3883
06500     0.5956      0.8143     0.8298     73.1723
06600     0.5126      0.8586     0.8298     73.6264
06700     0.5723      0.8312     0.8298     72.8421
06800     0.6561      0.7806     0.8298     72.5162
06900     0.5843      0.8080     0.8352     71.8757
07000     0.5046      0.8249     0.8352     72.9669
07100     0.5066      0.8397     0.8352     71.9357
07200     0.5977      0.7890     0.8352     73.4988
07300     0.5634      0.8228     0.8352     73.0879
07400     0.5141      0.8439     0.8352     73.3721
07500     0.6246      0.8059     0.8357     72.8179
07600     0.5601      0.8249     0.8357     71.8699
07700     0.5380      0.8207     0.8357     72.7288
07800     0.5174      0.8312     0.8402     71.6661
07900     0.5104      0.8502     0.8402     71.7869
08000     0.6353      0.7932     0.8402     72.7845
08100     0.5283      0.8502     0.8402     71.7155
08200     0.4854      0.8397     0.8402     72.9419
08300     0.6399      0.8165     0.8402     72.4787
08400     0.5421      0.8186     0.8402     72.1314
08500     0.6667      0.7975     0.8402     73.4877
08600     0.5622      0.8186     0.8431     72.4691
08700     0.5389      0.8376     0.8431     72.5627
08800     0.5674      0.8333     0.8431     73.4268
08900     0.5218      0.8397     0.8431     71.3142
09000     0.5687      0.8291     0.8431     70.9430
09100     0.5214      0.8270     0.8431     72.4374
09200     0.5566      0.8080     0.8431     72.2629
09300     0.6162      0.8101     0.8431     72.6552
09400     0.5264      0.8291     0.8431     72.9954
09500     0.5571      0.8080     0.8454     71.9823
09600     0.5488      0.8312     0.8454     72.7482
09700     0.5116      0.8291     0.8454     72.4043
09800     0.4297      0.8565     0.8454     72.1394
09900     0.5937      0.8017     0.8454     71.7671
10000     0.5412      0.8186     0.8454     71.8884
10100     0.5647      0.8207     0.8454     72.7522
10200     0.4881      0.8397     0.8454     73.6795
10300     0.5007      0.8439     0.8454     73.5582
10400     0.5238      0.8270     0.8454     73.0337
10500     0.4758      0.8460     0.8454     72.7074
10600     0.5712      0.8207     0.8454     71.8940
10700     0.5189      0.8439     0.8471     72.3028
10800     0.5362      0.8397     0.8471     72.8138
10900     0.5084      0.8291     0.8471     72.2954
11000     0.5288      0.8122     0.8484     72.5560
11100     0.5429      0.8122     0.8484     72.8570
11200     0.5635      0.8143     0.8484     73.3308
11300     0.5013      0.8439     0.8484     72.6086
11400     0.4166      0.8629     0.8484     71.9516
11500     0.5644      0.8207     0.8490     72.4144
11600     0.4904      0.8608     0.8490     72.7429
11700     0.4902      0.8418     0.8490     72.5931
11800     0.4684      0.8376     0.8490     72.6222
11900     0.5299      0.8122     0.8490     72.1910
12000     0.4947      0.8460     0.8490     72.2593
12100     0.5369      0.8397     0.8490     72.6085
12200     0.4719      0.8565     0.8490     72.7520
12300     0.5589      0.8270     0.8490     73.0937
12400     0.5160      0.8439     0.8490     71.8998
12500     0.5210      0.8376     0.8490     73.3173
12600     0.4704      0.8502     0.8490     73.8018
12700     0.5837      0.7996     0.8490     72.2571
12800     0.5129      0.8312     0.8490     72.3546
12900     0.4405      0.8565     0.8490     72.8035
13000     0.4870      0.8671     0.8508     72.2752
13100     0.5216      0.8249     0.8521     72.5102
13200     0.4591      0.8502     0.8521     72.0466
13300     0.5076      0.8418     0.8521     71.7465
13400     0.4801      0.8713     0.8521     72.6120
13500     0.5480      0.8122     0.8521     73.5561
13600     0.5176      0.8291     0.8521     71.1997
13700     0.4918      0.8291     0.8521     71.1473
13800     0.4912      0.8565     0.8521     72.1863
13900     0.4926      0.8397     0.8521     74.5295
14000     0.5401      0.8186     0.8521     71.4364
14100     0.4668      0.8376     0.8524     74.3172
14200     0.4457      0.8713     0.8524     72.8388
14300     0.5362      0.8376     0.8524     72.3630
14400     0.5042      0.8354     0.8524     72.0917
14500     0.4410      0.8565     0.8524     71.9048
14600     0.4761      0.8544     0.8524     72.2816
14700     0.5108      0.8376     0.8524     72.3627
14800     0.4261      0.8629     0.8524     71.9499
14900     0.5733      0.8333     0.8524     72.1362
15000     0.4500      0.8523     0.8524     72.1282
15100     0.5771      0.8122     0.8524     73.1302
15200     0.5070      0.8333     0.8524     72.6611
15300     0.5327      0.8291     0.8524     72.5404
15400     0.5018      0.8397     0.8524     72.7558
15500     0.5429      0.8080     0.8524     72.1235
15600     0.4825      0.8397     0.8524     71.9641
15700     0.5318      0.8270     0.8524     72.7637
15800     0.4980      0.8207     0.8524     72.5560
15900     0.6155      0.8143     0.8524     71.8586
16000     0.4344      0.8565     0.8524     72.1183
16100     0.4331      0.8629     0.8524     72.7861
16200     0.4635      0.8439     0.8524     72.6741
16300     0.5287      0.8312     0.8535     71.5972
16400     0.4736      0.8376     0.8535     72.7113
16500     0.4878      0.8397     0.8535     72.8186
16600     0.4668      0.8397     0.8535     71.8540
16700     0.4049      0.8586     0.8535     72.5608
16800     0.4656      0.8586     0.8535     73.5388
16900     0.4629      0.8544     0.8535     72.2278
17000     0.5167      0.8397     0.8535     73.8103
17100     0.4906      0.8397     0.8535     72.4783
17200     0.4565      0.8629     0.8535     71.8026
17300     0.5171      0.8460     0.8535     72.2990
17400     0.4978      0.8418     0.8536     71.9471
17500     0.5447      0.8207     0.8551     72.9443
17600     0.4240      0.8671     0.8551     72.5627
17700     0.4474      0.8544     0.8551     71.7870
17800     0.4563      0.8460     0.8551     73.1801
17900     0.4928      0.8439     0.8551     72.0738
18000     0.4330      0.8586     0.8551     71.6330
18100     0.4702      0.8354     0.8551     72.1542
18200     0.4868      0.8523     0.8551     72.4545
18300     0.4824      0.8502     0.8551     71.8961
18400     0.4819      0.8376     0.8551     71.6737
18500     0.4455      0.8544     0.8551     71.6760
18600     0.5606      0.8270     0.8560     72.7133
18700     0.4711      0.8544     0.8560     72.3093
18800     0.4974      0.8228     0.8560     72.5521
18900     0.5293      0.8186     0.8560     73.5973
19000     0.4684      0.8565     0.8602     72.0431
19100     0.4141      0.8755     0.8602     71.5512
19200     0.5471      0.8228     0.8602     72.6464
19300     0.4561      0.8734     0.8602     72.4420
19400     0.5303      0.8249     0.8602     72.4952
19500     0.5371      0.8249     0.8602     71.9431
19600     0.5548      0.8080     0.8602     71.7871
19700     0.4501      0.8586     0.8602     72.1996
19800     0.5398      0.8270     0.8602     72.2021
19900     0.4638      0.8439     0.8602     72.2440
20000     0.4620      0.8586     0.8602     73.1355
20100     0.4487      0.8439     0.8602     72.0734
20199     0.4369      0.8713     0.8602     71.4554
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.3706      0.8819     0.8569     11.3745
00100     0.4476      0.8523     0.8569     73.2339
00200     0.4726      0.8692     0.8606     72.9883
00300     0.3849      0.8755     0.8606     73.0120
00400     0.4384      0.8586     0.8606     70.9048
00500     0.4170      0.8650     0.8606     72.4012
00600     0.4013      0.8650     0.8606     71.5354
00700     0.3703      0.8966     0.8606     72.5981
00800     0.4236      0.8586     0.8606     73.3515
00900     0.3914      0.8650     0.8606     73.2760
01000     0.4062      0.8671     0.8606     71.5694
01100     0.3770      0.8840     0.8606     71.3879
01200     0.3690      0.8713     0.8606     72.2529
01300     0.4152      0.8713     0.8606     72.4580
01400     0.3866      0.8734     0.8606     71.3164
01500     0.4095      0.8734     0.8619     72.4549
01600     0.3932      0.8734     0.8619     72.0115
01700     0.4404      0.8586     0.8619     71.8758
01800     0.4270      0.8586     0.8619     72.3360
01900     0.4755      0.8586     0.8619     71.5889
02000     0.3928      0.8692     0.8619     71.1592
02100     0.4074      0.8650     0.8619     71.2783
02200     0.4045      0.8797     0.8619     71.5920
02300     0.4114      0.8692     0.8619     72.9175
02400     0.4596      0.8608     0.8619     71.6042
02500     0.4167      0.8713     0.8619     72.7032
02600     0.4736      0.8460     0.8619     72.4306
02700     0.4802      0.8439     0.8619     72.0654
02800     0.4222      0.8586     0.8619     72.0897
02900     0.3892      0.8819     0.8619     72.0910
03000     0.3996      0.8776     0.8619     72.5152
03100     0.4384      0.8502     0.8619     72.4424
03200     0.3883      0.8671     0.8619     73.7044
03300     0.3765      0.8861     0.8619     72.6109
03400     0.3782      0.9008     0.8619     71.8200
03500     0.4098      0.8713     0.8619     71.5337
03600     0.3983      0.8840     0.8619     72.1488
03700     0.4156      0.8776     0.8619     71.9685
03800     0.4214      0.8819     0.8619     71.2779
03900     0.4531      0.8586     0.8619     71.3773
04000     0.4062      0.8629     0.8619     71.1703
04100     0.3927      0.8819     0.8619     74.5079
04200     0.4074      0.8713     0.8619     74.2525
04300     0.3750      0.8882     0.8619     72.2989
04400     0.3755      0.8903     0.8619     73.9809
04500     0.4098      0.8713     0.8619     72.5200
04600     0.3993      0.8671     0.8619     71.9762
04700     0.4738      0.8439     0.8619     72.1742
04800     0.3701      0.9008     0.8619     73.7697
04900     0.4157      0.8629     0.8619     72.0175
05000     0.3790      0.8692     0.8619     72.6951
05100     0.4457      0.8713     0.8619     72.4410
05200     0.4093      0.8713     0.8619     71.7447
05300     0.3876      0.8776     0.8619     72.2661
05400     0.4549      0.8544     0.8619     71.8625
05500     0.4278      0.8650     0.8619     72.9956
05600     0.3501      0.8819     0.8619     72.1817
05700     0.4225      0.8671     0.8619     71.8914
05800     0.3709      0.8840     0.8619     71.7354
05900     0.4056      0.8650     0.8619     69.8065
06000     0.4477      0.8439     0.8619     72.6783
06100     0.4131      0.8734     0.8619     73.4613
06200     0.3973      0.8692     0.8619     73.1194
06300     0.3954      0.8734     0.8619     71.7063
06400     0.3821      0.8586     0.8619     72.0884
06500     0.3375      0.9008     0.8619     72.1218
06600     0.3776      0.8924     0.8619     72.9552
06700     0.4010      0.8776     0.8619     72.3687
06800     0.4552      0.8565     0.8619     72.4607
06900     0.3788      0.8861     0.8619     71.7347
07000     0.3708      0.8819     0.8619     71.4244
07100     0.4751      0.8312     0.8619     72.9607
07200     0.4621      0.8460     0.8619     72.8509
07300     0.4219      0.8629     0.8619     72.0237
07400     0.4753      0.8544     0.8619     72.6959
07500     0.4068      0.8776     0.8619     73.5485
07600     0.3459      0.8966     0.8619     72.6658
07700     0.4138      0.8819     0.8619     72.4742
07800     0.3206      0.9051     0.8619     71.9607
07900     0.3692      0.8755     0.8619     72.1386
08000     0.4564      0.8523     0.8619     72.4779
08100     0.4320      0.8692     0.8619     71.5339
08200     0.3695      0.8861     0.8619     72.8318
08300     0.4344      0.8734     0.8619     73.3245
08400     0.4093      0.8650     0.8619     73.1385
08500     0.4743      0.8481     0.8619     72.0531
08600     0.4450      0.8734     0.8619     72.9376
08700     0.4067      0.8586     0.8619     71.8094
08800     0.3926      0.8734     0.8619     72.7712
08900     0.4268      0.8608     0.8619     71.1808
09000     0.4037      0.8734     0.8619     72.6370
09100     0.3989      0.8861     0.8619     71.9714
09200     0.4193      0.8692     0.8619     71.6074
09300     0.4365      0.8544     0.8619     72.4431
09400     0.4670      0.8523     0.8619     73.0193
09500     0.4338      0.8734     0.8619     73.5369
09600     0.4359      0.8544     0.8619     74.3083
09700     0.3447      0.8966     0.8619     72.3333
09800     0.4502      0.8544     0.8619     72.6718
09900     0.4214      0.8565     0.8619     72.6951
Start testing:
Test Accuracy: 0.8407
