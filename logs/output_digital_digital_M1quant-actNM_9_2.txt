Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
893457ca-837c-4468-a928-32db243cad37
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
4c786b33-1409-443c-b9b0-4376e877b6a6
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
79720df3-0a4b-43b1-b4c4-573ad4de07e5
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.5850      0.0612     0.0669     11.1898
00100     2.0694      0.3354     0.3461     74.2666
00200     1.5604      0.4789     0.5052     74.3441
00300     1.3236      0.5696     0.5828     74.3540
00400     1.1864      0.6266     0.6345     74.6375
00500     1.1266      0.6308     0.6720     73.0033
00600     0.9321      0.7110     0.6938     73.0179
00700     0.9540      0.7046     0.7175     75.0688
00800     0.8797      0.7278     0.7235     75.3509
00900     0.9073      0.7257     0.7407     75.2083
01000     0.7894      0.7637     0.7407     73.9829
01100     0.8430      0.7278     0.7416     74.5132
01200     0.8571      0.7173     0.7619     73.0682
01300     0.8381      0.7363     0.7638     75.9534
01400     0.8109      0.7532     0.7791     74.0058
01500     0.7997      0.7468     0.7791     74.7404
01600     0.8163      0.7321     0.7791     73.1750
01700     0.6821      0.7848     0.7830     73.8951
01800     0.6414      0.7827     0.7830     73.7054
01900     0.7081      0.7743     0.7927     73.5508
02000     0.7359      0.7679     0.7927     74.5452
02100     0.6621      0.7911     0.7943     73.4968
02200     0.7833      0.7511     0.7978     75.5347
02300     0.6578      0.7975     0.7978     74.9892
02400     0.6463      0.8143     0.7978     74.2832
02500     0.6991      0.7679     0.7978     72.7041
02600     0.6892      0.7869     0.7978     73.1745
02700     0.7117      0.7785     0.7978     75.0615
02800     0.7023      0.7722     0.8080     75.6975
02900     0.6649      0.7827     0.8080     74.7677
03000     0.6495      0.7890     0.8138     72.3054
03100     0.6533      0.7848     0.8138     75.6528
03200     0.6508      0.7932     0.8138     73.7287
03300     0.7621      0.7468     0.8138     75.0012
03400     0.6258      0.8080     0.8145     73.4151
03500     0.6930      0.7975     0.8145     71.6076
03600     0.6602      0.7932     0.8145     72.4865
03700     0.6544      0.7932     0.8177     73.3241
03800     0.6257      0.7996     0.8186     73.8547
03900     0.5712      0.8291     0.8186     72.6502
04000     0.6587      0.7954     0.8186     73.6625
04100     0.6650      0.7679     0.8186     74.4841
04200     0.6662      0.7785     0.8186     70.4916
04300     0.6165      0.7954     0.8186     74.1975
04400     0.6273      0.7911     0.8186     72.3843
04500     0.6873      0.7890     0.8186     72.6730
04600     0.6241      0.8101     0.8186     74.2541
04700     0.5960      0.8249     0.8186     73.7280
04800     0.6063      0.7996     0.8191     73.5268
04900     0.7020      0.7890     0.8191     72.6281
05000     0.6705      0.7890     0.8191     74.1172
05100     0.5433      0.8207     0.8191     73.2866
05200     0.6306      0.8101     0.8191     74.4062
05300     0.5341      0.8376     0.8191     74.2009
05400     0.6028      0.8122     0.8246     73.0063
05500     0.7170      0.7743     0.8246     72.4724
05600     0.6769      0.7848     0.8246     72.2554
05700     0.6247      0.7954     0.8246     73.5351
05800     0.6046      0.8122     0.8246     73.1457
05900     0.6421      0.8059     0.8246     73.9852
06000     0.5472      0.8291     0.8246     74.0317
06100     0.6213      0.8059     0.8246     73.5699
06200     0.5780      0.8101     0.8246     74.6321
06300     0.6182      0.7975     0.8304     75.2129
06400     0.6145      0.7911     0.8304     75.7439
06500     0.5694      0.8291     0.8304     73.7814
06600     0.5484      0.8186     0.8304     73.0461
06700     0.5380      0.8460     0.8304     73.5096
06800     0.6375      0.8038     0.8304     73.6897
06900     0.5252      0.8354     0.8304     72.7938
07000     0.5958      0.8080     0.8304     74.1978
07100     0.6317      0.7911     0.8336     73.8255
07200     0.6241      0.8080     0.8336     73.8452
07300     0.6726      0.7975     0.8336     73.2752
07400     0.5152      0.8228     0.8336     75.0316
07500     0.5097      0.8249     0.8336     73.5740
07600     0.5517      0.8291     0.8336     74.3696
07700     0.6052      0.8165     0.8336     73.0590
07800     0.5812      0.8143     0.8336     73.7751
07900     0.5638      0.8059     0.8336     71.6668
08000     0.5891      0.7975     0.8336     72.1723
08100     0.4978      0.8502     0.8336     73.0052
08200     0.5462      0.8270     0.8336     75.4287
08300     0.6355      0.7975     0.8336     72.0898
08400     0.5863      0.8080     0.8336     73.6151
08500     0.5413      0.8207     0.8337     73.6730
08600     0.5512      0.8122     0.8337     72.2303
08700     0.5170      0.8333     0.8337     71.6086
08800     0.6043      0.7869     0.8337     74.5111
08900     0.4873      0.8333     0.8337     74.5650
09000     0.5505      0.8059     0.8337     75.5242
09100     0.5082      0.8565     0.8337     73.4162
09200     0.5818      0.8207     0.8337     76.1612
09300     0.5301      0.8143     0.8337     74.7022
09400     0.6002      0.8080     0.8337     72.6995
09500     0.4466      0.8586     0.8337     72.6838
09600     0.5495      0.8376     0.8337     71.9459
09700     0.5300      0.8397     0.8337     71.5088
09800     0.6070      0.8038     0.8337     74.3263
09900     0.5028      0.8354     0.8337     73.0217
10000     0.5248      0.8397     0.8337     73.6603
10100     0.5426      0.8228     0.8337     73.8991
10200     0.4920      0.8418     0.8339     75.0258
10300     0.5169      0.8270     0.8339     73.1809
10400     0.4898      0.8502     0.8372     74.5862
10500     0.5215      0.8354     0.8372     75.5095
10600     0.5068      0.8460     0.8372     74.3815
10700     0.4751      0.8586     0.8372     72.0126
10800     0.5537      0.8249     0.8379     73.1082
10900     0.5770      0.7996     0.8379     74.2504
11000     0.5434      0.8312     0.8379     74.6379
11100     0.5858      0.8122     0.8379     74.9296
11200     0.4662      0.8418     0.8420     73.6280
11300     0.4564      0.8650     0.8420     74.4656
11400     0.4938      0.8523     0.8420     73.5302
11500     0.4351      0.8776     0.8420     74.0425
11600     0.5138      0.8418     0.8420     73.3598
11700     0.5373      0.8017     0.8420     73.3578
11800     0.5919      0.7975     0.8420     71.9924
11900     0.5371      0.8270     0.8420     72.3120
12000     0.5096      0.8333     0.8432     75.7689
12100     0.5451      0.8270     0.8432     74.5325
12200     0.4931      0.8460     0.8432     72.2659
12300     0.4473      0.8439     0.8432     73.9984
12400     0.5031      0.8291     0.8432     73.9266
12500     0.4775      0.8523     0.8432     71.8688
12600     0.4972      0.8481     0.8432     73.1654
12700     0.4652      0.8650     0.8432     74.5128
12800     0.5058      0.8439     0.8432     72.7870
12900     0.4841      0.8586     0.8432     75.0145
13000     0.5201      0.8481     0.8432     74.0002
13100     0.5746      0.7954     0.8432     75.2046
13200     0.5044      0.8312     0.8432     73.3391
13300     0.5083      0.8376     0.8432     72.0624
13400     0.5397      0.8017     0.8432     74.8659
13500     0.5574      0.8228     0.8432     73.6917
13600     0.5327      0.8333     0.8432     74.3571
13700     0.5602      0.8186     0.8432     73.4911
13800     0.5218      0.8333     0.8432     75.2171
13900     0.4252      0.8734     0.8432     72.4649
14000     0.4928      0.8333     0.8432     72.4913
14100     0.4939      0.8354     0.8432     74.4320
14200     0.6048      0.8017     0.8432     74.7967
14300     0.4349      0.8523     0.8432     73.4441
14400     0.4679      0.8650     0.8432     75.1968
14500     0.5082      0.8502     0.8432     74.3610
14600     0.4797      0.8481     0.8432     73.5178
14700     0.5294      0.8080     0.8432     74.2459
14800     0.4899      0.8376     0.8432     73.8232
14900     0.5028      0.8397     0.8432     73.2353
15000     0.5149      0.8333     0.8432     72.7444
15100     0.4773      0.8544     0.8432     73.6492
15200     0.5359      0.8186     0.8432     73.2505
15300     0.4914      0.8270     0.8432     72.6582
15400     0.4891      0.8397     0.8432     73.3484
15500     0.4637      0.8376     0.8432     73.6497
15600     0.5244      0.8270     0.8432     75.7209
15700     0.4695      0.8523     0.8432     73.1355
15800     0.3967      0.8882     0.8432     74.9461
15900     0.4772      0.8312     0.8432     73.2273
16000     0.4903      0.8397     0.8449     73.9814
16100     0.5034      0.8333     0.8449     73.0340
16200     0.5130      0.8354     0.8449     72.9385
16300     0.5081      0.8291     0.8449     73.9045
16400     0.6145      0.8186     0.8449     74.8370
16500     0.4048      0.8671     0.8449     72.7541
16600     0.4573      0.8565     0.8449     72.5554
16700     0.4829      0.8312     0.8449     75.9415
16800     0.5107      0.8376     0.8449     73.9456
16900     0.5892      0.8017     0.8449     75.2951
17000     0.5613      0.8270     0.8449     73.4168
17100     0.4927      0.8460     0.8449     75.5953
17200     0.4865      0.8565     0.8449     73.8252
17300     0.4802      0.8544     0.8449     73.1300
17400     0.5446      0.8186     0.8449     73.1779
17500     0.5409      0.8165     0.8449     73.7031
17600     0.5433      0.8143     0.8449     77.6629
17700     0.5087      0.8418     0.8449     74.4443
17800     0.5521      0.8186     0.8449     73.2792
17900     0.5331      0.8165     0.8449     71.5455
18000     0.4840      0.8312     0.8449     72.1774
18100     0.5732      0.8312     0.8449     73.7492
18200     0.4187      0.8734     0.8449     73.4649
18300     0.5869      0.8228     0.8449     73.3398
18400     0.4375      0.8565     0.8449     74.8489
18500     0.4644      0.8376     0.8449     75.1809
18600     0.4970      0.8439     0.8449     73.7779
18700     0.4922      0.8439     0.8455     74.2558
18800     0.5158      0.8312     0.8455     73.2791
18900     0.5220      0.8376     0.8455     73.2297
19000     0.4790      0.8481     0.8455     73.5005
19100     0.4946      0.8418     0.8464     73.1529
19200     0.5433      0.8101     0.8464     73.5879
19300     0.5343      0.8312     0.8464     73.4363
19400     0.5069      0.8397     0.8464     73.0249
19500     0.4680      0.8544     0.8476     74.5677
19600     0.5400      0.8186     0.8476     74.0179
19700     0.5408      0.8312     0.8476     72.6846
19800     0.6207      0.8017     0.8476     74.0677
19900     0.4498      0.8734     0.8476     73.4638
20000     0.5462      0.8312     0.8476     73.1757
20100     0.5165      0.8439     0.8476     74.5353
20199     0.6130      0.8122     0.8476     72.3654
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4749      0.8418     0.8429     9.8748
00100     0.3970      0.8734     0.8465     73.0491
00200     0.4133      0.8713     0.8465     74.8264
00300     0.4201      0.8608     0.8465     74.7415
00400     0.4235      0.8650     0.8482     73.7376
00500     0.4094      0.8713     0.8482     74.4023
00600     0.4141      0.8523     0.8482     72.6796
00700     0.4110      0.8650     0.8496     74.5357
00800     0.4453      0.8502     0.8496     71.8382
00900     0.4682      0.8671     0.8496     73.5393
01000     0.3877      0.8713     0.8497     73.1395
01100     0.3955      0.8755     0.8526     74.2855
01200     0.4111      0.8755     0.8526     73.0963
01300     0.3976      0.8692     0.8526     76.4050
01400     0.4283      0.8481     0.8526     76.3262
01500     0.3908      0.8861     0.8526     75.3380
01600     0.4341      0.8544     0.8526     73.8033
01700     0.4340      0.8586     0.8526     74.6639
01800     0.4045      0.8776     0.8526     73.0618
01900     0.3327      0.9008     0.8526     74.5119
02000     0.5143      0.8249     0.8526     75.1783
02100     0.4262      0.8755     0.8526     73.2353
02200     0.3627      0.8945     0.8526     74.1051
02300     0.4154      0.8671     0.8526     73.4905
02400     0.4038      0.8692     0.8526     76.0983
02500     0.4302      0.8544     0.8531     75.6240
02600     0.3909      0.8734     0.8531     72.7550
02700     0.4763      0.8354     0.8531     76.0503
02800     0.4407      0.8819     0.8531     73.8567
02900     0.3957      0.8671     0.8531     73.0047
03000     0.4495      0.8692     0.8531     74.6661
03100     0.4008      0.8903     0.8531     75.4057
03200     0.4108      0.8819     0.8531     74.2651
03300     0.3974      0.8734     0.8531     72.5669
03400     0.4345      0.8713     0.8531     72.4935
03500     0.4371      0.8460     0.8531     75.6586
03600     0.4288      0.8608     0.8531     72.3743
03700     0.4488      0.8565     0.8531     73.2040
03800     0.4357      0.8565     0.8531     73.9777
03900     0.4188      0.8734     0.8531     73.4231
04000     0.4049      0.8713     0.8531     74.5675
04100     0.4068      0.8692     0.8531     74.4266
04200     0.4045      0.8797     0.8531     73.4115
04300     0.3959      0.8776     0.8531     72.0132
04400     0.3843      0.8650     0.8531     72.9555
04500     0.4352      0.8565     0.8531     71.9598
04600     0.4119      0.8608     0.8531     72.6361
04700     0.4111      0.8608     0.8531     73.4540
04800     0.4540      0.8523     0.8531     73.1850
04900     0.4087      0.8840     0.8531     74.6003
05000     0.4190      0.8819     0.8531     72.5008
05100     0.4589      0.8460     0.8531     77.2645
05200     0.4520      0.8565     0.8531     72.4103
05300     0.3925      0.8861     0.8531     72.6584
05400     0.3995      0.8671     0.8531     74.6780
05500     0.4598      0.8671     0.8531     72.9147
05600     0.4613      0.8460     0.8531     73.1895
05700     0.3829      0.8797     0.8531     73.6038
05800     0.4546      0.8565     0.8531     73.1617
05900     0.4093      0.8776     0.8531     75.6226
06000     0.3549      0.8987     0.8531     74.2430
06100     0.4125      0.8776     0.8531     73.1185
06200     0.3794      0.8797     0.8531     73.2932
06300     0.4180      0.8586     0.8531     73.6795
06400     0.4019      0.8586     0.8531     73.0717
06500     0.3806      0.8797     0.8531     73.8570
06600     0.4527      0.8734     0.8531     71.9796
06700     0.4473      0.8354     0.8531     73.3412
06800     0.4077      0.8565     0.8531     75.9198
06900     0.3757      0.8945     0.8531     74.5310
07000     0.4239      0.8692     0.8531     75.8667
07100     0.4490      0.8692     0.8531     76.0180
07200     0.4616      0.8333     0.8531     74.0823
07300     0.3498      0.8840     0.8531     73.2524
07400     0.4106      0.8608     0.8531     73.7070
07500     0.4023      0.8840     0.8531     73.8873
07600     0.3953      0.8692     0.8531     72.6287
07700     0.3992      0.8713     0.8531     73.8167
07800     0.4687      0.8460     0.8531     75.1833
07900     0.4238      0.8629     0.8531     75.1875
08000     0.3826      0.8882     0.8531     74.1253
08100     0.3641      0.8903     0.8531     73.6583
08200     0.4065      0.8692     0.8531     72.7519
08300     0.4046      0.8692     0.8531     73.6155
08400     0.5090      0.8354     0.8531     73.9232
08500     0.3845      0.8882     0.8531     73.8353
08600     0.3366      0.8797     0.8531     72.5916
08700     0.3975      0.8734     0.8531     72.9841
08800     0.3453      0.8945     0.8531     76.3380
08900     0.3565      0.8987     0.8531     74.0843
09000     0.4387      0.8819     0.8531     73.1527
09100     0.4083      0.8586     0.8531     73.9250
09200     0.3780      0.8882     0.8531     73.0082
09300     0.3819      0.8755     0.8531     72.4990
09400     0.3940      0.8671     0.8531     72.1740
09500     0.4513      0.8460     0.8531     73.9821
09600     0.4642      0.8481     0.8531     73.0053
09700     0.4273      0.8713     0.8531     73.6978
09800     0.4626      0.8608     0.8531     72.1729
09900     0.3905      0.8903     0.8531     74.0635
Start testing:
Test Accuracy: 0.8264
