Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=7, quant_actNM=7, quant_inp=7, quant_w=7, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
5b7c69f6-daf7-4c91-928e-f98a1ffed0ef
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=7, quant_actNM=7, quant_inp=7, quant_w=7, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
ba47d6a7-475c-457d-841c-60c5cfb7be36
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=7, quant_actNM=7, quant_inp=7, quant_w=7, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
7edbad37-f20d-46b5-aa3e-08341419561a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.6948      0.0970     0.0818     9.7103
00100     2.3461      0.2616     0.2557     54.0513
00200     1.8442      0.3734     0.4548     54.4981
00300     1.4041      0.5570     0.5670     55.1059
00400     1.4744      0.5527     0.5967     55.1135
00500     1.2580      0.6055     0.6370     54.6480
00600     1.1850      0.6329     0.6626     54.8882
00700     1.0315      0.6983     0.6714     55.0791
00800     1.0343      0.6857     0.6978     54.9464
00900     0.9512      0.7110     0.7218     54.1370
01000     1.0244      0.6899     0.7257     55.1500
01100     0.9340      0.7363     0.7257     55.9215
01200     0.9407      0.7278     0.7262     54.6067
01300     0.8288      0.7658     0.7418     55.3216
01400     0.9127      0.7215     0.7439     55.8136
01500     0.7878      0.7637     0.7439     55.1085
01600     0.9008      0.7194     0.7517     54.6869
01700     0.9532      0.7025     0.7546     54.3066
01800     0.8419      0.7468     0.7634     54.9411
01900     0.8411      0.7321     0.7636     54.3138
02000     0.8200      0.7595     0.7652     54.5983
02100     0.8311      0.7658     0.7652     54.4734
02200     0.8511      0.7384     0.7710     55.0891
02300     0.8303      0.7489     0.7710     54.9735
02400     0.8402      0.7511     0.7710     54.5301
02500     0.9120      0.7278     0.7792     55.1946
02600     0.7844      0.7616     0.7792     54.6960
02700     0.9144      0.7131     0.7792     55.2501
02800     0.7353      0.7764     0.7802     54.6170
02900     0.7740      0.7553     0.7802     55.2441
03000     0.8117      0.7468     0.7975     55.7686
03100     0.8079      0.7743     0.7975     54.8135
03200     0.8134      0.7637     0.7975     57.1079
03300     0.7628      0.7764     0.7975     53.9418
03400     0.7866      0.7722     0.7975     56.7927
03500     0.7371      0.7764     0.7988     57.7656
03600     0.7320      0.7637     0.7988     56.7232
03700     0.7544      0.7679     0.7988     55.9919
03800     0.7568      0.7806     0.8004     55.1725
03900     0.7388      0.7700     0.8004     55.2795
04000     0.7583      0.7679     0.8004     55.6586
04100     0.7325      0.7806     0.8004     55.0537
04200     0.7694      0.7806     0.8004     54.5396
04300     0.7707      0.7637     0.8039     54.6226
04400     0.6451      0.8038     0.8039     55.4670
04500     0.7043      0.8165     0.8090     54.3798
04600     0.7431      0.7743     0.8090     54.4831
04700     0.8140      0.7574     0.8090     56.0716
04800     0.7688      0.7806     0.8090     55.2039
04900     0.7469      0.7785     0.8090     54.5696
05000     0.7702      0.7616     0.8090     54.3077
05100     0.7556      0.7869     0.8090     54.7559
05200     0.7362      0.7743     0.8090     54.6740
05300     0.7648      0.7722     0.8090     54.3657
05400     0.8223      0.7595     0.8090     55.5642
05500     0.7031      0.7996     0.8090     54.0543
05600     0.6805      0.8059     0.8090     56.0239
05700     0.6834      0.7806     0.8090     55.2249
05800     0.7414      0.7764     0.8131     54.5886
05900     0.7740      0.7637     0.8131     55.6985
06000     0.6481      0.7975     0.8131     54.3346
06100     0.7159      0.7806     0.8174     55.1593
06200     0.6919      0.7975     0.8174     55.9122
06300     0.6935      0.8059     0.8174     55.5682
06400     0.6030      0.8291     0.8199     55.8697
06500     0.7363      0.7806     0.8199     55.1908
06600     0.6552      0.8038     0.8199     54.4261
06700     0.6446      0.8038     0.8199     54.8293
06800     0.7604      0.7574     0.8199     55.0438
06900     0.6835      0.8080     0.8199     55.3242
07000     0.7535      0.7764     0.8199     55.3948
07100     0.6822      0.7932     0.8199     55.2221
07200     0.6604      0.7996     0.8199     55.6891
07300     0.6259      0.8122     0.8199     55.0922
07400     0.7705      0.7806     0.8199     56.3968
07500     0.7207      0.7911     0.8199     56.9231
07600     0.7118      0.7890     0.8199     54.7213
07700     0.6341      0.8165     0.8199     54.7447
07800     0.7328      0.7806     0.8199     56.4885
07900     0.6687      0.8143     0.8202     55.3334
08000     0.6291      0.8165     0.8202     55.6562
08100     0.6798      0.8228     0.8209     54.5665
08200     0.6658      0.7975     0.8209     54.3152
08300     0.6714      0.8059     0.8209     55.7322
08400     0.7139      0.7890     0.8209     54.1776
08500     0.6250      0.8186     0.8209     55.6892
08600     0.6386      0.8186     0.8209     54.2470
08700     0.6758      0.7954     0.8209     54.5666
08800     0.6149      0.7911     0.8209     55.6770
08900     0.6570      0.8080     0.8209     53.6935
09000     0.6594      0.7932     0.8275     57.3749
09100     0.6527      0.8017     0.8275     55.7729
09200     0.5956      0.8249     0.8275     55.1470
09300     0.6660      0.8186     0.8275     54.7604
09400     0.7256      0.7932     0.8275     55.5896
09500     0.6963      0.7911     0.8275     56.0970
09600     0.6487      0.8207     0.8275     55.8673
09700     0.7381      0.7911     0.8275     54.0296
09800     0.7459      0.7911     0.8275     54.3465
09900     0.6709      0.7890     0.8275     54.5686
10000     0.5930      0.8228     0.8275     55.4712
10100     0.6795      0.7932     0.8275     55.7823
10200     0.6784      0.7806     0.8275     55.4418
10300     0.7475      0.7637     0.8275     54.5891
10400     0.6864      0.7911     0.8275     54.5304
10500     0.5538      0.8439     0.8275     54.8495
10600     0.5831      0.8207     0.8275     54.7800
10700     0.6871      0.7975     0.8275     57.3583
10800     0.6830      0.7806     0.8275     55.4385
10900     0.6387      0.8080     0.8275     55.4359
11000     0.6629      0.7932     0.8275     56.4956
11100     0.6637      0.8038     0.8329     55.7281
11200     0.6575      0.8038     0.8329     54.6491
11300     0.6820      0.7975     0.8329     54.2303
11400     0.6510      0.8017     0.8329     54.8694
11500     0.6198      0.8270     0.8329     54.8778
11600     0.5609      0.8376     0.8329     55.7867
11700     0.6225      0.8270     0.8329     54.9911
11800     0.6165      0.8270     0.8329     55.0277
11900     0.6637      0.7911     0.8329     54.9149
12000     0.6344      0.8101     0.8329     55.1985
12100     0.5972      0.8207     0.8329     54.0743
12200     0.6573      0.8017     0.8329     54.2295
12300     0.6642      0.7996     0.8329     54.8703
12400     0.5959      0.8333     0.8329     55.1299
12500     0.5905      0.8333     0.8329     54.6966
12600     0.6121      0.8017     0.8329     54.4703
12700     0.6712      0.8038     0.8329     54.3452
12800     0.6484      0.7911     0.8329     56.0474
12900     0.7079      0.8017     0.8329     54.9246
13000     0.6782      0.8165     0.8329     54.4988
13100     0.6827      0.8017     0.8329     55.0584
13200     0.6431      0.7996     0.8329     54.0865
13300     0.6027      0.8228     0.8329     54.7636
13400     0.6546      0.7890     0.8329     55.4144
13500     0.5486      0.8354     0.8329     54.1060
13600     0.6013      0.8143     0.8329     55.1009
13700     0.6526      0.7890     0.8329     54.7775
13800     0.6085      0.8270     0.8329     54.0282
13900     0.6921      0.8101     0.8329     54.7200
14000     0.6262      0.8080     0.8329     54.8845
14100     0.7003      0.7785     0.8329     55.2037
14200     0.5484      0.8270     0.8329     55.3060
14300     0.7339      0.7743     0.8329     55.5394
14400     0.6002      0.8249     0.8329     55.2214
14500     0.5632      0.8122     0.8329     54.1006
14600     0.5559      0.8460     0.8329     55.3745
14700     0.6880      0.7996     0.8348     56.1448
14800     0.6256      0.8101     0.8348     56.8995
14900     0.7047      0.7954     0.8348     55.8401
15000     0.6748      0.8059     0.8348     56.1171
15100     0.6625      0.7996     0.8348     56.0760
15200     0.5590      0.8376     0.8348     56.0316
15300     0.6045      0.8397     0.8348     54.5162
15400     0.5962      0.8439     0.8348     55.2561
15500     0.5657      0.8397     0.8348     55.0061
15600     0.5982      0.8333     0.8348     54.2538
15700     0.6161      0.8228     0.8348     54.3747
15800     0.5589      0.8439     0.8348     55.3020
15900     0.6054      0.8333     0.8348     54.2340
16000     0.6226      0.8207     0.8348     54.8216
16100     0.6542      0.8080     0.8348     55.9529
16200     0.6087      0.8249     0.8348     55.4617
16300     0.6416      0.8080     0.8348     55.4605
16400     0.6432      0.8249     0.8348     54.8251
16500     0.6082      0.8354     0.8348     54.6484
16600     0.6041      0.8122     0.8353     54.5917
16700     0.5293      0.8523     0.8353     55.0542
16800     0.5968      0.8333     0.8353     55.3891
16900     0.6815      0.7932     0.8353     54.3475
17000     0.5847      0.8460     0.8353     55.9196
17100     0.7009      0.7932     0.8353     55.4458
17200     0.6078      0.8270     0.8353     54.8209
17300     0.6481      0.8291     0.8353     55.6295
17400     0.6358      0.8059     0.8353     54.1815
17500     0.5712      0.8186     0.8362     53.9756
17600     0.6511      0.7954     0.8362     55.2795
17700     0.6434      0.7996     0.8362     55.0947
17800     0.5683      0.8544     0.8362     56.5848
17900     0.5644      0.8291     0.8362     55.1220
18000     0.6970      0.7764     0.8362     54.7316
18100     0.6242      0.8143     0.8362     53.8710
18200     0.6498      0.8122     0.8375     55.1875
18300     0.6461      0.8017     0.8375     54.9340
18400     0.6675      0.7869     0.8375     55.1060
18500     0.6014      0.8080     0.8375     55.3885
18600     0.5695      0.8249     0.8375     54.2694
18700     0.5987      0.8291     0.8375     54.9653
18800     0.5680      0.8228     0.8375     53.6010
18900     0.6287      0.8143     0.8375     54.1673
19000     0.5839      0.8397     0.8375     54.2866
19100     0.6031      0.8228     0.8375     56.0514
19200     0.6371      0.8101     0.8375     54.7975
19300     0.5514      0.8376     0.8375     54.0184
19400     0.6250      0.8186     0.8375     54.8399
19500     0.5743      0.8291     0.8375     54.7534
19600     0.6349      0.7975     0.8375     54.4654
19700     0.6708      0.8101     0.8375     56.1583
19800     0.5759      0.8143     0.8375     54.1227
19900     0.6301      0.8165     0.8375     54.6453
20000     0.6559      0.8017     0.8375     56.4389
20100     0.5644      0.8502     0.8375     54.5313
20199     0.6632      0.8080     0.8375     55.4760
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.5768      0.8249     0.8276     9.5870
00100     0.5508      0.8165     0.8374     54.8482
00200     0.5467      0.8418     0.8374     54.5375
00300     0.5652      0.8249     0.8374     55.3766
00400     0.6365      0.8186     0.8374     55.4272
00500     0.5254      0.8544     0.8374     54.5688
00600     0.5618      0.8397     0.8374     54.5218
00700     0.5683      0.8354     0.8374     55.1367
00800     0.5819      0.8143     0.8411     54.8648
00900     0.3751      0.9008     0.8411     53.8713
01000     0.4865      0.8565     0.8411     54.7333
01100     0.6725      0.7911     0.8411     54.7868
01200     0.6022      0.8186     0.8411     54.8216
01300     0.5089      0.8460     0.8411     54.1063
01400     0.5311      0.8586     0.8411     55.7082
01500     0.5668      0.8502     0.8411     55.3215
01600     0.5597      0.8291     0.8411     54.4966
01700     0.5065      0.8439     0.8411     54.3503
01800     0.4934      0.8608     0.8411     55.8019
01900     0.5549      0.8439     0.8411     55.5304
02000     0.5475      0.8354     0.8411     55.4614
02100     0.4987      0.8397     0.8411     54.1236
02200     0.6343      0.8249     0.8411     54.7154
02300     0.6352      0.7954     0.8411     55.9812
02400     0.5609      0.8291     0.8411     55.9482
02500     0.5681      0.8397     0.8411     54.8165
02600     0.4777      0.8565     0.8411     54.7696
02700     0.5399      0.8481     0.8411     55.9050
02800     0.5378      0.8376     0.8411     54.5216
02900     0.5437      0.8165     0.8411     54.8141
03000     0.5461      0.8228     0.8411     55.5123
03100     0.4836      0.8650     0.8411     55.4472
03200     0.4581      0.8671     0.8411     55.0616
03300     0.4523      0.8713     0.8411     54.3522
03400     0.4834      0.8650     0.8411     55.0731
03500     0.4764      0.8460     0.8411     55.7938
03600     0.6044      0.8143     0.8411     54.9977
03700     0.5280      0.8291     0.8411     54.7817
03800     0.4937      0.8565     0.8411     54.9862
03900     0.6286      0.8101     0.8411     55.2215
04000     0.5288      0.8439     0.8411     54.9504
04100     0.5141      0.8586     0.8411     54.4905
04200     0.5251      0.8397     0.8411     53.7421
04300     0.5135      0.8502     0.8411     55.0770
04400     0.5452      0.8397     0.8411     53.7802
04500     0.5462      0.8565     0.8411     54.7224
04600     0.5228      0.8397     0.8411     54.5561
04700     0.5845      0.8228     0.8411     55.5927
04800     0.5062      0.8544     0.8411     55.6110
04900     0.5461      0.8502     0.8411     54.8662
05000     0.5142      0.8376     0.8411     54.9595
05100     0.5318      0.8439     0.8411     56.3118
05200     0.5350      0.8502     0.8411     55.1204
05300     0.5526      0.8270     0.8411     54.8856
05400     0.5053      0.8650     0.8411     55.4643
05500     0.5111      0.8544     0.8411     55.0536
05600     0.5539      0.8312     0.8411     54.8880
05700     0.5836      0.8186     0.8411     54.3012
05800     0.5801      0.8101     0.8411     55.8463
05900     0.5492      0.8439     0.8411     56.2695
06000     0.5200      0.8418     0.8411     54.4743
06100     0.5266      0.8608     0.8411     54.8302
06200     0.5478      0.8397     0.8411     55.0707
06300     0.4216      0.8819     0.8411     54.2435
06400     0.5030      0.8418     0.8411     56.5311
06500     0.5853      0.8228     0.8411     54.3032
06600     0.5624      0.8312     0.8411     55.0556
06700     0.5226      0.8481     0.8411     55.7449
06800     0.6117      0.8059     0.8411     54.7338
06900     0.5077      0.8439     0.8411     54.9323
07000     0.5805      0.8291     0.8411     55.2556
07100     0.5399      0.8481     0.8411     54.1498
07200     0.5755      0.8143     0.8411     55.4982
07300     0.5306      0.8460     0.8411     53.9915
07400     0.5254      0.8502     0.8411     55.0712
07500     0.5549      0.8333     0.8429     55.8973
07600     0.5936      0.8249     0.8429     55.6461
07700     0.5449      0.8312     0.8429     55.1043
07800     0.5231      0.8397     0.8429     54.7639
07900     0.5140      0.8586     0.8429     54.3890
08000     0.6074      0.8270     0.8429     55.5163
08100     0.5142      0.8565     0.8429     54.8093
08200     0.5318      0.8502     0.8429     54.8766
08300     0.4468      0.8629     0.8429     55.3366
08400     0.4746      0.8650     0.8429     56.3051
08500     0.5444      0.8354     0.8429     55.5088
08600     0.6005      0.8291     0.8429     55.0528
08700     0.5038      0.8586     0.8429     54.8708
08800     0.5535      0.8460     0.8429     56.7229
08900     0.4865      0.8608     0.8429     54.8775
09000     0.5295      0.8397     0.8429     54.9714
09100     0.4810      0.8523     0.8429     55.6261
09200     0.5283      0.8397     0.8429     55.4546
09300     0.5785      0.8270     0.8429     54.0951
09400     0.6285      0.8291     0.8429     55.3122
09500     0.4977      0.8586     0.8429     57.1938
09600     0.5227      0.8481     0.8429     58.4517
09700     0.5479      0.8376     0.8429     54.2283
09800     0.4742      0.8544     0.8429     54.6037
09900     0.5549      0.8376     0.8429     56.1207
Start testing:
Test Accuracy: 0.8130
