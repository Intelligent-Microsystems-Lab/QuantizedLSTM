Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
416860ab-9601-4232-9a39-ef46ae683089
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
fcddca9c-1207-48a1-b78b-9261a21296d2
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=235899598, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
1fa949a1-a3d0-44b4-ba6b-0951cbc18e7f
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.0041      0.0949     0.0799     9.5318
00100     2.6302      0.0802     0.0813     56.9724
00200     2.5288      0.1118     0.1083     55.4025
00300     2.3713      0.3017     0.3288     55.6283
00400     2.3423      0.2975     0.3464     57.4436
00500     2.1982      0.3565     0.3778     55.1570
00600     2.0538      0.3650     0.3864     56.0481
00700     1.9780      0.3819     0.3988     54.4233
00800     1.9088      0.3819     0.4038     56.4562
00900     1.9366      0.3376     0.4200     54.6666
01000     1.7335      0.4367     0.4409     56.4511
01100     1.7658      0.4325     0.4468     55.5923
01200     1.6627      0.4114     0.4468     54.5260
01300     1.7345      0.4114     0.4468     54.8869
01400     1.6994      0.4599     0.4693     57.0573
01500     1.5560      0.4557     0.4777     55.2139
01600     1.6176      0.4810     0.5010     56.5155
01700     1.7099      0.4895     0.5424     54.3032
01800     1.5536      0.4747     0.5424     55.6250
01900     1.4551      0.5042     0.5424     56.6694
02000     1.5935      0.5232     0.5534     55.4351
02100     1.6080      0.4916     0.5534     55.4600
02200     1.5215      0.5084     0.5534     55.3987
02300     1.5121      0.5127     0.5661     55.9203
02400     1.5703      0.4852     0.5661     57.2088
02500     1.4426      0.5401     0.5661     54.7540
02600     1.4045      0.5295     0.5890     54.8422
02700     1.5374      0.5274     0.5890     55.8476
02800     1.3556      0.5654     0.6023     57.4064
02900     1.5948      0.5042     0.6023     55.7035
03000     1.4744      0.5380     0.6065     56.8467
03100     1.4289      0.5612     0.6079     55.3970
03200     1.3395      0.5338     0.6079     55.6000
03300     1.5562      0.5443     0.6079     54.8756
03400     1.3849      0.5738     0.6224     55.8983
03500     1.5457      0.5021     0.6224     56.0617
03600     1.5017      0.5338     0.6224     55.5573
03700     1.4658      0.5274     0.6224     57.1334
03800     1.4123      0.5063     0.6224     56.7380
03900     1.4310      0.5654     0.6224     56.6780
04000     1.3892      0.5612     0.6224     55.7835
04100     1.2935      0.5338     0.6224     55.2054
04200     1.4696      0.5274     0.6224     55.4876
04300     1.3718      0.5633     0.6224     56.4332
04400     1.2161      0.5928     0.6224     55.6600
04500     1.3580      0.5759     0.6232     55.3277
04600     1.1208      0.6118     0.6288     56.3207
04700     1.3083      0.5844     0.6330     54.6995
04800     1.2506      0.5654     0.6330     55.6240
04900     1.4830      0.5211     0.6330     54.6363
05000     1.2172      0.6034     0.6330     54.8165
05100     1.2042      0.5570     0.6330     55.3316
05200     1.4775      0.5063     0.6330     55.7126
05300     1.2094      0.5865     0.6330     55.9458
05400     1.3757      0.5464     0.6330     57.5572
05500     1.3123      0.5696     0.6330     55.2608
05600     1.3066      0.5823     0.6330     57.4251
05700     1.1763      0.5654     0.6330     55.6944
05800     1.3162      0.5464     0.6330     55.1010
05900     1.1555      0.6203     0.6330     57.6777
06000     1.2154      0.5992     0.6330     55.5254
06100     1.2397      0.5781     0.6330     54.7804
06200     1.3264      0.5823     0.6330     55.0625
06300     1.2120      0.5781     0.6379     54.8537
06400     1.3701      0.5654     0.6379     56.2083
06500     1.3027      0.5928     0.6379     54.4925
06600     1.1596      0.6076     0.6400     54.8908
06700     1.2700      0.5907     0.6400     56.0027
06800     1.2755      0.5802     0.6532     56.4652
06900     1.2726      0.5865     0.6532     56.4888
07000     1.1628      0.5886     0.6532     55.8919
07100     1.2817      0.6160     0.6532     55.7392
07200     1.1852      0.5570     0.6532     56.1053
07300     1.2640      0.6118     0.6532     55.4393
07400     1.1513      0.5992     0.6532     55.1412
07500     1.3742      0.5823     0.6532     56.4736
07600     1.4049      0.5422     0.6532     55.5546
07700     1.2763      0.5886     0.6532     55.5154
07800     1.2806      0.5781     0.6532     55.5500
07900     1.2954      0.5970     0.6532     56.9375
08000     1.2873      0.5717     0.6532     57.2489
08100     1.2805      0.5886     0.6532     55.4131
08200     1.1876      0.5907     0.6532     55.4173
08300     1.2132      0.5970     0.6532     55.4676
08400     1.2463      0.5781     0.6532     56.2938
08500     1.4842      0.5211     0.6532     55.2219
08600     1.1797      0.6139     0.6532     55.4357
08700     1.0699      0.6308     0.6532     56.2594
08800     1.2870      0.6097     0.6532     55.5166
08900     1.1352      0.6139     0.6532     55.0763
09000     1.3088      0.5928     0.6535     54.5915
09100     1.2815      0.5992     0.6535     55.1202
09200     1.1889      0.5886     0.6535     55.9888
09300     1.1963      0.5970     0.6535     55.6273
09400     1.2582      0.5675     0.6535     55.7843
09500     1.3033      0.5865     0.6698     55.1174
09600     1.2662      0.5970     0.6698     56.4461
09700     1.2045      0.5844     0.6698     54.5312
09800     1.1625      0.6118     0.6698     55.7214
09900     1.1916      0.5886     0.6698     56.1204
10000     1.2601      0.5802     0.6698     55.1358
10100     1.2219      0.6034     0.6698     56.3247
10200     1.2060      0.6329     0.6698     57.0940
10300     1.3119      0.5717     0.6698     56.1614
10400     1.1910      0.5823     0.6698     55.9743
10500     1.1486      0.6392     0.6698     55.6836
10600     1.3052      0.5781     0.6713     55.5461
10700     1.1786      0.6371     0.6713     57.3513
10800     1.2372      0.6097     0.6713     56.3162
10900     1.1829      0.6055     0.6713     55.5962
11000     1.2818      0.6245     0.6713     56.6232
11100     1.2888      0.5970     0.6713     54.7696
11200     1.2885      0.6076     0.6713     56.3175
11300     1.1876      0.6287     0.6713     54.7454
11400     1.0797      0.6477     0.6713     55.2971
11500     1.2959      0.5654     0.6713     55.7854
11600     1.0923      0.6371     0.6713     54.9437
11700     1.1111      0.6034     0.6713     55.5989
11800     1.1286      0.6181     0.6713     56.2447
11900     1.2007      0.6139     0.6713     55.2163
12000     1.3075      0.5865     0.6713     55.0458
12100     1.2061      0.6118     0.6713     55.9759
12200     1.1387      0.6582     0.6713     56.6534
12300     1.3514      0.5823     0.6713     57.1337
12400     1.2874      0.5591     0.6713     54.7272
12500     1.1630      0.5992     0.6713     55.4657
12600     1.1963      0.5717     0.6713     55.4246
12700     1.3561      0.5485     0.6713     54.7511
12800     1.2176      0.6582     0.6713     55.2296
12900     1.0483      0.6603     0.6713     54.3637
13000     1.2263      0.5970     0.6713     56.8778
13100     1.2010      0.6245     0.6713     57.3238
13200     1.1730      0.5823     0.6713     56.5778
13300     1.1499      0.5928     0.6713     56.4669
13400     1.2036      0.6350     0.6713     56.4487
13500     1.3587      0.5717     0.6713     55.9290
13600     1.2285      0.5738     0.6713     56.0582
13700     1.2409      0.5907     0.6713     54.8743
13800     1.2726      0.6118     0.6713     54.6000
13900     1.2880      0.5886     0.6713     56.1617
14000     1.2913      0.6055     0.6713     54.9004
14100     1.2334      0.5633     0.6713     55.4959
14200     1.1762      0.6139     0.6713     55.2831
14300     1.2544      0.6118     0.6713     55.8575
14400     1.2186      0.6350     0.6713     56.3282
14500     1.1611      0.6540     0.6713     55.7443
14600     1.2105      0.6266     0.6713     56.3501
14700     1.2653      0.5696     0.6713     57.0742
14800     1.2217      0.6034     0.6713     56.1802
14900     1.2286      0.6160     0.6713     55.5423
15000     1.1956      0.5717     0.6713     56.1250
15100     1.1167      0.6392     0.6713     55.2497
15200     1.1602      0.6139     0.6713     56.7128
15300     1.2729      0.6034     0.6713     55.6985
15400     1.2114      0.6034     0.6713     55.5558
15500     1.3344      0.5422     0.6713     55.8027
15600     1.2197      0.5886     0.6713     55.2117
15700     1.3215      0.5759     0.6713     55.4613
15800     1.1706      0.6266     0.6713     56.5034
15900     1.3906      0.5612     0.6713     55.4544
16000     1.1606      0.6245     0.6713     55.0054
16100     1.0625      0.6540     0.6713     53.5240
16200     1.1118      0.6224     0.6713     55.0223
16300     1.3483      0.5422     0.6713     56.2943
16400     1.1437      0.6350     0.6713     55.6597
16500     1.3859      0.5992     0.6713     55.9241
16600     1.0711      0.6498     0.6713     56.7977
16700     1.2281      0.5992     0.6713     54.6756
16800     1.2267      0.6034     0.6713     55.5723
16900     1.1115      0.6456     0.6713     54.9602
17000     1.3988      0.5696     0.6713     55.1689
17100     1.1089      0.6392     0.6713     56.3033
17200     1.1480      0.6287     0.6713     57.3741
17300     1.1227      0.6329     0.6713     56.3806
17400     1.1520      0.6287     0.6713     56.0224
17500     1.2979      0.5928     0.6713     56.1406
17600     1.1276      0.6181     0.6713     55.1705
17700     1.0744      0.5970     0.6713     55.2004
17800     1.1700      0.5907     0.6713     55.8140
17900     1.1067      0.6139     0.6713     56.5426
18000     1.1040      0.6224     0.6713     56.5467
18100     1.1936      0.6329     0.6713     55.2294
18200     1.1581      0.6308     0.6713     55.5153
18300     1.2012      0.6329     0.6713     54.7449
18400     1.1992      0.6076     0.6713     56.5815
18500     1.1827      0.6266     0.6713     55.2170
18600     1.2179      0.5970     0.6713     54.5666
18700     1.1733      0.5886     0.6713     54.7994
18800     1.2466      0.5970     0.6713     57.2574
18900     1.0970      0.6139     0.6713     57.4671
19000     1.2244      0.6329     0.6713     55.4291
19100     1.1798      0.5949     0.6713     55.6226
19200     1.1416      0.6013     0.6713     56.1543
19300     1.2444      0.6224     0.6713     55.1354
19400     1.3009      0.5844     0.6713     55.4692
19500     1.2146      0.5949     0.6713     55.0935
19600     1.4176      0.5696     0.6713     55.1757
19700     1.0296      0.6329     0.6713     56.0267
19800     1.2189      0.5570     0.6713     56.7936
19900     1.1224      0.6371     0.6713     55.5930
20000     1.1671      0.6181     0.6713     56.7009
20100     1.0926      0.6435     0.6713     56.3689
20199     1.1186      0.6160     0.6713     55.5336
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     1.1168      0.6350     0.6562     8.5159
00100     1.1854      0.6224     0.6612     55.5582
00200     1.2620      0.6118     0.6638     55.0241
00300     1.0890      0.6329     0.6638     55.2313
00400     1.1323      0.6139     0.6638     54.9104
00500     1.1341      0.6477     0.6638     55.8156
00600     1.1234      0.6118     0.6638     54.7351
00700     1.1282      0.6160     0.6638     55.8085
00800     1.0899      0.6435     0.6638     54.8664
00900     1.0193      0.6561     0.6638     56.0494
01000     1.0953      0.6055     0.6638     55.4905
01100     1.1261      0.6561     0.6638     56.6870
01200     1.1235      0.6561     0.6724     55.5360
01300     1.1832      0.6097     0.6724     55.9865
01400     1.0750      0.6730     0.6724     54.8523
01500     1.1626      0.6287     0.6724     55.0520
01600     1.0986      0.6308     0.6724     55.5878
01700     1.2030      0.6392     0.6724     55.6182
01800     1.1880      0.6350     0.6724     56.1353
01900     1.1493      0.6160     0.6724     55.2940
02000     1.1099      0.6245     0.6724     54.7717
02100     1.1319      0.6371     0.6724     55.1717
02200     1.1425      0.6561     0.6724     55.3470
02300     1.1014      0.6477     0.6724     55.0196
02400     1.0874      0.6350     0.6724     55.7755
02500     1.1367      0.6329     0.6724     55.0053
02600     1.2144      0.5823     0.6724     56.1396
02700     1.2684      0.5865     0.6724     56.0033
02800     1.1668      0.5970     0.6724     56.8032
02900     1.1580      0.6603     0.6724     56.1329
03000     1.0830      0.6308     0.6724     56.4581
03100     1.1891      0.6076     0.6724     57.5998
03200     1.0117      0.6603     0.6724     55.6143
03300     1.1519      0.6203     0.6724     55.6833
03400     1.2171      0.6224     0.6724     56.1013
03500     1.0997      0.6266     0.6724     56.0606
03600     1.1354      0.6139     0.6724     55.0906
03700     1.1640      0.6118     0.6724     56.8826
03800     1.0178      0.6624     0.6724     56.1047
03900     1.0081      0.6624     0.6724     55.7594
04000     1.0805      0.6203     0.6724     55.1281
04100     1.1021      0.6540     0.6724     57.1567
04200     1.0907      0.6076     0.6724     55.3050
04300     1.0411      0.6414     0.6724     55.5819
04400     0.9952      0.6582     0.6724     54.5220
04500     1.0431      0.6582     0.6724     56.7085
04600     1.0465      0.6540     0.6724     58.2243
04700     1.1695      0.6519     0.6724     55.6860
04800     1.0087      0.6688     0.6724     57.1641
04900     1.1291      0.6160     0.6724     57.8880
05000     1.1337      0.6055     0.6724     56.5119
05100     1.1355      0.6477     0.6728     57.6054
05200     1.0731      0.6561     0.6728     55.2572
05300     1.0541      0.6308     0.6728     56.1467
05400     1.1660      0.6266     0.6767     57.5875
05500     1.2229      0.6055     0.6767     56.3456
05600     1.0194      0.6561     0.6767     55.7780
05700     1.0609      0.6624     0.6767     56.1495
05800     1.0632      0.6688     0.6767     56.0064
05900     1.0466      0.6582     0.6767     56.3458
06000     1.1273      0.6329     0.6767     56.3184
06100     1.0561      0.6435     0.6767     55.6280
06200     1.0555      0.6772     0.6767     56.3491
06300     1.0219      0.6371     0.6767     55.6940
06400     1.1540      0.6308     0.6767     56.9008
06500     0.9787      0.6709     0.6767     55.7954
06600     0.8863      0.6835     0.6767     55.5217
06700     0.9538      0.6561     0.6767     57.3835
06800     1.3180      0.5865     0.6767     54.5982
06900     1.1091      0.6435     0.6767     54.4510
07000     0.9566      0.6350     0.6767     55.6000
07100     1.2966      0.6013     0.6767     54.7646
07200     1.2452      0.6013     0.6767     55.0156
07300     1.2942      0.5907     0.6767     56.0624
07400     1.0983      0.6329     0.6767     56.1577
07500     1.1591      0.6371     0.6767     55.8681
07600     1.0081      0.6582     0.6767     55.8940
07700     1.1600      0.6414     0.6767     56.8095
07800     0.9895      0.6688     0.6767     56.5780
07900     1.1125      0.6435     0.6767     55.8278
08000     1.1763      0.6245     0.6767     55.5209
08100     1.2447      0.5612     0.6767     56.8650
08200     1.1025      0.6329     0.6767     55.4355
08300     1.1699      0.6329     0.6767     55.3281
08400     1.0261      0.6097     0.6767     55.6333
08500     1.2460      0.5949     0.6767     56.4207
08600     1.1823      0.6266     0.6767     56.1776
08700     1.0731      0.6224     0.6767     56.4142
08800     1.1206      0.6181     0.6767     56.4758
08900     1.1463      0.6203     0.6767     56.5157
09000     0.9700      0.6519     0.6778     54.7177
09100     1.1427      0.6519     0.6778     56.1177
09200     1.1634      0.6392     0.6778     54.8639
09300     1.1789      0.6308     0.6778     55.4525
09400     1.1264      0.6519     0.6778     56.0039
09500     1.1048      0.6245     0.6778     55.5338
09600     1.0877      0.5992     0.6778     55.7737
09700     1.0000      0.6878     0.6778     56.1987
09800     1.1473      0.6646     0.6778     56.9939
09900     1.2033      0.5844     0.6778     56.7363
Start testing:
Test Accuracy: 0.6752
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
