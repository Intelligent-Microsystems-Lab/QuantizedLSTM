Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
d2d9e1a8-6354-42cc-a34a-c031529db3dc
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
4e4e4de6-43ac-4f68-9245-24d718e1bbce
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
d171b350-ec0b-4e6f-a9f3-8c7d49a66196
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.9652      0.0865     0.0753     10.7950
00100     2.0378      0.3692     0.4013     74.8370
00200     1.6345      0.4831     0.5032     75.3055
00300     1.3968      0.5675     0.5788     75.3726
00400     1.1823      0.6181     0.6315     74.8299
00500     1.1309      0.6624     0.6615     75.1785
00600     1.0329      0.6962     0.7078     74.2862
00700     0.9711      0.7089     0.7301     74.9213
00800     0.8552      0.7426     0.7438     75.1105
00900     0.8870      0.7278     0.7515     74.4644
01000     0.8122      0.7511     0.7651     75.1382
01100     0.7881      0.7679     0.7706     75.3115
01200     0.8048      0.7511     0.7706     74.6339
01300     0.8684      0.7384     0.7812     74.5940
01400     0.7828      0.7278     0.7828     75.6686
01500     0.7228      0.7848     0.7895     74.9681
01600     0.7217      0.7637     0.7956     74.7985
01700     0.7790      0.7553     0.7956     74.5764
01800     0.7436      0.7764     0.7956     75.0227
01900     0.6978      0.8122     0.7956     75.3519
02000     0.7519      0.7806     0.8013     74.8341
02100     0.7397      0.7679     0.8013     74.3969
02200     0.7141      0.7890     0.8077     74.9561
02300     0.6030      0.8333     0.8077     74.6856
02400     0.7242      0.7764     0.8077     74.9323
02500     0.7030      0.7975     0.8077     74.4920
02600     0.7295      0.7700     0.8140     74.4552
02700     0.5817      0.8207     0.8140     75.5358
02800     0.6438      0.7890     0.8140     74.4736
02900     0.6469      0.8207     0.8140     72.9097
03000     0.6463      0.8186     0.8140     72.7504
03100     0.6643      0.7975     0.8182     73.1486
03200     0.6680      0.7848     0.8182     73.4555
03300     0.6919      0.7848     0.8182     73.0214
03400     0.7115      0.7806     0.8196     72.9579
03500     0.7273      0.7954     0.8196     73.4010
03600     0.5498      0.8354     0.8196     72.8211
03700     0.6536      0.7954     0.8198     72.5904
03800     0.6357      0.7996     0.8198     73.1319
03900     0.7060      0.8038     0.8198     72.3961
04000     0.6383      0.8101     0.8215     73.4714
04100     0.6194      0.8228     0.8217     72.4433
04200     0.5618      0.8397     0.8271     72.9437
04300     0.6110      0.8207     0.8271     72.6498
04400     0.6126      0.8186     0.8278     71.9582
04500     0.6474      0.8080     0.8278     72.0740
04600     0.7242      0.7553     0.8278     72.9112
04700     0.5838      0.7954     0.8278     72.4671
04800     0.6541      0.8017     0.8278     73.2647
04900     0.6565      0.8143     0.8290     72.5847
05000     0.6259      0.8165     0.8290     72.7073
05100     0.5810      0.8439     0.8306     72.5578
05200     0.6561      0.7975     0.8306     71.9521
05300     0.5524      0.8460     0.8306     72.0810
05400     0.6594      0.8017     0.8306     72.4057
05500     0.6279      0.8017     0.8306     72.6210
05600     0.6704      0.7869     0.8306     72.8865
05700     0.6409      0.7954     0.8306     71.8927
05800     0.6664      0.7932     0.8306     72.6974
05900     0.5283      0.8481     0.8306     73.1518
06000     0.6040      0.8228     0.8306     72.3380
06100     0.6243      0.8165     0.8306     72.6286
06200     0.6161      0.8312     0.8346     72.4886
06300     0.6046      0.8122     0.8346     72.6483
06400     0.7096      0.7679     0.8346     72.9963
06500     0.5210      0.8544     0.8346     72.2239
06600     0.6390      0.8017     0.8346     72.3046
06700     0.6577      0.7996     0.8346     72.7020
06800     0.6445      0.8059     0.8346     73.0207
06900     0.5581      0.8439     0.8346     72.6233
07000     0.5899      0.8101     0.8346     73.2509
07100     0.5940      0.8228     0.8346     72.7360
07200     0.6942      0.7827     0.8346     72.6965
07300     0.5825      0.8165     0.8346     72.8701
07400     0.6282      0.8101     0.8346     72.4153
07500     0.5390      0.8376     0.8346     72.2673
07600     0.5729      0.8186     0.8346     72.3173
07700     0.5173      0.8502     0.8346     72.8058
07800     0.5499      0.8502     0.8346     72.4141
07900     0.5667      0.8228     0.8346     72.8769
08000     0.5236      0.8629     0.8346     73.0462
08100     0.6666      0.7932     0.8346     72.0957
08200     0.5728      0.8228     0.8346     72.9548
08300     0.6322      0.8059     0.8346     72.5431
08400     0.5304      0.8523     0.8378     72.7399
08500     0.6031      0.8080     0.8378     72.5558
08600     0.6470      0.8059     0.8378     73.0246
08700     0.5835      0.8291     0.8391     73.0197
08800     0.6073      0.7975     0.8391     73.3130
08900     0.5099      0.8312     0.8391     72.7660
09000     0.6069      0.8291     0.8391     72.9951
09100     0.5590      0.8291     0.8391     73.2380
09200     0.5971      0.8143     0.8391     72.5634
09300     0.5629      0.8228     0.8391     72.2977
09400     0.5846      0.8207     0.8391     72.9742
09500     0.4893      0.8608     0.8428     72.1633
09600     0.5991      0.8207     0.8428     73.1029
09700     0.6017      0.8122     0.8428     72.9530
09800     0.5271      0.8333     0.8428     73.2348
09900     0.5701      0.8397     0.8428     73.0424
10000     0.6169      0.8059     0.8428     72.3954
10100     0.5164      0.8502     0.8428     72.8149
10200     0.5504      0.8354     0.8428     73.3570
10300     0.5231      0.8333     0.8428     72.4473
10400     0.5670      0.8249     0.8428     72.7773
10500     0.5204      0.8333     0.8428     72.7281
10600     0.5557      0.8333     0.8428     73.0997
10700     0.5899      0.8460     0.8428     73.1658
10800     0.5495      0.8354     0.8428     72.5320
10900     0.5824      0.8376     0.8428     73.3646
11000     0.4826      0.8523     0.8428     72.9810
11100     0.4663      0.8586     0.8428     72.8601
11200     0.5434      0.8291     0.8428     73.0271
11300     0.5361      0.8333     0.8428     72.1216
11400     0.5772      0.8143     0.8428     72.2502
11500     0.5834      0.8291     0.8428     72.1947
11600     0.5991      0.8207     0.8428     72.9143
11700     0.6949      0.7743     0.8428     73.2163
11800     0.6239      0.8059     0.8428     73.7275
11900     0.5477      0.8270     0.8428     73.1579
12000     0.4991      0.8713     0.8428     74.1736
12100     0.5658      0.8270     0.8430     72.8940
12200     0.5883      0.7911     0.8439     73.5305
12300     0.5355      0.8122     0.8439     73.6882
12400     0.5458      0.8312     0.8439     73.3381
12500     0.5385      0.8165     0.8481     73.8480
12600     0.5898      0.8291     0.8481     73.4676
12700     0.5431      0.8186     0.8481     73.1674
12800     0.5589      0.8333     0.8481     72.7967
12900     0.4813      0.8502     0.8481     73.9099
13000     0.5542      0.8502     0.8481     73.0210
13100     0.5138      0.8523     0.8481     73.2689
13200     0.5295      0.8608     0.8481     73.9039
13300     0.5266      0.8460     0.8481     73.1697
13400     0.5184      0.8397     0.8481     73.5846
13500     0.5142      0.8270     0.8481     73.5816
13600     0.5097      0.8397     0.8481     73.8506
13700     0.5046      0.8397     0.8481     73.7254
13800     0.5223      0.8270     0.8481     73.1997
13900     0.5045      0.8439     0.8481     73.0993
14000     0.4856      0.8502     0.8481     73.3867
14100     0.5055      0.8502     0.8481     72.9436
14200     0.4757      0.8692     0.8481     73.0907
14300     0.5215      0.8376     0.8481     72.3227
14400     0.5114      0.8502     0.8481     72.6101
14500     0.5194      0.8312     0.8481     72.9060
14600     0.5657      0.8523     0.8481     72.8345
14700     0.5249      0.8312     0.8481     72.9330
14800     0.4768      0.8692     0.8481     72.3262
14900     0.5369      0.8333     0.8481     72.9196
15000     0.4871      0.8397     0.8481     73.3758
15100     0.5778      0.8270     0.8481     72.3194
15200     0.4650      0.8629     0.8481     72.4466
15300     0.5132      0.8418     0.8481     72.7269
15400     0.5535      0.8354     0.8481     72.9123
15500     0.5244      0.8502     0.8481     72.6251
15600     0.4586      0.8650     0.8481     71.8715
15700     0.5983      0.8143     0.8481     72.2756
15800     0.5309      0.8418     0.8481     73.0505
15900     0.5320      0.8671     0.8481     73.0681
16000     0.5269      0.8460     0.8481     73.0892
16100     0.5539      0.8397     0.8481     72.1338
16200     0.5513      0.8249     0.8481     72.4563
16300     0.4859      0.8586     0.8481     72.9459
16400     0.5394      0.8502     0.8481     72.9511
16500     0.4349      0.8776     0.8481     72.6630
16600     0.4634      0.8397     0.8481     72.6111
16700     0.4188      0.8734     0.8481     72.6187
16800     0.5279      0.8502     0.8485     72.5610
16900     0.5453      0.8376     0.8485     72.1750
17000     0.5482      0.8460     0.8485     72.8427
17100     0.5239      0.8418     0.8485     72.7876
17200     0.4904      0.8692     0.8485     72.8125
17300     0.4894      0.8418     0.8485     72.6252
17400     0.5523      0.8354     0.8485     73.1282
17500     0.5110      0.8397     0.8485     72.4380
17600     0.5148      0.8439     0.8485     72.6639
17700     0.5102      0.8502     0.8490     71.9613
17800     0.4929      0.8586     0.8490     72.4527
17900     0.5091      0.8186     0.8490     72.9825
18000     0.5379      0.8333     0.8490     73.1080
18100     0.4800      0.8291     0.8490     73.0825
18200     0.5836      0.8186     0.8490     73.1031
18300     0.5265      0.8439     0.8490     73.3947
18400     0.4526      0.8629     0.8490     73.8689
18500     0.6278      0.7932     0.8490     73.5355
18600     0.6031      0.8312     0.8490     72.6809
18700     0.5412      0.8270     0.8490     73.3586
18800     0.4770      0.8502     0.8490     72.9262
18900     0.6021      0.8143     0.8490     72.7794
19000     0.5498      0.8460     0.8490     73.4238
19100     0.5227      0.8481     0.8490     72.7151
19200     0.5477      0.8291     0.8490     73.6013
19300     0.5164      0.8460     0.8490     72.7988
19400     0.5806      0.8249     0.8490     74.0622
19500     0.5277      0.8481     0.8490     73.7749
19600     0.5283      0.8481     0.8490     73.8464
19700     0.5076      0.8460     0.8490     73.5988
19800     0.5277      0.8418     0.8490     72.9383
19900     0.4918      0.8502     0.8490     73.2325
20000     0.4596      0.8523     0.8490     73.2721
20100     0.6324      0.8080     0.8490     73.2497
20199     0.5205      0.8418     0.8490     72.5099
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4047      0.8819     0.8425     10.2908
00100     0.4281      0.8797     0.8467     72.2013
00200     0.4411      0.8797     0.8467     71.8401
00300     0.3807      0.8966     0.8493     71.7660
00400     0.4674      0.8439     0.8493     72.0524
00500     0.4586      0.8608     0.8493     72.0377
00600     0.4932      0.8523     0.8493     72.8171
00700     0.4696      0.8523     0.8493     72.1399
00800     0.4217      0.8776     0.8493     72.7472
00900     0.4841      0.8502     0.8506     73.0118
01000     0.4793      0.8481     0.8506     72.3685
01100     0.4138      0.8903     0.8506     73.1332
01200     0.4897      0.8502     0.8506     72.9182
01300     0.4857      0.8586     0.8506     73.1595
01400     0.4328      0.8755     0.8506     72.6212
01500     0.3674      0.8987     0.8506     72.4327
01600     0.4599      0.8544     0.8529     72.8922
01700     0.4329      0.8776     0.8529     72.4207
01800     0.4132      0.8819     0.8529     72.3414
01900     0.4221      0.8797     0.8529     72.8159
02000     0.4273      0.8734     0.8529     72.4516
02100     0.4588      0.8586     0.8529     72.1982
02200     0.4536      0.8713     0.8529     72.9251
02300     0.4770      0.8650     0.8529     73.2428
02400     0.3889      0.8945     0.8529     73.1188
02500     0.4363      0.8755     0.8532     73.7651
02600     0.4295      0.8819     0.8532     73.2348
02700     0.4569      0.8713     0.8532     72.5780
02800     0.5132      0.8523     0.8532     72.3116
02900     0.3806      0.8924     0.8542     72.1149
03000     0.4472      0.8565     0.8542     73.2274
03100     0.4688      0.8671     0.8542     73.2330
03200     0.4403      0.8882     0.8542     73.6895
03300     0.4123      0.8755     0.8542     72.6879
03400     0.5041      0.8439     0.8542     72.2665
03500     0.4496      0.8608     0.8542     72.3045
03600     0.4166      0.8776     0.8542     72.3859
03700     0.4421      0.8629     0.8542     72.2003
03800     0.4721      0.8544     0.8542     73.3962
03900     0.4939      0.8291     0.8542     72.8398
04000     0.4487      0.8797     0.8542     72.6795
04100     0.3883      0.8945     0.8542     72.8017
04200     0.4712      0.8544     0.8542     72.4129
04300     0.4553      0.8671     0.8542     73.1412
04400     0.4534      0.8650     0.8542     71.9695
04500     0.4467      0.8671     0.8542     72.4657
04600     0.4705      0.8544     0.8542     72.6875
04700     0.4134      0.8861     0.8542     74.7272
04800     0.4124      0.8882     0.8542     74.6388
04900     0.4251      0.8987     0.8542     74.9879
05000     0.5115      0.8608     0.8542     76.1642
05100     0.4882      0.8586     0.8542     75.1703
05200     0.4042      0.8776     0.8542     74.8802
05300     0.4095      0.8797     0.8542     74.6254
05400     0.5143      0.8629     0.8542     75.1888
05500     0.4757      0.8629     0.8542     74.2918
05600     0.4380      0.8671     0.8542     73.5982
05700     0.3445      0.8924     0.8542     74.3973
05800     0.4587      0.8481     0.8542     74.4407
05900     0.4380      0.8650     0.8542     74.9458
06000     0.4831      0.8481     0.8542     74.0681
06100     0.4227      0.8819     0.8542     74.3006
06200     0.4263      0.8797     0.8542     74.3907
06300     0.4015      0.8650     0.8542     74.0741
06400     0.4195      0.8734     0.8542     75.0128
06500     0.4384      0.8861     0.8542     74.5531
06600     0.4798      0.8755     0.8542     73.9921
06700     0.4239      0.8819     0.8542     74.4920
06800     0.3992      0.8945     0.8542     73.7246
06900     0.4547      0.8460     0.8542     74.9618
07000     0.3978      0.8819     0.8542     74.3822
07100     0.4776      0.8502     0.8542     73.9440
07200     0.4860      0.8608     0.8542     74.9554
07300     0.4349      0.8629     0.8544     74.8332
07400     0.4069      0.8692     0.8552     74.7248
07500     0.5385      0.8439     0.8552     75.1353
07600     0.4265      0.8713     0.8570     74.6074
07700     0.4197      0.8840     0.8570     74.5399
07800     0.4116      0.8755     0.8570     74.7202
07900     0.3983      0.8903     0.8570     74.7812
08000     0.4553      0.8565     0.8570     75.0525
08100     0.4171      0.8819     0.8570     74.3385
08200     0.4402      0.8671     0.8570     74.4932
08300     0.4566      0.8629     0.8570     75.3974
08400     0.4264      0.8755     0.8570     74.3568
08500     0.4875      0.8544     0.8570     74.4653
08600     0.5435      0.8481     0.8570     75.0434
08700     0.4289      0.8776     0.8570     74.1249
08800     0.4414      0.8671     0.8570     74.0145
08900     0.5025      0.8502     0.8570     75.2613
09000     0.4638      0.8629     0.8570     74.4669
09100     0.4740      0.8565     0.8570     74.9204
09200     0.4787      0.8713     0.8570     75.1633
09300     0.3934      0.8903     0.8570     76.8027
09400     0.4210      0.8755     0.8570     74.9141
09500     0.4475      0.8650     0.8570     74.4027
09600     0.4126      0.8882     0.8583     74.8325
09700     0.4161      0.8565     0.8583     75.7635
09800     0.4648      0.8650     0.8583     75.1002
09900     0.3961      0.8819     0.8583     75.0525
Start testing:
Test Accuracy: 0.8382
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
2f2525ac-0012-4b02-9296-31c9c9c32124
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.9652      0.0865     0.0753     9.5685
00100     2.0378      0.3692     0.4013     53.3422
00200     1.6345      0.4831     0.5032     53.9710
00300     1.3968      0.5675     0.5788     54.5396
00400     1.1823      0.6181     0.6315     53.4507
00500     1.1309      0.6624     0.6615     55.1152
00600     1.0329      0.6962     0.7078     55.2989
00700     0.9711      0.7089     0.7301     53.9739
00800     0.8552      0.7426     0.7438     54.8036
00900     0.8870      0.7278     0.7515     54.9578
01000     0.8122      0.7511     0.7651     53.8881
01100     0.7881      0.7679     0.7706     56.3228
01200     0.8048      0.7511     0.7706     54.1940
01300     0.8684      0.7384     0.7812     55.0428
01400     0.7828      0.7278     0.7828     59.9340
01500     0.7228      0.7848     0.7895     59.7888
01600     0.7217      0.7637     0.7956     56.9025
01700     0.7790      0.7553     0.7956     54.1265
01800     0.7436      0.7764     0.7956     53.5276
01900     0.6978      0.8122     0.7956     55.1312
02000     0.7519      0.7806     0.8013     54.8150
02100     0.7397      0.7679     0.8013     54.9514
02200     0.7141      0.7890     0.8077     54.4435
02300     0.6030      0.8333     0.8077     54.5374
02400     0.7242      0.7764     0.8077     54.3070
02500     0.7030      0.7975     0.8077     54.7385
02600     0.7295      0.7700     0.8140     54.2159
02700     0.5817      0.8207     0.8140     54.6945
02800     0.6438      0.7890     0.8140     55.3071
02900     0.6469      0.8207     0.8140     55.4722
03000     0.6463      0.8186     0.8140     55.6657
03100     0.6643      0.7975     0.8182     55.4646
03200     0.6680      0.7848     0.8182     55.1068
03300     0.6919      0.7848     0.8182     54.0654
03400     0.7115      0.7806     0.8196     55.1897
03500     0.7273      0.7954     0.8196     56.3214
03600     0.5498      0.8354     0.8196     54.2980
03700     0.6536      0.7954     0.8198     54.3744
03800     0.6357      0.7996     0.8198     54.1478
03900     0.7060      0.8038     0.8198     53.9348
04000     0.6383      0.8101     0.8215     55.4751
04100     0.6194      0.8228     0.8217     54.9613
04200     0.5618      0.8397     0.8271     55.2991
04300     0.6110      0.8207     0.8271     54.3196
04400     0.6126      0.8186     0.8278     53.9934
04500     0.6474      0.8080     0.8278     54.7886
04600     0.7242      0.7553     0.8278     55.9845
04700     0.5838      0.7954     0.8278     54.3032
04800     0.6541      0.8017     0.8278     54.5271
04900     0.6565      0.8143     0.8290     54.3781
05000     0.6259      0.8165     0.8290     54.3870
05100     0.5810      0.8439     0.8306     55.2014
05200     0.6561      0.7975     0.8306     55.0859
05300     0.5524      0.8460     0.8306     54.3871
05400     0.6594      0.8017     0.8306     54.8720
05500     0.6279      0.8017     0.8306     55.4895
05600     0.6704      0.7869     0.8306     55.9616
05700     0.6409      0.7954     0.8306     53.9081
05800     0.6664      0.7932     0.8306     54.1521
05900     0.5283      0.8481     0.8306     54.6927
06000     0.6040      0.8228     0.8306     54.1110
06100     0.6243      0.8165     0.8306     54.7345
06200     0.6161      0.8312     0.8346     55.4447
06300     0.6046      0.8122     0.8346     53.9396
06400     0.7096      0.7679     0.8346     54.7655
06500     0.5210      0.8544     0.8346     53.9985
06600     0.6390      0.8017     0.8346     55.8390
06700     0.6577      0.7996     0.8346     55.8156
06800     0.6445      0.8059     0.8346     54.4558
06900     0.5581      0.8439     0.8346     54.3423
07000     0.5899      0.8101     0.8346     54.2985
07100     0.5940      0.8228     0.8346     54.5711
07200     0.6942      0.7827     0.8346     55.3016
07300     0.5825      0.8165     0.8346     54.3389
07400     0.6282      0.8101     0.8346     53.9749
07500     0.5390      0.8376     0.8346     54.2474
07600     0.5729      0.8186     0.8346     53.7938
07700     0.5173      0.8502     0.8346     53.3530
07800     0.5499      0.8502     0.8346     53.9881
07900     0.5667      0.8228     0.8346     54.4625
08000     0.5236      0.8629     0.8346     55.0808
08100     0.6666      0.7932     0.8346     55.3709
08200     0.5728      0.8228     0.8346     54.9554
08300     0.6322      0.8059     0.8346     54.6913
08400     0.5304      0.8523     0.8378     53.7130
08500     0.6031      0.8080     0.8378     55.7218
08600     0.6470      0.8059     0.8378     54.1689
08700     0.5835      0.8291     0.8391     53.9289
08800     0.6073      0.7975     0.8391     54.3746
08900     0.5099      0.8312     0.8391     55.5922
09000     0.6069      0.8291     0.8391     55.1791
09100     0.5590      0.8291     0.8391     55.7565
09200     0.5971      0.8143     0.8391     53.9458
09300     0.5629      0.8228     0.8391     54.4522
09400     0.5846      0.8207     0.8391     53.7299
09500     0.4893      0.8608     0.8428     54.2156
09600     0.5991      0.8207     0.8428     54.4375
09700     0.6017      0.8122     0.8428     53.4884
09800     0.5271      0.8333     0.8428     53.6045
09900     0.5701      0.8397     0.8428     55.4398
10000     0.6169      0.8059     0.8428     54.4105
10100     0.5164      0.8502     0.8428     54.3401
10200     0.5504      0.8354     0.8428     54.5975
10300     0.5231      0.8333     0.8428     54.3661
10400     0.5670      0.8249     0.8428     54.3013
10500     0.5204      0.8333     0.8428     54.4376
10600     0.5557      0.8333     0.8428     54.2364
10700     0.5899      0.8460     0.8428     54.4535
10800     0.5495      0.8354     0.8428     54.0369
10900     0.5824      0.8376     0.8428     54.4699
11000     0.4826      0.8523     0.8428     54.7031
11100     0.4663      0.8586     0.8428     54.9086
11200     0.5434      0.8291     0.8428     54.3019
11300     0.5361      0.8333     0.8428     54.9432
11400     0.5772      0.8143     0.8428     54.2475
11500     0.5834      0.8291     0.8428     54.7940
11600     0.5991      0.8207     0.8428     55.4147
11700     0.6949      0.7743     0.8428     55.2467
11800     0.6239      0.8059     0.8428     54.0961
11900     0.5477      0.8270     0.8428     53.7055
