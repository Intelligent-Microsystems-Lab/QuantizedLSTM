Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
86042be6-e2cf-440e-a769-17cc8f7936f5
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
1192ea87-9306-4869-b8e4-dd66ab49485a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
d6116b5e-cece-4644-962b-cc0052437cb4
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
f3d59b59-f296-41e2-bc9e-3ac3fd250f7b
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8226      0.0738     0.0876     9.7697
00100     2.3679      0.2173     0.2548     67.6565
00200     1.8556      0.3819     0.4247     68.3693
00300     1.5161      0.5042     0.5308     67.9150
00400     1.3947      0.5591     0.6106     67.6879
00500     1.1697      0.6181     0.6550     67.3886
00600     1.1055      0.6772     0.6809     67.2068
00700     0.9934      0.7089     0.7056     66.9744
00800     0.9944      0.6878     0.7235     67.5473
00900     1.0187      0.6899     0.7330     66.5955
01000     0.9411      0.7110     0.7465     67.2067
01100     0.9501      0.7363     0.7465     66.9515
01200     0.8823      0.7574     0.7604     67.7742
01300     0.8612      0.7321     0.7610     66.4725
01400     0.9051      0.7489     0.7691     66.7661
01500     0.8415      0.7384     0.7760     66.7970
01600     0.8383      0.7342     0.7829     67.0329
01700     0.7697      0.7658     0.7840     66.9379
01800     0.8284      0.7553     0.7840     66.6075
01900     0.7104      0.7932     0.7873     67.4511
02000     0.8062      0.7700     0.7873     66.8680
02100     0.7123      0.7764     0.7899     66.6587
02200     0.7084      0.7722     0.7899     66.6402
02300     0.7454      0.7637     0.7899     66.1562
02400     0.6891      0.8080     0.7918     67.3442
02500     0.7912      0.7743     0.8026     67.1487
02600     0.7616      0.7764     0.8026     66.7292
02700     0.6928      0.7954     0.8026     67.3539
02800     0.7641      0.7722     0.8026     66.8892
02900     0.8331      0.7489     0.8026     67.5301
03000     0.7150      0.7806     0.8026     67.7838
03100     0.7593      0.7679     0.8053     67.5096
03200     0.7217      0.7743     0.8053     67.9797
03300     0.6498      0.8059     0.8053     66.7223
03400     0.7536      0.7574     0.8053     66.8426
03500     0.7176      0.7785     0.8057     68.1216
03600     0.7137      0.7869     0.8057     67.0848
03700     0.7185      0.7932     0.8057     66.9496
03800     0.6968      0.7932     0.8129     67.3572
03900     0.7230      0.7869     0.8129     66.6791
04000     0.6760      0.8059     0.8129     67.5266
04100     0.6266      0.8143     0.8129     67.5054
04200     0.6676      0.8038     0.8129     67.9786
04300     0.7041      0.7975     0.8129     67.0938
04400     0.6858      0.8186     0.8129     67.4511
04500     0.6144      0.8101     0.8129     66.8586
04600     0.7244      0.7722     0.8129     67.2329
04700     0.6024      0.8249     0.8129     65.1649
04800     0.6671      0.8101     0.8129     65.6568
04900     0.6549      0.7954     0.8135     66.4915
05000     0.6625      0.7890     0.8173     66.8342
05100     0.6984      0.7911     0.8173     66.1783
05200     0.6589      0.8143     0.8204     66.4114
05300     0.6993      0.8122     0.8204     65.9688
05400     0.6623      0.7996     0.8204     66.7321
05500     0.6659      0.8207     0.8204     66.8535
05600     0.5782      0.8186     0.8213     67.0361
05700     0.6939      0.7911     0.8213     67.5227
05800     0.7035      0.7869     0.8215     66.5011
05900     0.6215      0.8122     0.8215     66.7278
06000     0.6726      0.7932     0.8215     66.0398
06100     0.6831      0.7785     0.8215     66.1179
06200     0.6735      0.8038     0.8215     66.5945
06300     0.6076      0.8186     0.8215     66.3070
06400     0.6330      0.8101     0.8224     66.3703
06500     0.6702      0.8038     0.8224     65.8985
06600     0.6616      0.7954     0.8250     66.6220
06700     0.6648      0.8059     0.8250     67.0222
06800     0.5963      0.8122     0.8250     67.1275
06900     0.5838      0.8291     0.8250     67.0151
07000     0.6770      0.7975     0.8250     67.0402
07100     0.6520      0.8059     0.8250     66.1424
07200     0.6780      0.7911     0.8250     66.8427
07300     0.7068      0.7954     0.8250     66.4137
07400     0.6412      0.8080     0.8250     66.6379
07500     0.5856      0.8376     0.8250     66.6560
07600     0.7107      0.7890     0.8250     67.0446
07700     0.5253      0.8481     0.8250     66.7367
07800     0.6457      0.8038     0.8295     66.9896
07900     0.7319      0.7806     0.8295     66.5981
08000     0.6190      0.8354     0.8295     66.5772
08100     0.6295      0.8080     0.8295     67.3052
08200     0.5302      0.8460     0.8323     66.6547
08300     0.5663      0.8186     0.8323     67.3506
08400     0.6180      0.8017     0.8323     66.9016
08500     0.6461      0.8186     0.8323     66.6128
08600     0.6516      0.8080     0.8323     66.3325
08700     0.6492      0.8038     0.8323     67.0653
08800     0.6806      0.7932     0.8323     67.6715
08900     0.6678      0.7954     0.8323     67.0617
09000     0.5844      0.8270     0.8323     66.7806
09100     0.5899      0.8228     0.8323     67.3225
09200     0.6420      0.8101     0.8323     66.8801
09300     0.6248      0.8059     0.8323     67.3662
09400     0.6709      0.7848     0.8323     67.1781
09500     0.6459      0.8017     0.8323     67.7618
09600     0.5468      0.8376     0.8323     66.9748
09700     0.5697      0.8249     0.8323     67.4083
09800     0.5533      0.8418     0.8323     67.3227
09900     0.5717      0.8228     0.8323     67.1452
10000     0.5893      0.8228     0.8323     67.0913
10100     0.6203      0.8228     0.8323     67.9463
10200     0.5474      0.8270     0.8323     67.3794
10300     0.5538      0.8249     0.8346     67.5052
10400     0.5636      0.8249     0.8346     67.5486
10500     0.5081      0.8565     0.8346     66.9604
10600     0.5786      0.8186     0.8346     66.8939
10700     0.5646      0.8143     0.8346     68.0433
10800     0.5621      0.8460     0.8346     67.4064
10900     0.6127      0.8017     0.8346     68.6392
11000     0.4938      0.8523     0.8346     67.5144
11100     0.5503      0.8249     0.8346     67.5370
11200     0.4940      0.8460     0.8346     67.2982
11300     0.5960      0.8165     0.8346     68.8048
11400     0.5855      0.8228     0.8346     66.5905
11500     0.5948      0.8354     0.8346     67.4440
11600     0.6581      0.7975     0.8352     67.6646
11700     0.6293      0.8122     0.8352     67.1504
11800     0.6112      0.7975     0.8352     66.6525
11900     0.5729      0.8312     0.8352     66.9224
12000     0.5002      0.8565     0.8357     67.9795
12100     0.5458      0.8439     0.8357     67.3209
12200     0.5509      0.8312     0.8357     68.2077
12300     0.5604      0.8418     0.8357     68.5636
12400     0.6114      0.8207     0.8357     66.6690
12500     0.6047      0.7996     0.8357     67.3934
12600     0.5974      0.8165     0.8357     67.7964
12700     0.5821      0.8228     0.8357     67.6868
12800     0.5605      0.8376     0.8357     66.9312
12900     0.5528      0.8333     0.8357     67.3006
13000     0.5804      0.8165     0.8367     67.0784
13100     0.5317      0.8565     0.8395     67.0770
13200     0.5559      0.8523     0.8395     67.3730
13300     0.5327      0.8565     0.8395     68.2462
13400     0.5026      0.8565     0.8395     67.4787
13500     0.6157      0.7996     0.8395     67.8234
13600     0.5718      0.8291     0.8410     68.6520
13700     0.5694      0.8291     0.8410     67.2539
13800     0.5952      0.8376     0.8410     66.6866
13900     0.5453      0.8439     0.8410     68.3817
14000     0.6142      0.8270     0.8410     67.8382
14100     0.5397      0.8397     0.8410     66.9252
14200     0.5136      0.8481     0.8410     66.9884
14300     0.5370      0.8460     0.8410     66.9352
14400     0.6051      0.8038     0.8410     68.2414
14500     0.5867      0.8418     0.8410     66.7139
14600     0.5694      0.8312     0.8410     66.5435
14700     0.5944      0.8165     0.8410     67.1826
14800     0.5899      0.8228     0.8410     67.8197
14900     0.5828      0.8186     0.8410     67.2865
15000     0.5290      0.8418     0.8410     67.7566
15100     0.5282      0.8565     0.8410     67.9762
15200     0.5663      0.8397     0.8410     68.0098
15300     0.5499      0.8165     0.8410     67.4342
15400     0.5413      0.8207     0.8410     67.4116
15500     0.7060      0.7954     0.8410     68.3981
15600     0.5972      0.8460     0.8410     68.1538
15700     0.5918      0.8439     0.8410     68.0887
15800     0.6763      0.7890     0.8410     67.3488
15900     0.5530      0.8312     0.8410     67.0361
16000     0.5527      0.8354     0.8410     67.6997
16100     0.6371      0.7975     0.8410     66.6129
16200     0.6389      0.8143     0.8410     67.2130
16300     0.5755      0.8165     0.8410     67.4417
16400     0.5506      0.8249     0.8410     67.1411
16500     0.4753      0.8671     0.8410     67.9183
16600     0.5946      0.8059     0.8410     67.5169
16700     0.4568      0.8692     0.8410     67.8221
16800     0.5274      0.8249     0.8467     68.1765
16900     0.6410      0.8143     0.8467     66.7947
17000     0.6818      0.7890     0.8467     66.3998
17100     0.5321      0.8544     0.8467     67.7447
17200     0.5883      0.8312     0.8467     67.0237
17300     0.6356      0.8059     0.8467     67.3801
17400     0.5718      0.8165     0.8467     67.8232
17500     0.6464      0.8101     0.8467     68.6273
17600     0.6260      0.8101     0.8467     67.3889
17700     0.5467      0.8376     0.8467     67.6160
17800     0.5939      0.8207     0.8467     67.2636
17900     0.5768      0.8270     0.8467     67.3601
18000     0.5664      0.8270     0.8467     68.6199
18100     0.5111      0.8481     0.8467     67.5443
18200     0.5481      0.8228     0.8467     68.1622
18300     0.5745      0.8312     0.8467     68.2337
18400     0.5547      0.8418     0.8467     67.5664
18500     0.4638      0.8586     0.8467     66.1516
18600     0.6371      0.8165     0.8467     66.6411
18700     0.5761      0.8354     0.8467     67.6963
18800     0.5463      0.8565     0.8467     67.2003
18900     0.6279      0.8143     0.8467     67.2382
19000     0.4757      0.8650     0.8467     67.5082
19100     0.4617      0.8776     0.8467     67.3913
19200     0.5161      0.8460     0.8467     68.3045
19300     0.6195      0.8291     0.8467     67.3306
19400     0.5083      0.8586     0.8467     67.6072
19500     0.5207      0.8650     0.8467     67.6064
19600     0.5947      0.8143     0.8467     67.0843
19700     0.5622      0.8228     0.8467     67.2681
19800     0.6339      0.8101     0.8467     67.4325
19900     0.5928      0.8080     0.8467     67.2458
20000     0.5794      0.8354     0.8467     67.3814
20100     0.5428      0.8291     0.8467     67.5093
20199     0.5813      0.8249     0.8467     66.2207
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.5367      0.8312     0.8345     9.4145
00100     0.3665      0.8903     0.8483     65.0717
00200     0.4996      0.8502     0.8483     66.9898
00300     0.5078      0.8460     0.8483     66.0662
00400     0.4200      0.8734     0.8483     65.8621
00500     0.4490      0.8692     0.8483     66.8238
00600     0.4245      0.8861     0.8483     66.6064
00700     0.4392      0.8629     0.8483     67.4658
00800     0.4407      0.8692     0.8483     67.0290
00900     0.5505      0.8354     0.8483     66.6192
01000     0.4347      0.8797     0.8483     66.8729
01100     0.4776      0.8586     0.8483     66.8264
01200     0.5377      0.8481     0.8483     66.3217
01300     0.4722      0.8608     0.8483     66.5312
01400     0.5192      0.8376     0.8490     66.3174
01500     0.4870      0.8671     0.8490     66.2824
01600     0.5253      0.8418     0.8490     66.2575
01700     0.4782      0.8713     0.8490     67.6840
01800     0.3926      0.9008     0.8490     66.5690
01900     0.3923      0.8903     0.8490     66.3791
02000     0.5127      0.8460     0.8490     67.4938
02100     0.4504      0.8755     0.8490     65.9356
02200     0.4566      0.8755     0.8500     66.5928
02300     0.4618      0.8819     0.8500     66.2395
02400     0.3964      0.9008     0.8500     66.8104
02500     0.4835      0.8586     0.8500     67.2365
02600     0.4928      0.8439     0.8500     67.1993
02700     0.4272      0.8840     0.8500     67.0267
02800     0.4733      0.8502     0.8500     67.6572
02900     0.4408      0.8819     0.8500     66.7848
03000     0.5134      0.8376     0.8500     67.4249
03100     0.4970      0.8755     0.8500     68.0612
03200     0.4602      0.8734     0.8500     66.9156
03300     0.4611      0.8418     0.8500     67.6840
03400     0.4323      0.8586     0.8500     66.9333
03500     0.5245      0.8523     0.8500     67.3310
03600     0.4291      0.8755     0.8500     66.9315
03700     0.5729      0.8270     0.8500     66.6569
03800     0.4391      0.8713     0.8500     66.9828
03900     0.4280      0.8776     0.8500     66.2611
04000     0.5503      0.8249     0.8500     66.2080
04100     0.4601      0.8797     0.8500     66.7469
04200     0.4464      0.8713     0.8500     66.3333
04300     0.4479      0.8797     0.8500     67.1942
04400     0.4585      0.8586     0.8500     67.1727
04500     0.4627      0.8586     0.8500     67.0256
04600     0.4830      0.8692     0.8500     66.9457
04700     0.4946      0.8544     0.8500     66.7976
04800     0.4155      0.8987     0.8500     66.8154
04900     0.4798      0.8586     0.8500     67.2571
05000     0.4850      0.8460     0.8500     66.8515
05100     0.4122      0.8840     0.8500     67.6325
05200     0.5089      0.8629     0.8512     67.2493
05300     0.4374      0.8650     0.8512     65.7032
05400     0.4472      0.8565     0.8512     67.8090
05500     0.4539      0.8650     0.8512     67.3094
05600     0.4748      0.8565     0.8512     66.3022
05700     0.5035      0.8502     0.8512     67.7245
05800     0.4300      0.8819     0.8512     66.8850
05900     0.4898      0.8523     0.8512     67.2255
06000     0.4572      0.8629     0.8512     67.0944
06100     0.4840      0.8565     0.8512     67.1119
06200     0.4327      0.8861     0.8512     68.5067
06300     0.4884      0.8608     0.8512     67.0946
06400     0.4169      0.8924     0.8512     67.7417
06500     0.4886      0.8629     0.8512     67.4835
06600     0.4805      0.8692     0.8512     67.6917
06700     0.5484      0.8460     0.8512     67.3313
06800     0.5383      0.8397     0.8512     68.2351
06900     0.3561      0.8924     0.8512     67.2985
07000     0.4802      0.8629     0.8512     67.9358
07100     0.5234      0.8397     0.8512     67.5823
07200     0.4563      0.8650     0.8512     68.3584
07300     0.5448      0.8523     0.8512     68.1010
07400     0.5216      0.8439     0.8512     67.3931
07500     0.3997      0.8840     0.8512     67.5355
07600     0.4948      0.8481     0.8512     67.1960
07700     0.4217      0.8734     0.8512     68.1964
07800     0.4595      0.8481     0.8512     67.9685
07900     0.4986      0.8333     0.8512     67.1458
08000     0.4817      0.8734     0.8512     68.0205
08100     0.4725      0.8544     0.8512     67.7626
08200     0.4464      0.8629     0.8512     66.7954
08300     0.4288      0.8797     0.8512     67.7898
08400     0.4231      0.8713     0.8512     67.4232
08500     0.4165      0.8840     0.8512     67.0879
08600     0.5038      0.8460     0.8512     67.9595
08700     0.4509      0.8755     0.8512     67.0098
08800     0.4709      0.8650     0.8512     66.3388
08900     0.4510      0.8671     0.8512     67.0883
09000     0.4866      0.8481     0.8512     67.6191
09100     0.4427      0.8713     0.8512     67.6109
09200     0.4499      0.8650     0.8512     66.9908
09300     0.4540      0.8629     0.8512     67.8907
09400     0.5019      0.8544     0.8512     68.6999
09500     0.4472      0.8755     0.8512     68.1031
09600     0.4785      0.8586     0.8559     67.9148
09700     0.5521      0.8312     0.8559     67.7733
09800     0.4574      0.8734     0.8559     67.7637
09900     0.4370      0.8608     0.8559     68.0386
Start testing:
Test Accuracy: 0.8374
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=193012823, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
63751c88-f1c0-4c60-82ef-2f75a6a052b5
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.7948      0.0844     0.0629     11.3275
00100     1.3460      0.5612     0.5977     56.9184
00200     0.8228      0.7384     0.7617     55.8119
00300     0.6701      0.8017     0.8179     56.0164
00400     0.6135      0.8165     0.8410     55.8657
00500     0.5573      0.8207     0.8448     56.7862
00600     0.4717      0.8608     0.8470     56.4464
00700     0.4929      0.8502     0.8510     56.1053
00800     0.4624      0.8713     0.8636     56.1020
00900     0.4430      0.8776     0.8652     57.0785
01000     0.3926      0.8861     0.8722     56.5641
01100     0.3686      0.8882     0.8795     56.5797
01200     0.3730      0.8924     0.8896     58.3035
01300     0.3115      0.9325     0.8896     55.7655
01400     0.3450      0.9093     0.8896     56.1213
01500     0.3651      0.8903     0.8896     55.5905
01600     0.2984      0.9177     0.8968     56.1596
01700     0.3074      0.9156     0.8968     55.5011
01800     0.3103      0.9135     0.8968     55.9985
01900     0.3655      0.8924     0.8968     56.8096
02000     0.3159      0.8987     0.8968     54.9827
02100     0.2832      0.9114     0.8968     56.2112
02200     0.2697      0.9219     0.8968     56.5804
02300     0.2659      0.9241     0.8968     56.5637
02400     0.2916      0.9156     0.8968     56.7432
02500     0.2542      0.9093     0.8968     55.3828
02600     0.2581      0.9346     0.8976     55.3357
02700     0.2512      0.9219     0.8976     55.5651
02800     0.2521      0.9473     0.8976     55.3753
02900     0.2752      0.9304     0.8976     56.6182
03000     0.2674      0.9156     0.8976     56.5940
03100     0.2074      0.9451     0.8976     56.1010
03200     0.1798      0.9494     0.8979     55.8601
03300     0.2811      0.9156     0.8979     56.3897
03400     0.2444      0.9367     0.8979     55.1375
03500     0.2028      0.9367     0.8983     56.8792
03600     0.1982      0.9409     0.8983     55.9932
03700     0.2188      0.9367     0.8985     55.3643
03800     0.1975      0.9367     0.8994     56.6979
03900     0.2372      0.9262     0.8994     57.3372
04000     0.2111      0.9451     0.8994     56.2640
04100     0.2035      0.9388     0.8994     56.0687
04200     0.1552      0.9620     0.8994     55.1128
04300     0.2650      0.9219     0.9051     56.1451
04400     0.2253      0.9409     0.9051     56.4003
04500     0.1681      0.9536     0.9051     57.2126
04600     0.2477      0.9367     0.9071     57.0451
04700     0.1506      0.9620     0.9071     55.6333
04800     0.2317      0.9409     0.9071     58.1021
04900     0.1742      0.9599     0.9076     56.6600
05000     0.1863      0.9515     0.9076     55.6586
05100     0.1824      0.9515     0.9076     58.1931
05200     0.2132      0.9451     0.9089     55.6148
05300     0.1952      0.9494     0.9089     54.9145
05400     0.1547      0.9557     0.9089     55.4753
05500     0.2075      0.9388     0.9089     56.0400
05600     0.2001      0.9451     0.9089     55.4041
05700     0.1588      0.9662     0.9089     55.2786
05800     0.2023      0.9451     0.9089     55.1565
05900     0.1895      0.9536     0.9089     56.6480
06000     0.1919      0.9557     0.9089     56.2181
06100     0.1809      0.9494     0.9089     56.8285
06200     0.1860      0.9494     0.9089     55.5340
06300     0.1586      0.9662     0.9105     56.2578
06400     0.1449      0.9599     0.9105     57.3775
06500     0.1935      0.9494     0.9105     55.7564
06600     0.1956      0.9451     0.9105     55.7987
06700     0.1581      0.9620     0.9105     57.3495
06800     0.1651      0.9641     0.9105     56.8347
06900     0.1894      0.9536     0.9105     55.7094
07000     0.1745      0.9599     0.9105     57.7427
07100     0.1575      0.9620     0.9105     55.2931
07200     0.1804      0.9473     0.9105     56.0742
07300     0.1453      0.9684     0.9105     55.7275
07400     0.1666      0.9662     0.9105     56.0668
07500     0.1882      0.9515     0.9105     56.3429
07600     0.1875      0.9536     0.9105     55.7270
07700     0.1600      0.9620     0.9105     55.5952
07800     0.1797      0.9578     0.9105     55.8583
07900     0.1401      0.9620     0.9105     55.5382
08000     0.1890      0.9536     0.9105     56.5043
08100     0.1846      0.9536     0.9105     56.0776
08200     0.2491      0.9409     0.9105     56.0535
08300     0.1888      0.9473     0.9105     56.6790
08400     0.1508      0.9641     0.9105     54.3003
08500     0.1663      0.9536     0.9105     56.4104
08600     0.1892      0.9451     0.9105     55.8226
08700     0.1940      0.9388     0.9105     55.4506
08800     0.1685      0.9536     0.9105     55.8988
08900     0.1709      0.9536     0.9105     55.4079
09000     0.1236      0.9705     0.9105     56.3780
09100     0.1404      0.9789     0.9105     56.0109
09200     0.1822      0.9599     0.9105     57.9327
09300     0.1574      0.9684     0.9105     55.4943
09400     0.1513      0.9620     0.9105     55.7300
09500     0.1541      0.9599     0.9105     55.4462
09600     0.1376      0.9641     0.9105     55.4000
09700     0.2147      0.9409     0.9105     55.5307
09800     0.1852      0.9494     0.9105     56.2187
09900     0.1368      0.9641     0.9105     54.9249
10000     0.1395      0.9620     0.9105     54.7301
10100     0.1378      0.9641     0.9152     55.5795
10200     0.1709      0.9557     0.9152     55.1292
10300     0.1436      0.9599     0.9152     55.5064
10400     0.1208      0.9684     0.9152     55.7045
10500     0.1496      0.9599     0.9152     55.5780
10600     0.1126      0.9684     0.9152     54.7180
10700     0.1577      0.9557     0.9152     56.4167
10800     0.1072      0.9789     0.9152     55.5979
10900     0.1596      0.9557     0.9152     55.4267
11000     0.1251      0.9641     0.9152     55.5891
11100     0.1159      0.9768     0.9152     56.4653
11200     0.1476      0.9662     0.9152     56.0087
11300     0.1469      0.9641     0.9152     55.8311
11400     0.1256      0.9747     0.9152     54.9216
11500     0.1413      0.9557     0.9152     56.0853
11600     0.1113      0.9705     0.9152     55.1579
11700     0.1183      0.9726     0.9152     55.7069
11800     0.1055      0.9768     0.9152     54.9959
11900     0.1305      0.9726     0.9152     55.5257
12000     0.1560      0.9620     0.9152     55.7000
12100     0.1538      0.9662     0.9152     54.4360
12200     0.1339      0.9684     0.9152     55.5690
12300     0.1663      0.9515     0.9152     55.6983
12400     0.1080      0.9810     0.9152     54.9709
12500     0.1064      0.9726     0.9152     55.2882
12600     0.0955      0.9852     0.9152     55.9292
12700     0.1479      0.9662     0.9152     54.9145
12800     0.1626      0.9662     0.9152     55.4150
12900     0.1344      0.9684     0.9152     55.2617
13000     0.1369      0.9620     0.9152     55.1654
13100     0.1375      0.9684     0.9152     55.2991
13200     0.1327      0.9662     0.9152     54.7402
13300     0.1500      0.9620     0.9152     55.3021
13400     0.1718      0.9536     0.9152     55.5080
13500     0.0786      0.9852     0.9152     56.3305
13600     0.1559      0.9684     0.9152     55.7301
13700     0.1288      0.9747     0.9152     54.4667
13800     0.1293      0.9620     0.9152     54.3647
13900     0.1505      0.9684     0.9152     55.7608
14000     0.1391      0.9726     0.9152     55.9057
14100     0.1222      0.9662     0.9152     55.9357
14200     0.1086      0.9831     0.9152     56.0985
14300     0.1205      0.9768     0.9152     55.0921
14400     0.1111      0.9768     0.9152     55.3008
14500     0.1162      0.9684     0.9152     54.1351
14600     0.1415      0.9662     0.9152     54.7553
14700     0.0863      0.9789     0.9152     56.0444
14800     0.1214      0.9620     0.9152     56.1068
14900     0.1040      0.9810     0.9152     54.7479
15000     0.0987      0.9789     0.9152     55.6012
15100     0.1069      0.9789     0.9152     56.0949
15200     0.1224      0.9768     0.9152     56.5223
15300     0.1300      0.9684     0.9152     54.6815
15400     0.1274      0.9747     0.9152     55.4856
15500     0.1092      0.9747     0.9152     55.2687
15600     0.1060      0.9726     0.9152     54.9173
15700     0.1461      0.9578     0.9152     55.7188
15800     0.0991      0.9810     0.9152     55.7036
15900     0.0856      0.9852     0.9152     54.9512
16000     0.1072      0.9768     0.9152     56.8362
16100     0.1659      0.9578     0.9152     54.7392
16200     0.1272      0.9641     0.9152     55.0508
16300     0.1058      0.9726     0.9152     55.0247
16400     0.1181      0.9768     0.9152     55.1295
16500     0.1002      0.9810     0.9152     54.4760
16600     0.1192      0.9684     0.9152     55.0317
16700     0.1589      0.9641     0.9152     54.7970
16800     0.1354      0.9641     0.9152     55.2371
16900     0.1451      0.9726     0.9152     55.2243
17000     0.1084      0.9747     0.9152     55.2199
17100     0.1176      0.9768     0.9152     55.5487
17200     0.1413      0.9599     0.9152     55.4999
17300     0.1018      0.9768     0.9152     55.4061
17400     0.1333      0.9768     0.9152     56.2437
17500     0.0934      0.9852     0.9152     55.3050
17600     0.1137      0.9768     0.9152     55.5297
17700     0.1148      0.9831     0.9152     55.5827
17800     0.1264      0.9684     0.9152     55.1709
17900     0.1092      0.9810     0.9152     55.5826
18000     0.1259      0.9684     0.9152     54.6151
18100     0.0861      0.9810     0.9152     54.2135
18200     0.0990      0.9768     0.9152     55.8808
18300     0.1382      0.9641     0.9152     54.7701
18400     0.0947      0.9789     0.9152     55.5536
18500     0.1140      0.9726     0.9152     55.0871
18600     0.1234      0.9726     0.9152     54.8762
18700     0.1505      0.9536     0.9152     56.0448
18800     0.1233      0.9684     0.9152     55.5925
18900     0.1479      0.9662     0.9152     55.2677
19000     0.0900      0.9810     0.9152     55.7573
19100     0.0864      0.9852     0.9152     54.5976
19200     0.1059      0.9768     0.9152     55.3557
19300     0.1214      0.9726     0.9152     55.3395
19400     0.1172      0.9726     0.9152     55.6091
19500     0.0977      0.9831     0.9152     54.9214
19600     0.1524      0.9641     0.9152     54.1878
19700     0.1276      0.9705     0.9152     54.8968
19800     0.1432      0.9684     0.9152     55.0766
19900     0.1267      0.9662     0.9152     54.9705
20000     0.0926      0.9768     0.9152     56.3832
20100     0.0848      0.9810     0.9152     54.8518
20199     0.1361      0.9705     0.9152     56.6472
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.0961      0.9789     0.9093     8.9868
00100     0.1065      0.9789     0.9095     55.7780
00200     0.0847      0.9852     0.9114     55.5302
00300     0.0841      0.9831     0.9114     55.6871
00400     0.0984      0.9768     0.9114     54.5907
00500     0.0968      0.9768     0.9114     54.5864
00600     0.0913      0.9810     0.9114     56.1343
00700     0.1011      0.9789     0.9114     55.3688
00800     0.0859      0.9789     0.9114     56.8949
00900     0.1042      0.9789     0.9114     56.5416
01000     0.1168      0.9726     0.9114     55.7465
01100     0.0812      0.9810     0.9114     56.0739
01200     0.0699      0.9873     0.9114     55.7398
01300     0.1152      0.9768     0.9114     57.1149
01400     0.1107      0.9747     0.9114     56.8487
01500     0.0985      0.9810     0.9114     55.9519
01600     0.1074      0.9768     0.9114     55.4772
01700     0.0700      0.9873     0.9114     56.1147
01800     0.1129      0.9768     0.9114     55.2090
01900     0.0807      0.9852     0.9114     56.0424
02000     0.0877      0.9810     0.9114     54.2528
02100     0.0777      0.9852     0.9114     54.6043
02200     0.0929      0.9768     0.9114     54.7656
02300     0.1273      0.9726     0.9114     56.4991
02400     0.0735      0.9831     0.9114     54.2162
02500     0.0685      0.9916     0.9114     55.9092
02600     0.0957      0.9768     0.9114     55.0933
02700     0.0952      0.9789     0.9114     55.2170
02800     0.0987      0.9810     0.9114     55.1775
02900     0.1054      0.9768     0.9114     56.2816
03000     0.0880      0.9831     0.9114     55.3313
03100     0.0883      0.9768     0.9114     54.4313
03200     0.0754      0.9895     0.9114     55.3136
03300     0.0941      0.9831     0.9114     56.0984
03400     0.1266      0.9641     0.9114     54.2604
03500     0.1485      0.9726     0.9114     55.4646
03600     0.0903      0.9810     0.9114     54.6733
03700     0.0730      0.9852     0.9114     56.0302
03800     0.0844      0.9810     0.9114     55.3693
03900     0.0794      0.9873     0.9114     56.1319
04000     0.0957      0.9768     0.9114     55.7384
04100     0.0984      0.9789     0.9114     55.2090
04200     0.1101      0.9747     0.9114     55.8799
04300     0.0890      0.9852     0.9114     55.8168
04400     0.0827      0.9831     0.9114     55.8375
04500     0.0719      0.9895     0.9114     56.4432
04600     0.0652      0.9916     0.9114     56.0420
04700     0.0980      0.9810     0.9114     54.3337
04800     0.0713      0.9895     0.9114     54.4847
04900     0.0734      0.9831     0.9114     55.4547
05000     0.0932      0.9831     0.9114     54.7458
05100     0.1154      0.9747     0.9114     55.7015
05200     0.0970      0.9768     0.9114     55.3074
05300     0.0899      0.9831     0.9114     55.4204
05400     0.0967      0.9810     0.9114     56.7173
05500     0.0829      0.9831     0.9114     54.9323
05600     0.0724      0.9831     0.9114     54.8894
05700     0.0819      0.9831     0.9114     56.3765
05800     0.0865      0.9873     0.9114     55.4574
05900     0.0888      0.9810     0.9114     55.6353
06000     0.0798      0.9916     0.9114     55.4951
06100     0.0769      0.9852     0.9114     55.6838
06200     0.0821      0.9895     0.9114     55.9135
06300     0.0917      0.9810     0.9114     54.3769
06400     0.0809      0.9852     0.9114     55.9403
06500     0.0695      0.9873     0.9114     55.1884
06600     0.0863      0.9789     0.9114     54.8623
06700     0.1067      0.9726     0.9114     55.6372
06800     0.0928      0.9789     0.9114     54.4320
06900     0.0648      0.9895     0.9114     56.4751
07000     0.0902      0.9831     0.9114     55.6006
07100     0.1080      0.9747     0.9114     55.5862
07200     0.0991      0.9747     0.9114     55.5857
07300     0.0909      0.9831     0.9114     54.7666
07400     0.0609      0.9916     0.9114     56.6261
07500     0.0902      0.9768     0.9114     55.9434
07600     0.0884      0.9810     0.9114     55.5141
07700     0.0740      0.9873     0.9114     55.4956
07800     0.0858      0.9789     0.9114     55.3434
07900     0.1227      0.9684     0.9114     54.6308
08000     0.0949      0.9726     0.9114     55.5723
08100     0.0982      0.9768     0.9114     56.8528
08200     0.0608      0.9916     0.9114     55.7358
08300     0.0541      0.9958     0.9114     54.7974
08400     0.1038      0.9852     0.9114     55.8502
08500     0.0897      0.9810     0.9114     55.2697
08600     0.0717      0.9852     0.9114     55.9386
08700     0.0800      0.9831     0.9114     54.9901
08800     0.0834      0.9810     0.9114     54.7444
08900     0.0807      0.9810     0.9114     55.0299
09000     0.0835      0.9831     0.9114     55.0029
09100     0.0763      0.9873     0.9114     55.0496
09200     0.0807      0.9831     0.9114     55.4776
09300     0.0988      0.9810     0.9114     55.3602
09400     0.0959      0.9873     0.9114     57.2609
09500     0.0823      0.9873     0.9114     56.6153
09600     0.1084      0.9768     0.9114     54.6276
09700     0.0881      0.9831     0.9114     54.6213
09800     0.0880      0.9873     0.9114     55.4875
09900     0.0931      0.9852     0.9114     56.4054
Start testing:
Test Accuracy: 0.8995
