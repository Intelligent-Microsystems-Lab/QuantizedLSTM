Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(batch_size=256, cy_div=2, cy_scale=2, dataloader_num_workers=4, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', epochs=50000, global_beta=1.5, hidden=256, hop_length=320, hp_bw=False, init_factor=2, learning_rate=0.0005, lr_divide=15000, n_mfcc=40, noise_injection=0.1, quant_actMVM=6, quant_actNM=8, quant_inp=4, quant_w=None, sample_rate=16000, std_scale=4, testing_percentage=10, validation_percentage=10, validation_size=10000, win_length=400, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
a7cfc331-2389-49f4-a93a-92ab923b5f98
Start Training:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 405, in <module>
    output = model(x_data, train = False)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "KWS_LSTM.py", line 314, in forward
    lstm_out, self.hidden_state = self.lstmL(inputs, self.hidden_state, train)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "KWS_LSTM.py", line 260, in forward
    return torch.stack(outputs), state
RuntimeError: CUDA out of memory. Tried to allocate 500.00 MiB (GPU 0; 11.78 GiB total capacity; 10.55 GiB already allocated; 125.38 MiB free; 10.59 GiB reserved in total by PyTorch)
