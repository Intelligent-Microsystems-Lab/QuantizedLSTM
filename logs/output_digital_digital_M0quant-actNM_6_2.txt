Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=6, quant_actNM=6, quant_inp=6, quant_w=6, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
7e8d83ef-7659-4943-9694-ab217ecf133c
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=6, quant_actNM=6, quant_inp=6, quant_w=6, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
23339709-59e5-496f-8b05-ef3c0f676f59
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=6, quant_actNM=6, quant_inp=6, quant_w=6, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
cae6a39f-3e92-403c-bf98-242e34a029fb
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8566      0.0949     0.0767     10.5175
00100     2.2189      0.2764     0.3367     71.3921
00200     1.8437      0.3924     0.4188     71.6640
00300     1.6528      0.4684     0.5208     71.9291
00400     1.4597      0.5316     0.5432     71.5037
00500     1.3729      0.5696     0.5772     71.6336
00600     1.2695      0.5949     0.6300     71.8411
00700     1.2796      0.5949     0.6399     72.3346
00800     1.1906      0.6118     0.6463     72.5140
00900     1.1066      0.6519     0.6798     71.6695
01000     1.1684      0.6203     0.6891     71.6180
01100     1.1068      0.6624     0.7067     72.0007
01200     1.0841      0.6540     0.7083     72.8505
01300     1.1157      0.6646     0.7125     71.7438
01400     0.9623      0.6983     0.7269     72.3685
01500     0.9015      0.7405     0.7276     71.9698
01600     0.9749      0.6730     0.7287     71.8531
01700     0.9818      0.6878     0.7396     71.9242
01800     0.9071      0.7131     0.7396     71.8720
01900     0.8843      0.7278     0.7449     73.1212
02000     0.9474      0.7300     0.7523     71.9744
02100     0.9689      0.6857     0.7523     71.4115
02200     0.9419      0.7025     0.7544     72.3521
02300     0.8316      0.7700     0.7559     71.5391
02400     0.9555      0.7384     0.7674     71.9724
02500     0.9416      0.7152     0.7674     71.1140
02600     0.9143      0.7236     0.7674     71.8727
02700     0.8461      0.7215     0.7674     71.7647
02800     0.8240      0.7574     0.7686     71.7046
02900     0.8995      0.7236     0.7686     71.5100
03000     0.8741      0.7257     0.7744     71.7334
03100     0.9334      0.7405     0.7744     70.8708
03200     0.8799      0.7300     0.7802     71.8656
03300     0.8612      0.7363     0.7808     71.3993
03400     0.9053      0.7257     0.7814     71.8433
03500     1.0249      0.7046     0.7814     71.7154
03600     0.8498      0.7426     0.7814     72.4698
03700     0.8321      0.7511     0.7814     72.2213
03800     0.7391      0.7743     0.7814     72.1854
03900     0.8678      0.7342     0.7814     71.8935
04000     0.7588      0.8017     0.7814     72.4316
04100     0.8080      0.7911     0.7814     72.2094
04200     0.8532      0.7278     0.7814     71.8406
04300     0.7963      0.7468     0.7814     71.1808
04400     0.8728      0.7616     0.7814     71.3488
04500     0.8922      0.7363     0.7814     71.7303
04600     0.9064      0.7300     0.7814     72.2533
04700     0.7860      0.7511     0.7829     71.4486
04800     0.7936      0.7658     0.7829     71.6674
04900     0.8692      0.7489     0.7848     72.0901
05000     0.8590      0.7342     0.7848     71.3569
05100     0.8041      0.7637     0.7848     72.1554
05200     0.8734      0.7405     0.7848     71.9463
05300     0.7274      0.7806     0.7848     71.6183
05400     0.7960      0.7574     0.7848     72.0890
05500     0.8455      0.7342     0.7848     71.3278
05600     0.7807      0.7574     0.7848     72.1151
05700     0.8069      0.7574     0.7848     72.0966
05800     0.8723      0.7574     0.7942     75.0635
05900     0.7648      0.7827     0.7942     73.1114
06000     0.8021      0.7764     0.7942     72.1967
06100     0.6783      0.7996     0.7942     72.0331
06200     0.7471      0.7764     0.7961     72.4198
06300     0.7795      0.7679     0.7961     71.8256
06400     0.9201      0.7194     0.7961     72.4088
06500     0.7805      0.7616     0.7961     72.1864
06600     0.8357      0.7321     0.7961     71.8537
06700     0.8859      0.7194     0.7961     72.1030
06800     0.8029      0.7321     0.7961     70.4094
06900     0.7188      0.7848     0.7961     70.5124
07000     0.7468      0.7785     0.7961     72.0071
07100     0.7531      0.7848     0.7965     71.8245
07200     0.8665      0.7342     0.7965     72.3918
07300     0.7766      0.7574     0.7965     72.2572
07400     0.8215      0.7637     0.7965     71.5936
07500     0.7435      0.7679     0.7978     72.6432
07600     0.8089      0.7679     0.7989     72.4462
07700     0.8463      0.7743     0.7989     71.1843
07800     0.8511      0.7785     0.7989     72.1697
07900     0.7217      0.7890     0.7989     71.9786
08000     0.6774      0.7806     0.7989     72.6532
08100     0.7902      0.7489     0.7989     72.0497
08200     0.7483      0.7595     0.7989     72.1409
08300     0.7776      0.7658     0.8031     72.6157
08400     0.7945      0.7700     0.8031     72.5164
08500     0.7251      0.7848     0.8031     72.3367
08600     0.7724      0.7785     0.8031     73.3925
08700     0.7748      0.7679     0.8031     72.4673
08800     0.7538      0.7827     0.8031     72.6616
08900     0.7537      0.7679     0.8031     72.5546
09000     0.7954      0.7278     0.8031     72.3679
09100     0.7525      0.7911     0.8031     72.6823
09200     0.7891      0.7679     0.8031     72.5542
09300     0.8017      0.7679     0.8031     72.5339
09400     0.8157      0.7511     0.8031     72.1361
09500     0.8473      0.7426     0.8031     72.4183
09600     0.7712      0.7574     0.8031     74.8770
09700     0.8312      0.7595     0.8031     79.9025
09800     0.7110      0.7975     0.8031     76.6981
09900     0.7854      0.7806     0.8031     79.1682
10000     0.8288      0.7384     0.8031     79.6045
10100     0.7135      0.7932     0.8031     79.3289
10200     0.7311      0.8017     0.8031     79.9347
10300     0.7229      0.8017     0.8031     79.0510
10400     0.7774      0.7869     0.8065     79.1166
10500     0.8300      0.7722     0.8065     80.8081
10600     0.7526      0.7848     0.8065     77.7469
10700     0.7316      0.7954     0.8065     79.5677
10800     0.8296      0.7553     0.8065     77.1513
10900     0.6960      0.7890     0.8065     77.7268
11000     0.7080      0.8017     0.8065     77.5188
11100     0.6509      0.8249     0.8065     76.9658
11200     0.7392      0.7722     0.8065     79.1473
11300     0.6814      0.7996     0.8065     77.6775
11400     0.7412      0.7848     0.8065     78.2185
11500     0.7997      0.7848     0.8065     77.9089
11600     0.8774      0.7236     0.8065     77.0220
11700     0.8367      0.7532     0.8065     77.9208
11800     0.7380      0.7743     0.8065     78.1232
11900     0.7730      0.7511     0.8065     77.2000
12000     0.7679      0.7890     0.8065     78.3416
12100     0.8418      0.7574     0.8065     78.7776
12200     0.7857      0.7743     0.8065     77.3083
12300     0.7245      0.7932     0.8065     78.2797
12400     0.7516      0.7848     0.8065     78.3503
12500     0.8408      0.7468     0.8065     77.7632
12600     0.8093      0.7574     0.8065     78.4285
12700     0.7817      0.7722     0.8065     78.5116
12800     0.7508      0.7848     0.8065     80.8434
12900     0.7326      0.7890     0.8065     77.6374
13000     0.7551      0.7890     0.8065     76.5277
13100     0.7298      0.7806     0.8065     78.6611
13200     0.7837      0.7637     0.8065     77.4044
13300     0.6583      0.7848     0.8065     78.3225
13400     0.7948      0.7426     0.8072     77.9172
13500     0.7852      0.7658     0.8072     78.8684
13600     0.7234      0.7700     0.8072     78.7370
13700     0.7074      0.7679     0.8084     76.1611
13800     0.7530      0.7869     0.8084     76.9575
13900     0.8210      0.7511     0.8084     77.8010
14000     0.6733      0.8228     0.8084     76.0603
14100     0.7684      0.7911     0.8084     79.3049
14200     0.6551      0.7743     0.8084     76.5856
14300     0.6945      0.7890     0.8084     77.9133
14400     0.6491      0.8059     0.8084     78.1774
14500     0.7341      0.7637     0.8084     77.1299
14600     0.8000      0.7595     0.8084     78.4268
14700     0.7195      0.7890     0.8084     77.0921
14800     0.6974      0.7700     0.8084     80.2461
14900     0.7007      0.7932     0.8084     76.6722
15000     0.7113      0.7954     0.8084     78.9706
15100     0.7625      0.7806     0.8084     76.9051
15200     0.6943      0.7954     0.8084     80.4469
15300     0.7004      0.7764     0.8084     77.6686
15400     0.8251      0.7384     0.8084     77.3134
15500     0.7108      0.7848     0.8084     78.0191
15600     0.6959      0.7975     0.8084     79.4655
15700     0.7654      0.7806     0.8109     77.8026
15800     0.6885      0.8059     0.8109     78.5245
15900     0.7682      0.7890     0.8109     77.3834
16000     0.7230      0.7785     0.8109     77.3718
16100     0.7403      0.7890     0.8109     77.6258
16200     0.7288      0.7785     0.8109     77.5633
16300     0.7343      0.7722     0.8109     77.7956
16400     0.6996      0.8038     0.8109     77.4492
16500     0.7140      0.7743     0.8109     77.1704
16600     0.6943      0.7954     0.8109     78.2032
16700     0.6507      0.8165     0.8109     77.7827
16800     0.7270      0.7722     0.8109     79.4934
16900     0.7261      0.7827     0.8109     76.0144
17000     0.7259      0.7890     0.8109     78.1462
17100     0.7682      0.7679     0.8109     78.4651
17200     0.7204      0.7890     0.8109     77.1191
17300     0.7401      0.7806     0.8109     79.0342
17400     0.7904      0.7743     0.8109     78.9428
17500     0.6864      0.7827     0.8112     78.0490
17600     0.7729      0.7869     0.8112     79.1963
17700     0.7077      0.7890     0.8112     77.4626
17800     0.6725      0.7932     0.8112     77.4060
17900     0.8104      0.7321     0.8112     79.7197
18000     0.7124      0.7911     0.8112     78.6303
18100     0.6897      0.7806     0.8112     78.0447
18200     0.7953      0.7511     0.8126     78.8959
18300     0.7557      0.7700     0.8126     78.0611
18400     0.6507      0.7954     0.8126     78.7518
18500     0.8746      0.7363     0.8126     77.4842
18600     0.7539      0.7658     0.8126     78.6748
18700     0.7158      0.7827     0.8126     77.2846
18800     0.6964      0.7890     0.8126     76.9334
18900     0.8169      0.7553     0.8126     76.8058
19000     0.7189      0.7764     0.8126     77.1136
19100     0.7600      0.7764     0.8126     77.5549
19200     0.7898      0.7616     0.8126     78.7939
19300     0.7545      0.7764     0.8126     78.3642
19400     0.7575      0.7722     0.8126     77.9512
19500     0.7620      0.7785     0.8138     77.3210
19600     0.7970      0.7658     0.8138     78.6200
19700     0.7448      0.7679     0.8138     77.4505
19800     0.7563      0.7637     0.8138     78.5253
19900     0.7613      0.7806     0.8138     78.8725
20000     0.7224      0.7806     0.8156     78.4833
20100     0.8005      0.7468     0.8156     77.7574
20199     0.7378      0.7890     0.8156     77.1483
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.5646      0.8270     0.8064     12.3150
00100     0.6096      0.8249     0.8158     76.4698
00200     0.6644      0.7848     0.8176     78.5425
00300     0.5777      0.8228     0.8194     77.7515
00400     0.6730      0.8059     0.8194     77.5458
00500     0.6522      0.7932     0.8194     77.8081
00600     0.6670      0.7890     0.8194     78.7101
00700     0.7173      0.7806     0.8194     79.5100
00800     0.6171      0.8186     0.8194     78.5618
00900     0.7113      0.8059     0.8194     77.4644
01000     0.6721      0.7890     0.8194     77.7028
01100     0.6047      0.8101     0.8194     78.9209
01200     0.6637      0.7911     0.8194     77.2191
01300     0.7220      0.7764     0.8198     77.3094
01400     0.6643      0.8059     0.8206     79.4074
01500     0.6405      0.8059     0.8206     77.8375
01600     0.6929      0.7827     0.8206     78.7386
01700     0.6105      0.8143     0.8206     76.1759
01800     0.5948      0.8312     0.8206     78.0670
01900     0.6513      0.7975     0.8206     79.1237
02000     0.6161      0.8122     0.8206     79.5139
02100     0.6345      0.8038     0.8206     78.0649
02200     0.6686      0.7975     0.8206     79.0814
02300     0.6567      0.8165     0.8206     75.8369
02400     0.6008      0.8228     0.8206     78.9572
02500     0.6067      0.8059     0.8206     77.7766
02600     0.6622      0.8143     0.8206     77.6797
02700     0.6371      0.8186     0.8206     77.6311
02800     0.6198      0.8143     0.8206     76.6854
02900     0.6927      0.7869     0.8206     78.3362
03000     0.6457      0.8186     0.8206     77.5208
03100     0.6617      0.7911     0.8206     76.7753
03200     0.6878      0.7890     0.8206     77.4611
03300     0.6620      0.8080     0.8206     77.5943
03400     0.6667      0.7911     0.8206     79.6887
03500     0.5926      0.8270     0.8206     78.8834
03600     0.6095      0.8101     0.8206     77.1614
03700     0.6123      0.7975     0.8206     76.7194
03800     0.6237      0.8207     0.8206     80.3998
03900     0.6359      0.8165     0.8206     80.0730
04000     0.6268      0.8101     0.8206     77.9908
04100     0.5449      0.8376     0.8206     78.8023
04200     0.6610      0.8186     0.8206     78.5263
04300     0.7349      0.7848     0.8206     79.6156
04400     0.6517      0.7954     0.8206     77.7248
04500     0.6280      0.8122     0.8206     78.2257
04600     0.6769      0.7785     0.8206     78.2911
04700     0.6492      0.8122     0.8206     77.7183
04800     0.6373      0.7954     0.8206     78.1736
04900     0.6492      0.8249     0.8206     77.7896
05000     0.7574      0.7827     0.8206     75.6302
05100     0.6727      0.8059     0.8206     75.6209
05200     0.6324      0.8143     0.8206     74.7904
05300     0.6519      0.7911     0.8206     75.9212
05400     0.6927      0.8080     0.8206     77.1131
05500     0.7030      0.7827     0.8206     77.2463
05600     0.6742      0.7975     0.8206     78.6775
05700     0.6550      0.8207     0.8206     76.7608
05800     0.6493      0.7890     0.8206     77.6152
05900     0.6007      0.8376     0.8206     78.1903
06000     0.6683      0.7975     0.8206     76.6027
06100     0.6577      0.8249     0.8206     79.3619
06200     0.6388      0.8101     0.8206     78.1065
06300     0.5628      0.8376     0.8206     79.3632
06400     0.7098      0.7890     0.8206     77.8581
06500     0.6690      0.8017     0.8206     79.5762
06600     0.6773      0.7785     0.8206     79.6379
06700     0.6419      0.8165     0.8206     78.4279
06800     0.6209      0.7996     0.8206     80.7861
06900     0.6582      0.7954     0.8206     78.7040
07000     0.5976      0.8439     0.8206     77.3651
07100     0.6400      0.8101     0.8206     79.4665
07200     0.7197      0.7700     0.8206     78.6718
07300     0.6560      0.8038     0.8206     79.0711
07400     0.6169      0.8165     0.8206     78.7277
07500     0.6780      0.8038     0.8206     77.5841
07600     0.7162      0.7511     0.8206     77.2783
07700     0.6925      0.7848     0.8206     77.6897
07800     0.6641      0.7932     0.8206     77.5393
07900     0.6145      0.8207     0.8206     76.2723
08000     0.6404      0.8017     0.8206     78.6241
08100     0.5936      0.8312     0.8206     78.0030
08200     0.6340      0.8165     0.8206     79.1168
08300     0.7118      0.7954     0.8206     80.5667
08400     0.6222      0.8017     0.8206     77.9377
08500     0.6819      0.7954     0.8206     79.8531
08600     0.7709      0.7700     0.8206     80.2667
08700     0.5809      0.8228     0.8206     78.8904
08800     0.6876      0.8059     0.8206     77.7470
08900     0.6666      0.8059     0.8206     78.1146
09000     0.7235      0.7932     0.8206     78.0305
09100     0.7014      0.8080     0.8206     77.8784
09200     0.7071      0.7975     0.8206     78.1996
09300     0.6080      0.8291     0.8206     78.1185
09400     0.6766      0.8080     0.8206     78.5408
09500     0.6137      0.8376     0.8206     77.0366
09600     0.5829      0.8207     0.8206     78.8746
09700     0.6878      0.8038     0.8206     77.3129
09800     0.6920      0.8080     0.8206     78.0361
09900     0.5617      0.8418     0.8206     77.2134
Start testing:
Test Accuracy: 0.7987
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=6, quant_actNM=6, quant_inp=6, quant_w=6, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
ae4052b5-86c0-4c76-a357-54e5efceba86
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8566      0.0949     0.0767     10.5069
00100     2.2189      0.2764     0.3367     72.4559
00200     1.8437      0.3924     0.4188     71.2292
00300     1.6528      0.4684     0.5208     71.2228
00400     1.4597      0.5316     0.5432     70.5704
00500     1.3729      0.5696     0.5772     71.4753
00600     1.2695      0.5949     0.6300     70.6288
00700     1.2796      0.5949     0.6399     71.2325
00800     1.1906      0.6118     0.6463     71.6913
00900     1.1066      0.6519     0.6798     71.9288
01000     1.1684      0.6203     0.6891     71.0230
01100     1.1068      0.6624     0.7067     72.4406
01200     1.0841      0.6540     0.7083     72.3609
01300     1.1157      0.6646     0.7125     74.6513
01400     0.9623      0.6983     0.7269     73.5148
01500     0.9015      0.7405     0.7276     72.3891
01600     0.9749      0.6730     0.7287     71.1275
01700     0.9818      0.6878     0.7396     73.0920
01800     0.9071      0.7131     0.7396     72.2433
01900     0.8843      0.7278     0.7449     72.3933
02000     0.9474      0.7300     0.7523     73.9904
02100     0.9689      0.6857     0.7523     73.1125
02200     0.9419      0.7025     0.7544     71.3678
02300     0.8316      0.7700     0.7559     72.8085
02400     0.9555      0.7384     0.7674     73.7698
02500     0.9416      0.7152     0.7674     73.7129
02600     0.9143      0.7236     0.7674     73.1467
02700     0.8461      0.7215     0.7674     72.4321
02800     0.8240      0.7574     0.7686     71.7410
02900     0.8995      0.7236     0.7686     70.8655
03000     0.8741      0.7257     0.7744     71.0362
03100     0.9334      0.7405     0.7744     74.5318
03200     0.8799      0.7300     0.7802     72.4460
03300     0.8612      0.7363     0.7808     75.5909
03400     0.9053      0.7257     0.7814     74.0439
03500     1.0249      0.7046     0.7814     73.2826
03600     0.8498      0.7426     0.7814     72.5430
03700     0.8321      0.7511     0.7814     73.1998
03800     0.7391      0.7743     0.7814     72.3431
03900     0.8678      0.7342     0.7814     73.6194
04000     0.7588      0.8017     0.7814     73.2311
04100     0.8080      0.7911     0.7814     70.6037
04200     0.8532      0.7278     0.7814     69.0002
04300     0.7963      0.7468     0.7814     71.3498
04400     0.8728      0.7616     0.7814     72.8268
04500     0.8922      0.7363     0.7814     72.7380
04600     0.9064      0.7300     0.7814     73.0708
04700     0.7860      0.7511     0.7829     73.7668
04800     0.7936      0.7658     0.7829     72.3339
04900     0.8692      0.7489     0.7848     74.5779
05000     0.8590      0.7342     0.7848     74.4335
05100     0.8041      0.7637     0.7848     73.0655
05200     0.8734      0.7405     0.7848     72.6968
05300     0.7274      0.7806     0.7848     73.3396
05400     0.7960      0.7574     0.7848     71.4157
05500     0.8455      0.7342     0.7848     74.6651
05600     0.7807      0.7574     0.7848     72.5115
05700     0.8069      0.7574     0.7848     73.2358
05800     0.8723      0.7574     0.7942     73.1604
05900     0.7648      0.7827     0.7942     73.3263
06000     0.8021      0.7764     0.7942     72.6098
06100     0.6783      0.7996     0.7942     72.1291
06200     0.7471      0.7764     0.7961     74.6419
06300     0.7795      0.7679     0.7961     72.8662
06400     0.9201      0.7194     0.7961     73.3607
06500     0.7805      0.7616     0.7961     71.5856
06600     0.8357      0.7321     0.7961     71.8225
06700     0.8859      0.7194     0.7961     73.3837
06800     0.8029      0.7321     0.7961     71.6293
06900     0.7188      0.7848     0.7961     72.0436
07000     0.7468      0.7785     0.7961     74.1078
07100     0.7531      0.7848     0.7965     72.7464
07200     0.8665      0.7342     0.7965     74.6209
07300     0.7766      0.7574     0.7965     71.5441
07400     0.8215      0.7637     0.7965     71.8672
07500     0.7435      0.7679     0.7978     73.8579
07600     0.8089      0.7679     0.7989     72.7905
07700     0.8463      0.7743     0.7989     74.0785
07800     0.8511      0.7785     0.7989     72.4101
07900     0.7217      0.7890     0.7989     71.8165
08000     0.6774      0.7806     0.7989     72.1195
08100     0.7902      0.7489     0.7989     73.5908
08200     0.7483      0.7595     0.7989     73.7249
08300     0.7776      0.7658     0.8031     74.6219
08400     0.7945      0.7700     0.8031     72.8294
08500     0.7251      0.7848     0.8031     74.9491
08600     0.7724      0.7785     0.8031     73.8381
08700     0.7748      0.7679     0.8031     72.4415
08800     0.7538      0.7827     0.8031     72.6915
08900     0.7537      0.7679     0.8031     71.6821
09000     0.7954      0.7278     0.8031     72.4985
09100     0.7525      0.7911     0.8031     74.4992
09200     0.7891      0.7679     0.8031     72.7146
09300     0.8017      0.7679     0.8031     71.8607
09400     0.8157      0.7511     0.8031     72.4385
09500     0.8473      0.7426     0.8031     73.0480
09600     0.7712      0.7574     0.8031     73.1795
09700     0.8312      0.7595     0.8031     74.3327
09800     0.7110      0.7975     0.8031     74.2730
09900     0.7854      0.7806     0.8031     72.8070
10000     0.8288      0.7384     0.8031     72.4060
10100     0.7135      0.7932     0.8031     72.4501
10200     0.7311      0.8017     0.8031     74.2988
10300     0.7229      0.8017     0.8031     72.8880
10400     0.7774      0.7869     0.8065     73.9528
10500     0.8300      0.7722     0.8065     71.7738
10600     0.7526      0.7848     0.8065     74.1106
10700     0.7316      0.7954     0.8065     74.4562
10800     0.8296      0.7553     0.8065     73.7137
10900     0.6960      0.7890     0.8065     73.1438
11000     0.7080      0.8017     0.8065     72.8020
11100     0.6509      0.8249     0.8065     72.5837
11200     0.7392      0.7722     0.8065     74.8067
11300     0.6814      0.7996     0.8065     71.6410
11400     0.7412      0.7848     0.8065     73.2049
11500     0.7997      0.7848     0.8065     72.2612
11600     0.8774      0.7236     0.8065     70.8068
11700     0.8367      0.7532     0.8065     72.0734
11800     0.7380      0.7743     0.8065     71.7625
11900     0.7730      0.7511     0.8065     73.8197
12000     0.7679      0.7890     0.8065     74.1232
12100     0.8418      0.7574     0.8065     74.9602
12200     0.7857      0.7743     0.8065     71.9661
12300     0.7245      0.7932     0.8065     71.9284
12400     0.7516      0.7848     0.8065     72.4896
12500     0.8408      0.7468     0.8065     72.0418
12600     0.8093      0.7574     0.8065     71.8994
12700     0.7817      0.7722     0.8065     72.3589
12800     0.7508      0.7848     0.8065     72.6504
12900     0.7326      0.7890     0.8065     71.7436
13000     0.7551      0.7890     0.8065     72.2973
13100     0.7298      0.7806     0.8065     74.2087
13200     0.7837      0.7637     0.8065     72.0432
13300     0.6583      0.7848     0.8065     73.2401
13400     0.7948      0.7426     0.8072     73.6194
13500     0.7852      0.7658     0.8072     71.5979
