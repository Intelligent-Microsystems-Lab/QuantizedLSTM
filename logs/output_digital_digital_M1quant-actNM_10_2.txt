Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
f94d2fc7-416c-4f66-825b-b565c3a35573
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
50786e91-3f34-4783-a9cc-3ce64c9c7099
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=10, quant_actNM=10, quant_inp=10, quant_w=10, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
a7be2d51-040e-4a28-9e6d-81d8d4d5eb87
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.5814      0.0654     0.0663     10.3020
00100     2.0662      0.3122     0.3374     55.6733
00200     1.5885      0.4810     0.5094     55.1698
00300     1.2988      0.5844     0.5870     56.0089
00400     1.2015      0.6308     0.6451     55.1916
00500     1.1241      0.6392     0.6808     54.6921
00600     0.9322      0.7131     0.6991     55.0837
00700     0.9854      0.6920     0.7212     55.0500
00800     0.9192      0.6983     0.7316     55.4021
00900     0.8967      0.7131     0.7370     54.8180
01000     0.7866      0.7637     0.7507     54.4338
01100     0.9118      0.7089     0.7562     55.2812
01200     0.8779      0.7236     0.7646     55.0385
01300     0.8000      0.7468     0.7805     55.1372
01400     0.8295      0.7468     0.7805     55.0946
01500     0.8047      0.7489     0.7805     55.0648
01600     0.7893      0.7532     0.7805     55.1838
01700     0.7103      0.7722     0.7860     55.4694
01800     0.6395      0.7911     0.7860     55.1693
01900     0.7088      0.7700     0.7860     55.1141
02000     0.7505      0.7637     0.7874     54.8284
02100     0.6660      0.7911     0.7966     55.1347
02200     0.7980      0.7257     0.8001     56.1112
02300     0.6193      0.7996     0.8033     55.0953
02400     0.6427      0.7975     0.8033     55.3550
02500     0.7149      0.7722     0.8070     56.3025
02600     0.6488      0.7975     0.8070     56.6484
02700     0.6591      0.8059     0.8070     55.7220
02800     0.6057      0.7954     0.8122     55.6974
02900     0.6457      0.7975     0.8122     55.2704
03000     0.6551      0.7975     0.8138     56.4256
03100     0.6483      0.7806     0.8138     55.1296
03200     0.6338      0.7954     0.8138     54.9795
03300     0.7642      0.7553     0.8138     55.4672
03400     0.5953      0.8122     0.8138     55.0835
03500     0.7271      0.7806     0.8138     55.4402
03600     0.6243      0.8122     0.8193     55.1797
03700     0.5983      0.8059     0.8193     54.6770
03800     0.6231      0.8038     0.8193     55.0842
03900     0.5301      0.8333     0.8193     54.5663
04000     0.6084      0.8101     0.8193     55.8284
04100     0.6574      0.7848     0.8209     55.4783
04200     0.6560      0.7911     0.8237     55.4076
04300     0.5699      0.8186     0.8237     56.0161
04400     0.6250      0.7932     0.8291     55.8267
04500     0.6507      0.7911     0.8291     55.4150
04600     0.5672      0.7975     0.8291     56.1605
04700     0.5590      0.8101     0.8291     54.6498
04800     0.5878      0.8143     0.8291     55.6936
04900     0.6126      0.8270     0.8291     55.3057
05000     0.5973      0.8165     0.8291     55.5634
05100     0.5547      0.8186     0.8291     55.3767
05200     0.5990      0.8207     0.8354     55.7323
05300     0.5759      0.8228     0.8354     54.8216
05400     0.5589      0.8291     0.8361     55.3614
05500     0.6117      0.8080     0.8362     55.2736
05600     0.6602      0.7722     0.8362     56.2791
05700     0.5589      0.8101     0.8362     55.3787
05800     0.5349      0.8502     0.8362     54.7658
05900     0.5745      0.8101     0.8362     55.5743
06000     0.5740      0.8291     0.8362     54.7311
06100     0.5941      0.8122     0.8362     55.0327
06200     0.5481      0.8291     0.8362     55.4426
06300     0.5814      0.8354     0.8375     54.9075
06400     0.5910      0.7975     0.8412     55.1980
06500     0.5615      0.8376     0.8412     53.9783
06600     0.5781      0.8376     0.8412     54.9181
06700     0.5716      0.8017     0.8412     55.1030
06800     0.6177      0.8080     0.8412     55.3429
06900     0.5433      0.8397     0.8412     54.3046
07000     0.5797      0.8270     0.8412     55.0534
07100     0.6197      0.8059     0.8412     54.7539
07200     0.5779      0.8017     0.8412     55.2289
07300     0.6132      0.8143     0.8412     54.8665
07400     0.5101      0.8333     0.8412     54.9929
07500     0.4821      0.8502     0.8412     55.3261
07600     0.5467      0.8186     0.8412     54.4135
07700     0.5160      0.8354     0.8412     55.2797
07800     0.5207      0.8312     0.8412     54.5919
07900     0.5127      0.8291     0.8412     54.4594
08000     0.5993      0.8207     0.8412     54.5418
08100     0.4593      0.8586     0.8412     54.7268
08200     0.5402      0.8122     0.8412     54.2690
08300     0.5179      0.8418     0.8412     54.7275
08400     0.5819      0.8228     0.8412     55.0686
08500     0.5383      0.8186     0.8412     55.2477
08600     0.5682      0.8059     0.8412     56.4707
08700     0.5015      0.8270     0.8412     55.3144
08800     0.5732      0.8017     0.8420     55.6194
08900     0.4834      0.8481     0.8420     54.5398
09000     0.4937      0.8502     0.8420     54.5729
09100     0.4931      0.8481     0.8425     55.4876
09200     0.5639      0.8165     0.8425     55.0086
09300     0.5180      0.8165     0.8425     54.8522
09400     0.5910      0.8207     0.8435     55.7096
09500     0.4863      0.8354     0.8435     56.3416
09600     0.4891      0.8608     0.8511     56.0030
09700     0.5263      0.8376     0.8511     56.2192
09800     0.5791      0.8038     0.8511     55.0994
09900     0.4947      0.8333     0.8511     55.7227
10000     0.5077      0.8270     0.8511     56.1218
10100     0.5414      0.8312     0.8511     55.4969
10200     0.4541      0.8523     0.8511     55.0506
10300     0.5233      0.8354     0.8511     54.6467
10400     0.4817      0.8502     0.8511     54.9752
10500     0.5064      0.8291     0.8511     54.6163
10600     0.4981      0.8460     0.8511     54.8379
10700     0.4505      0.8776     0.8511     54.8001
10800     0.5340      0.8207     0.8511     54.8735
10900     0.6077      0.8038     0.8511     54.6926
11000     0.5439      0.8291     0.8511     55.4688
11100     0.5343      0.8059     0.8511     54.8622
11200     0.4389      0.8565     0.8511     55.4469
11300     0.4352      0.8544     0.8511     55.4464
11400     0.4601      0.8565     0.8511     54.9497
11500     0.4467      0.8544     0.8511     56.9493
11600     0.4955      0.8354     0.8511     56.2750
11700     0.4715      0.8608     0.8511     55.3449
11800     0.5788      0.8207     0.8511     55.0061
11900     0.5325      0.8376     0.8511     55.0985
12000     0.5071      0.8270     0.8511     55.1642
12100     0.4665      0.8629     0.8511     55.2226
12200     0.4652      0.8713     0.8511     55.7922
12300     0.4525      0.8776     0.8511     55.9865
12400     0.5072      0.8333     0.8511     54.4978
12500     0.4661      0.8502     0.8511     55.2206
12600     0.4780      0.8565     0.8511     55.3664
12700     0.4480      0.8713     0.8511     54.9997
12800     0.4539      0.8523     0.8511     55.5318
12900     0.4714      0.8481     0.8511     54.2331
13000     0.4512      0.8460     0.8511     54.4911
13100     0.5380      0.8249     0.8511     55.5934
13200     0.4375      0.8586     0.8511     54.7028
13300     0.4729      0.8481     0.8511     54.7417
13400     0.5161      0.8397     0.8511     55.4472
13500     0.5382      0.8291     0.8511     54.4752
13600     0.5544      0.8249     0.8511     56.3135
13700     0.5619      0.8312     0.8511     55.1802
13800     0.5283      0.8291     0.8511     54.9507
13900     0.3662      0.8882     0.8511     55.0850
14000     0.4258      0.8608     0.8511     54.6269
14100     0.4297      0.8840     0.8518     55.0351
14200     0.5369      0.8249     0.8518     56.0589
14300     0.3952      0.8650     0.8518     54.7561
14400     0.4584      0.8629     0.8518     55.0241
14500     0.4689      0.8460     0.8518     54.4104
14600     0.5015      0.8397     0.8518     54.9008
14700     0.4846      0.8523     0.8518     55.3015
14800     0.4714      0.8523     0.8530     54.8711
14900     0.4733      0.8502     0.8530     54.8589
15000     0.5210      0.8270     0.8530     55.5735
15100     0.4593      0.8776     0.8530     55.0143
15200     0.5505      0.8165     0.8530     55.2414
15300     0.5292      0.8376     0.8530     54.5936
15400     0.5080      0.8333     0.8530     55.0563
15500     0.4564      0.8650     0.8530     55.8357
15600     0.4678      0.8586     0.8530     54.8536
15700     0.4945      0.8671     0.8530     55.4434
15800     0.4036      0.8840     0.8530     55.6040
15900     0.4537      0.8565     0.8530     55.1475
16000     0.5002      0.8312     0.8530     56.0506
16100     0.4403      0.8544     0.8530     55.8740
16200     0.5117      0.8354     0.8530     56.0496
16300     0.5163      0.8354     0.8530     56.3471
16400     0.6018      0.8186     0.8530     56.8021
16500     0.3347      0.8734     0.8530     54.6633
16600     0.4333      0.8481     0.8530     55.1163
16700     0.4257      0.8544     0.8530     55.2772
16800     0.4705      0.8544     0.8530     55.3964
16900     0.5476      0.8354     0.8530     54.5147
17000     0.4744      0.8502     0.8530     55.3152
17100     0.5107      0.8460     0.8530     55.7927
17200     0.5181      0.8354     0.8530     55.0252
17300     0.5068      0.8291     0.8530     54.7389
17400     0.5269      0.8460     0.8547     55.2449
17500     0.4964      0.8312     0.8547     54.6059
17600     0.5325      0.8312     0.8547     55.6729
17700     0.4577      0.8650     0.8547     55.4907
17800     0.5358      0.8165     0.8547     54.4169
17900     0.4764      0.8671     0.8547     55.5624
18000     0.4247      0.8734     0.8547     54.6616
18100     0.4606      0.8502     0.8547     55.1686
18200     0.4002      0.8608     0.8547     55.0932
18300     0.4776      0.8439     0.8547     55.2659
18400     0.4414      0.8439     0.8547     55.6923
18500     0.4636      0.8586     0.8547     55.6137
18600     0.4922      0.8354     0.8547     55.3444
18700     0.4805      0.8523     0.8547     55.2190
18800     0.4654      0.8629     0.8547     54.4539
18900     0.4585      0.8650     0.8547     55.0311
19000     0.4956      0.8481     0.8547     55.3511
19100     0.4340      0.8755     0.8547     55.6605
19200     0.5257      0.8291     0.8547     55.5930
19300     0.4883      0.8312     0.8547     55.0647
19400     0.4862      0.8186     0.8547     55.0339
19500     0.4700      0.8460     0.8547     55.4133
19600     0.5044      0.8312     0.8547     55.1491
19700     0.5371      0.8270     0.8547     55.1630
19800     0.5842      0.8143     0.8547     55.4982
19900     0.4501      0.8523     0.8547     55.2445
20000     0.5221      0.8270     0.8569     55.7317
20100     0.4757      0.8586     0.8569     54.8695
20199     0.5321      0.8186     0.8569     54.7795
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.3935      0.8650     0.8550     9.2744
00100     0.3775      0.8945     0.8550     55.4162
00200     0.4299      0.8502     0.8550     55.2612
00300     0.4236      0.8565     0.8550     55.5853
00400     0.4227      0.8608     0.8550     54.8209
00500     0.4103      0.8586     0.8550     55.5215
00600     0.3900      0.8692     0.8550     56.2497
00700     0.3780      0.8713     0.8564     55.3721
00800     0.4556      0.8439     0.8564     55.6848
00900     0.4039      0.8713     0.8564     55.5123
01000     0.3867      0.8692     0.8564     54.6885
01100     0.3778      0.8755     0.8564     55.3950
01200     0.3837      0.8713     0.8564     55.2229
01300     0.3927      0.8650     0.8564     54.9267
01400     0.4056      0.8776     0.8564     54.5752
01500     0.3979      0.8840     0.8564     55.1612
01600     0.4247      0.8629     0.8566     55.7466
01700     0.4058      0.8734     0.8566     55.8601
01800     0.3950      0.8861     0.8566     54.6283
01900     0.3190      0.9051     0.8566     56.0928
02000     0.4221      0.8692     0.8566     54.6333
02100     0.3987      0.8692     0.8566     54.8671
02200     0.3279      0.9114     0.8566     55.6486
02300     0.4210      0.8586     0.8566     55.8159
02400     0.3819      0.8755     0.8566     54.6491
02500     0.3718      0.8840     0.8566     55.4574
02600     0.3880      0.8650     0.8571     55.2865
02700     0.3838      0.8734     0.8571     55.7569
02800     0.4338      0.8523     0.8571     55.1602
02900     0.3865      0.8755     0.8571     54.6082
03000     0.4172      0.8671     0.8571     55.5172
03100     0.3937      0.8819     0.8571     55.2636
03200     0.4271      0.8671     0.8571     55.1628
03300     0.3766      0.9030     0.8571     55.1550
03400     0.4011      0.8755     0.8571     55.3022
03500     0.4738      0.8586     0.8574     55.4729
03600     0.3996      0.8608     0.8574     54.9435
03700     0.4132      0.8671     0.8574     56.8345
03800     0.4500      0.8397     0.8574     55.3323
03900     0.3607      0.8776     0.8574     55.5551
04000     0.3493      0.8924     0.8574     55.3909
04100     0.3810      0.8692     0.8574     55.6214
04200     0.3579      0.9030     0.8588     54.8905
04300     0.3501      0.9114     0.8588     55.9638
04400     0.3712      0.8945     0.8613     55.2853
04500     0.4263      0.8565     0.8613     55.3407
04600     0.4210      0.8713     0.8613     55.1719
04700     0.3424      0.9030     0.8613     55.2532
04800     0.4628      0.8418     0.8613     54.5868
04900     0.4376      0.8544     0.8613     55.1672
05000     0.3758      0.8945     0.8613     55.2456
05100     0.4058      0.8671     0.8613     55.8597
05200     0.3919      0.8734     0.8613     55.1529
05300     0.3844      0.8903     0.8613     55.3193
05400     0.4172      0.8671     0.8613     56.4156
05500     0.4560      0.8523     0.8613     55.5716
05600     0.4536      0.8502     0.8613     55.2427
05700     0.3904      0.8861     0.8613     55.8632
05800     0.4607      0.8502     0.8613     55.8570
05900     0.3595      0.8713     0.8613     55.5444
06000     0.2831      0.9093     0.8613     55.2414
06100     0.3449      0.8840     0.8613     55.0561
06200     0.3899      0.8755     0.8613     55.4741
06300     0.4285      0.8692     0.8613     55.1372
06400     0.3692      0.8882     0.8613     55.2944
06500     0.3645      0.8840     0.8613     55.6752
06600     0.4470      0.8734     0.8613     55.0258
06700     0.5251      0.8270     0.8613     55.5866
06800     0.3771      0.8692     0.8613     54.8139
06900     0.3997      0.8840     0.8613     55.1541
07000     0.4140      0.8523     0.8613     56.0464
07100     0.3875      0.8987     0.8613     55.2248
07200     0.4271      0.8608     0.8613     55.2539
07300     0.3603      0.8903     0.8613     56.1050
07400     0.3867      0.8671     0.8613     55.2953
07500     0.4137      0.8692     0.8613     56.0598
07600     0.4098      0.8713     0.8613     55.6088
07700     0.3626      0.8966     0.8613     55.9231
07800     0.4272      0.8692     0.8613     56.1631
07900     0.4070      0.8861     0.8613     55.1166
08000     0.3534      0.9030     0.8613     54.9375
08100     0.3130      0.9135     0.8613     55.8401
08200     0.3608      0.8819     0.8613     55.5470
08300     0.3933      0.8734     0.8613     55.6781
08400     0.4443      0.8586     0.8613     55.4468
08500     0.4011      0.8840     0.8613     55.8639
08600     0.3166      0.9008     0.8613     55.1739
08700     0.3898      0.8565     0.8613     55.1732
08800     0.3448      0.8882     0.8613     55.0266
08900     0.3617      0.8755     0.8613     55.2534
09000     0.4099      0.8692     0.8613     54.9749
09100     0.3462      0.8987     0.8613     56.7122
09200     0.3562      0.8861     0.8613     56.6208
09300     0.4050      0.8586     0.8613     55.0602
09400     0.3707      0.8776     0.8613     55.8687
09500     0.3979      0.8755     0.8613     55.1998
09600     0.4045      0.8776     0.8613     56.0384
09700     0.4235      0.8713     0.8613     55.8929
09800     0.4690      0.8523     0.8613     56.0155
09900     0.3342      0.8945     0.8613     56.3529
Start testing:
Test Accuracy: 0.8392
