Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
d11c9d6f-b44a-4099-9695-463a785df97a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
aeceed23-32b8-42b6-a7eb-8f1ed100e5a4
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
bb1384d2-4cda-455f-8bca-f84c57f1278b
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.5014      0.0844     0.0891     10.9240
00100     2.2772      0.2110     0.2345     76.6728
00200     1.8702      0.3650     0.3874     74.5105
00300     1.6092      0.4557     0.5005     76.1922
00400     1.3769      0.5633     0.5640     75.4998
00500     1.2821      0.5802     0.6144     75.1880
00600     1.0644      0.6540     0.6496     75.3525
00700     1.2359      0.6076     0.6758     74.5607
00800     1.1121      0.6730     0.6911     75.2874
00900     1.0740      0.6603     0.6983     74.2229
01000     1.0794      0.6540     0.7101     74.7102
01100     0.9287      0.6857     0.7186     75.0945
01200     0.9697      0.6920     0.7296     76.3462
01300     1.0089      0.6561     0.7324     75.6561
01400     0.8627      0.7236     0.7451     74.9461
01500     0.9587      0.6688     0.7554     73.6384
01600     0.9324      0.6835     0.7590     74.7562
01700     0.8582      0.7300     0.7620     75.0864
01800     0.8800      0.7215     0.7620     75.2409
01900     0.9083      0.6941     0.7620     76.7846
02000     0.8607      0.7405     0.7736     77.9226
02100     0.8416      0.7152     0.7820     74.6832
02200     0.8084      0.7110     0.7820     75.8270
02300     0.8050      0.7278     0.7820     74.9406
02400     0.8184      0.7342     0.7848     76.1100
02500     0.7415      0.7489     0.7848     74.6193
02600     0.7943      0.7468     0.7848     75.5698
02700     0.7471      0.7679     0.7848     74.8937
02800     0.7278      0.7827     0.7901     76.0951
02900     0.7867      0.7511     0.7901     76.4481
03000     0.7616      0.7532     0.7901     75.4073
03100     0.7316      0.7532     0.7927     76.6434
03200     0.7943      0.7511     0.7945     76.1114
03300     0.7215      0.7658     0.7977     75.5389
03400     0.8087      0.7511     0.7977     75.6271
03500     0.7009      0.7890     0.7977     76.3371
03600     0.6487      0.8186     0.7977     76.6024
03700     0.7476      0.7616     0.7977     74.7428
03800     0.8181      0.7173     0.7977     76.9118
03900     0.6615      0.7911     0.7977     73.8058
04000     0.6855      0.7785     0.7977     75.1421
04100     0.6337      0.7806     0.8014     75.1728
04200     0.7477      0.7722     0.8014     74.7079
04300     0.7522      0.7489     0.8014     75.5872
04400     0.6625      0.8017     0.8014     74.0668
04500     0.6887      0.7785     0.8014     76.3382
04600     0.6762      0.7785     0.8014     77.0691
04700     0.6406      0.7954     0.8014     74.7781
04800     0.6564      0.7679     0.8034     75.3476
04900     0.7280      0.7932     0.8039     76.2359
05000     0.7361      0.7743     0.8044     76.0792
05100     0.7080      0.7743     0.8048     73.9285
05200     0.5713      0.8249     0.8048     76.9369
05300     0.6748      0.7911     0.8132     74.6147
05400     0.6523      0.7996     0.8132     76.1116
05500     0.6883      0.7743     0.8132     76.3219
05600     0.6187      0.8143     0.8132     77.0008
05700     0.7607      0.7405     0.8132     75.3197
05800     0.7568      0.7321     0.8132     76.8119
05900     0.5935      0.8249     0.8132     75.5689
06000     0.6643      0.7996     0.8132     75.5534
06100     0.6524      0.7869     0.8132     76.8633
06200     0.6311      0.7848     0.8132     74.9133
06300     0.5712      0.8101     0.8132     77.4745
06400     0.5856      0.8122     0.8139     77.7071
06500     0.6335      0.8059     0.8139     75.5298
06600     0.6500      0.7911     0.8139     75.8157
06700     0.6281      0.7848     0.8139     76.6482
06800     0.5661      0.8207     0.8223     75.2896
06900     0.5540      0.8122     0.8223     74.9501
07000     0.6311      0.7932     0.8223     75.7597
07100     0.5414      0.8312     0.8223     74.9607
07200     0.6942      0.8017     0.8223     74.4122
07300     0.6991      0.7806     0.8223     74.7956
07400     0.6377      0.8165     0.8223     76.3283
07500     0.7145      0.7785     0.8223     76.4872
07600     0.5908      0.8143     0.8223     73.7083
07700     0.6185      0.8080     0.8223     75.6380
07800     0.6412      0.7785     0.8223     77.5954
07900     0.6469      0.7785     0.8223     77.3943
08000     0.6986      0.7785     0.8239     76.5597
08100     0.6509      0.7869     0.8239     74.1945
08200     0.6742      0.7890     0.8239     75.6686
08300     0.6354      0.7996     0.8239     75.4533
08400     0.5716      0.8186     0.8239     74.7047
08500     0.6015      0.8101     0.8281     75.0383
08600     0.5852      0.8038     0.8281     74.4171
08700     0.5406      0.8418     0.8281     76.4627
08800     0.6380      0.7700     0.8281     77.5804
08900     0.5250      0.8333     0.8281     76.4928
09000     0.6983      0.7785     0.8284     74.8808
09100     0.5817      0.8101     0.8284     75.1927
09200     0.6689      0.7764     0.8286     76.2199
09300     0.5814      0.8080     0.8286     74.9462
09400     0.5855      0.8017     0.8286     75.6556
09500     0.6365      0.7869     0.8286     76.4749
09600     0.5419      0.8333     0.8286     77.3777
09700     0.6114      0.7869     0.8286     74.9343
09800     0.4723      0.8354     0.8286     76.6268
09900     0.6527      0.7869     0.8292     76.2570
10000     0.5802      0.8207     0.8292     75.1732
10100     0.6296      0.8038     0.8292     75.4938
10200     0.6253      0.7911     0.8292     77.2757
10300     0.5434      0.8249     0.8292     77.4177
10400     0.5622      0.7954     0.8297     74.7667
10500     0.5916      0.8228     0.8297     74.6285
10600     0.6427      0.7954     0.8297     75.0094
10700     0.5620      0.8122     0.8297     76.2075
10800     0.5633      0.8397     0.8297     74.9937
10900     0.6474      0.7954     0.8297     75.2503
11000     0.6110      0.7954     0.8297     75.2586
11100     0.5591      0.8228     0.8297     76.3814
11200     0.5409      0.8165     0.8297     74.8337
11300     0.5251      0.8312     0.8297     75.4358
11400     0.5540      0.8228     0.8297     74.4844
11500     0.4879      0.8481     0.8297     76.9104
11600     0.6162      0.7869     0.8297     76.0270
11700     0.5884      0.8080     0.8297     76.6439
11800     0.5533      0.8207     0.8297     74.3414
11900     0.6195      0.7996     0.8297     74.2725
12000     0.5248      0.8481     0.8381     76.6170
12100     0.5685      0.8165     0.8381     74.5474
12200     0.5459      0.8228     0.8381     75.0304
12300     0.5966      0.8207     0.8381     73.6765
12400     0.5647      0.8017     0.8381     76.5019
12500     0.5697      0.8059     0.8381     74.9575
12600     0.5284      0.8122     0.8381     75.9618
12700     0.5925      0.8080     0.8381     75.3291
12800     0.5513      0.8270     0.8381     74.8425
12900     0.5388      0.8270     0.8381     73.9266
13000     0.6258      0.7869     0.8381     75.4549
13100     0.4992      0.8608     0.8386     73.6272
13200     0.5435      0.8270     0.8386     75.6719
13300     0.5160      0.8354     0.8386     76.7198
13400     0.5501      0.8143     0.8386     76.2200
13500     0.5371      0.8291     0.8386     74.8215
13600     0.4888      0.8354     0.8386     76.3189
13700     0.5254      0.8143     0.8386     73.8068
13800     0.5405      0.8165     0.8386     74.2873
13900     0.5428      0.8270     0.8386     75.7922
14000     0.4993      0.8523     0.8386     73.6760
14100     0.4917      0.8544     0.8386     76.3588
14200     0.5771      0.8080     0.8386     76.1616
14300     0.5251      0.8376     0.8386     74.6605
14400     0.5564      0.8270     0.8386     75.9569
14500     0.5451      0.8249     0.8386     75.1241
14600     0.4418      0.8755     0.8386     76.6215
14700     0.5292      0.8439     0.8386     75.7401
14800     0.5347      0.8502     0.8386     75.0778
14900     0.5929      0.8165     0.8386     75.9429
15000     0.6595      0.8017     0.8386     74.3985
15100     0.5591      0.8122     0.8386     74.6587
15200     0.5569      0.8312     0.8386     74.6443
15300     0.5948      0.8228     0.8386     76.0900
15400     0.5295      0.8333     0.8386     75.6823
15500     0.6001      0.8122     0.8386     76.6382
15600     0.5412      0.8228     0.8386     75.2318
15700     0.5996      0.8017     0.8386     75.5692
15800     0.5409      0.8312     0.8386     75.6667
15900     0.5482      0.8333     0.8386     75.8491
16000     0.5624      0.8165     0.8386     74.5911
16100     0.5706      0.8228     0.8386     75.4506
16200     0.5602      0.8249     0.8386     75.2230
16300     0.6090      0.8143     0.8386     74.6961
16400     0.5949      0.8059     0.8386     76.5319
16500     0.6611      0.8017     0.8386     75.2921
16600     0.6010      0.8038     0.8386     75.1095
16700     0.5352      0.8418     0.8386     74.9515
16800     0.5384      0.8397     0.8386     75.3798
16900     0.5393      0.8397     0.8386     75.5301
17000     0.5542      0.8122     0.8386     75.3972
17100     0.5250      0.8397     0.8386     76.0940
17200     0.5837      0.8165     0.8386     76.3858
17300     0.6157      0.7890     0.8386     76.1458
17400     0.5013      0.8439     0.8386     76.1960
17500     0.6751      0.8122     0.8386     77.2200
17600     0.5237      0.8376     0.8386     75.6240
17700     0.4949      0.8502     0.8386     75.5644
17800     0.5612      0.8186     0.8386     77.9249
17900     0.5647      0.8143     0.8388     75.2982
18000     0.5106      0.8439     0.8388     74.2420
18100     0.6341      0.7911     0.8388     75.8704
18200     0.5840      0.8017     0.8405     74.7328
18300     0.5251      0.8291     0.8405     75.4511
18400     0.5745      0.8101     0.8405     75.5303
18500     0.5445      0.8333     0.8405     75.8811
18600     0.5224      0.8312     0.8405     77.3228
18700     0.5650      0.8038     0.8405     74.0859
18800     0.5292      0.8270     0.8405     76.3444
18900     0.5251      0.8397     0.8405     77.4421
19000     0.5600      0.8249     0.8405     75.8405
19100     0.5946      0.8017     0.8405     76.3468
19200     0.5164      0.8376     0.8405     75.9609
19300     0.5659      0.8186     0.8405     74.3623
19400     0.5431      0.8165     0.8405     74.1838
19500     0.5760      0.8122     0.8405     76.4931
19600     0.5285      0.8460     0.8405     74.2821
19700     0.5098      0.8397     0.8405     75.8448
19800     0.5347      0.8228     0.8405     76.5785
19900     0.6019      0.7996     0.8405     75.0244
20000     0.5625      0.8228     0.8405     75.0879
20100     0.5025      0.8354     0.8405     75.2038
20199     0.5037      0.8376     0.8405     74.8248
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4643      0.8586     0.8337     9.8470
00100     0.4639      0.8502     0.8420     74.3287
00200     0.4963      0.8418     0.8420     74.2414
00300     0.4924      0.8481     0.8448     75.8864
00400     0.4565      0.8565     0.8448     74.9685
00500     0.4496      0.8481     0.8448     75.4464
00600     0.4263      0.8565     0.8448     74.4125
00700     0.4551      0.8650     0.8448     74.4136
00800     0.4560      0.8650     0.8448     75.6607
00900     0.5375      0.8143     0.8448     76.7891
01000     0.4506      0.8565     0.8448     74.8790
01100     0.3955      0.8882     0.8448     74.3397
01200     0.4641      0.8502     0.8461     74.8331
01300     0.5137      0.8312     0.8461     74.0824
01400     0.5169      0.8165     0.8461     76.7541
01500     0.4960      0.8291     0.8461     74.9130
01600     0.4604      0.8629     0.8461     76.4706
01700     0.3951      0.8755     0.8474     74.2000
01800     0.4945      0.8460     0.8474     72.2337
01900     0.4989      0.8354     0.8474     71.6152
02000     0.4412      0.8650     0.8474     72.5169
02100     0.4781      0.8460     0.8474     75.1571
02200     0.4458      0.8629     0.8474     74.1469
02300     0.4094      0.8692     0.8474     75.4224
02400     0.4834      0.8439     0.8474     76.1610
02500     0.4135      0.8671     0.8474     75.7572
02600     0.4458      0.8544     0.8474     74.7555
02700     0.4569      0.8481     0.8474     74.8493
02800     0.5437      0.8291     0.8474     77.6434
02900     0.5454      0.8333     0.8474     76.1646
03000     0.4894      0.8481     0.8474     75.2678
03100     0.4655      0.8481     0.8474     76.4206
03200     0.4830      0.8460     0.8474     76.1833
03300     0.4726      0.8713     0.8474     74.9553
03400     0.4907      0.8249     0.8474     74.7932
03500     0.4392      0.8460     0.8474     75.9946
03600     0.4306      0.8544     0.8474     75.2735
03700     0.5008      0.8523     0.8474     77.1891
03800     0.4117      0.8713     0.8474     76.6371
03900     0.5209      0.8397     0.8474     75.7049
04000     0.4712      0.8565     0.8474     76.5629
04100     0.4241      0.8713     0.8474     75.2212
04200     0.4536      0.8523     0.8474     76.3984
04300     0.4377      0.8586     0.8474     74.7156
04400     0.4663      0.8755     0.8474     78.0720
04500     0.4373      0.8418     0.8474     75.7298
04600     0.5227      0.8270     0.8474     74.4866
04700     0.5039      0.8418     0.8474     77.1771
04800     0.4830      0.8544     0.8474     76.6350
04900     0.5056      0.8376     0.8474     74.8831
05000     0.4456      0.8650     0.8474     76.3323
05100     0.4555      0.8650     0.8474     74.3227
05200     0.4698      0.8565     0.8515     77.1745
05300     0.4695      0.8671     0.8515     75.2827
05400     0.4471      0.8418     0.8515     74.5153
05500     0.5175      0.8080     0.8515     74.2684
05600     0.5005      0.8270     0.8515     76.6420
05700     0.4241      0.8734     0.8515     74.3582
05800     0.4202      0.8882     0.8515     76.2809
05900     0.4506      0.8629     0.8515     76.0714
06000     0.4020      0.8776     0.8515     75.1888
06100     0.4429      0.8692     0.8515     76.5901
06200     0.5377      0.8354     0.8515     77.1656
06300     0.4610      0.8397     0.8515     74.7303
06400     0.4970      0.8439     0.8515     76.2438
06500     0.5390      0.8270     0.8515     76.0900
06600     0.4570      0.8523     0.8515     76.1759
06700     0.4916      0.8523     0.8515     75.1345
06800     0.4381      0.8629     0.8515     74.2968
06900     0.4107      0.8692     0.8515     74.9174
07000     0.4322      0.8608     0.8515     74.4572
07100     0.4303      0.8713     0.8515     73.9202
07200     0.4359      0.8354     0.8515     75.0880
07300     0.4572      0.8418     0.8515     76.3555
07400     0.4675      0.8565     0.8515     75.8413
07500     0.5078      0.8270     0.8515     77.1179
07600     0.4401      0.8502     0.8515     76.5005
07700     0.4327      0.8565     0.8515     76.5170
07800     0.3976      0.8819     0.8515     75.6891
07900     0.4048      0.8692     0.8515     76.6967
08000     0.4714      0.8565     0.8515     77.6220
08100     0.4920      0.8481     0.8515     75.7512
08200     0.4788      0.8608     0.8515     75.6390
08300     0.4307      0.8840     0.8515     75.3235
08400     0.4760      0.8481     0.8515     75.8105
08500     0.4353      0.8502     0.8515     76.7740
08600     0.4766      0.8397     0.8515     76.4875
08700     0.5078      0.8523     0.8515     75.8386
08800     0.4888      0.8460     0.8515     75.7966
08900     0.4638      0.8586     0.8515     76.9425
09000     0.4260      0.8650     0.8515     77.3100
09100     0.4034      0.8776     0.8515     76.6105
09200     0.4974      0.8608     0.8515     74.3300
09300     0.4887      0.8481     0.8515     78.6179
09400     0.4933      0.8333     0.8515     76.5364
09500     0.4150      0.8692     0.8515     74.9195
09600     0.4270      0.8692     0.8515     77.5247
09700     0.4537      0.8439     0.8515     75.9292
09800     0.4858      0.8481     0.8515     75.3348
09900     0.5121      0.8376     0.8515     74.7518
Start testing:
Test Accuracy: 0.8407
