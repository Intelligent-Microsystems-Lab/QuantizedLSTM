Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(batch_size=256, cy_div=2, cy_scale=2, dataloader_num_workers=4, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', epochs=50000, global_beta=1.5, hidden=256, hop_length=320, hp_bw=False, init_factor=2, learning_rate=0.0005, lr_divide=15000, n_mfcc=40, noise_injection=0.1, quant_actMVM=6, quant_actNM=8, quant_inp=4, quant_w=None, sample_rate=16000, std_scale=1, testing_percentage=10, validation_percentage=10, validation_size=10000, win_length=400, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
4dc44c82-7039-44fc-9de0-4d17888ef01a
Start Training:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 405, in <module>
    output = model(x_data, train = False)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "KWS_LSTM.py", line 314, in forward
    lstm_out, self.hidden_state = self.lstmL(inputs, self.hidden_state, train)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "KWS_LSTM.py", line 257, in forward
    out, state = self.cell(inputs[i], state, train)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "KWS_LSTM.py", line 228, in forward
    cy = quant_pass( (quant_pass(forgetgate * cx, self.abNM, True, train) + quant_pass(ingate * cellgate, self.abNM, True, train)) * 1/args.cy_div, self.abNM, True, train)
  File "KWS_LSTM.py", line 131, in forward
    return quant(x, wb, sign)
  File "KWS_LSTM.py", line 95, in quant
    return torch.round(x * scale ) / scale
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 9.88 GiB already allocated; 11.12 MiB free; 9.89 GiB reserved in total by PyTorch)
