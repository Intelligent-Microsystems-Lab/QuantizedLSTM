Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
8c0b3b3d-4658-43bc-843f-0256e16229f0
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
3355b943-6622-47e4-b6ce-67b679010ffa
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=8, quant_actNM=8, quant_inp=8, quant_w=8, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
021fee94-0278-48ad-aa77-4f8861e382d9
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.9727      0.0886     0.0757     10.1015
00100     2.0912      0.3397     0.3531     53.9563
00200     1.7122      0.4473     0.4805     53.8293
00300     1.4351      0.5485     0.5642     54.4358
00400     1.2486      0.5992     0.6173     54.7235
00500     1.1787      0.6371     0.6381     54.2220
00600     1.0963      0.6540     0.6833     54.4173
00700     1.0235      0.6772     0.6951     54.8792
00800     1.0273      0.6667     0.7105     54.8190
00900     0.9096      0.7152     0.7386     53.9037
01000     0.9427      0.7110     0.7417     54.4230
01100     0.8185      0.7489     0.7571     55.2001
01200     0.7923      0.7574     0.7602     54.2584
01300     0.9040      0.7131     0.7687     55.1465
01400     0.7557      0.7637     0.7687     54.6112
01500     0.7847      0.7743     0.7708     55.6168
01600     0.7689      0.7658     0.7717     54.7052
01700     0.8111      0.7384     0.7831     54.4810
01800     0.8455      0.7384     0.7831     56.1128
01900     0.6992      0.7827     0.7831     54.5725
02000     0.7049      0.7827     0.7930     53.3784
02100     0.7689      0.7616     0.7930     55.7889
02200     0.7815      0.7574     0.7930     54.3523
02300     0.5957      0.8439     0.7930     55.1317
02400     0.7077      0.7869     0.7930     55.7746
02500     0.7117      0.7996     0.7930     54.2558
02600     0.6802      0.7806     0.7958     54.1454
02700     0.5826      0.8186     0.7958     54.6772
02800     0.6703      0.7954     0.7958     53.5179
02900     0.7645      0.7764     0.7958     54.5077
03000     0.6297      0.7932     0.7981     54.0781
03100     0.7303      0.7764     0.8005     53.5568
03200     0.7277      0.7785     0.8005     54.5429
03300     0.7171      0.7743     0.8005     55.7633
03400     0.7341      0.7848     0.8005     54.8222
03500     0.7950      0.7447     0.8005     55.6226
03600     0.6220      0.8165     0.8044     53.5605
03700     0.6882      0.7975     0.8069     55.0809
03800     0.6173      0.8101     0.8069     55.3962
03900     0.7183      0.8017     0.8069     53.5763
04000     0.6762      0.8143     0.8069     54.7222
04100     0.6389      0.8101     0.8069     53.5716
04200     0.6982      0.7827     0.8069     54.0776
04300     0.6844      0.8101     0.8069     55.2942
04400     0.7270      0.7848     0.8069     55.1141
04500     0.6752      0.7954     0.8069     53.9510
04600     0.7081      0.7658     0.8094     54.9590
04700     0.6581      0.7764     0.8094     53.9252
04800     0.7025      0.8038     0.8094     54.8852
04900     0.6789      0.7869     0.8094     53.7917
05000     0.6956      0.7975     0.8094     55.8044
05100     0.6117      0.8101     0.8103     55.4425
05200     0.7169      0.7743     0.8103     53.4146
05300     0.5724      0.8270     0.8103     55.3486
05400     0.6428      0.7975     0.8103     54.3734
05500     0.6037      0.8101     0.8209     55.0272
05600     0.6665      0.8059     0.8209     54.1415
05700     0.6506      0.7890     0.8209     53.2537
05800     0.7013      0.7848     0.8209     54.4825
05900     0.5578      0.8333     0.8209     54.6876
06000     0.6603      0.8017     0.8209     55.2840
06100     0.5720      0.8312     0.8209     54.2268
06200     0.5773      0.8186     0.8209     54.3438
06300     0.6433      0.7954     0.8209     53.4270
06400     0.6967      0.7869     0.8209     54.6531
06500     0.6602      0.8080     0.8209     53.9497
06600     0.7085      0.7890     0.8209     56.5779
06700     0.7178      0.7954     0.8209     55.9736
06800     0.6905      0.7827     0.8212     53.7596
06900     0.6122      0.8228     0.8212     54.5339
07000     0.5779      0.8460     0.8212     54.0388
07100     0.6128      0.7975     0.8212     54.3356
07200     0.6560      0.8017     0.8212     53.9304
07300     0.6303      0.8038     0.8212     53.6937
07400     0.5947      0.8143     0.8220     53.2356
07500     0.6165      0.8143     0.8220     53.6188
07600     0.6121      0.8249     0.8220     54.4924
07700     0.5998      0.8270     0.8220     53.7683
07800     0.5900      0.8249     0.8220     55.2638
07900     0.6261      0.8038     0.8220     54.7626
08000     0.5520      0.8186     0.8220     54.6410
08100     0.6085      0.8101     0.8220     53.5846
08200     0.5666      0.8291     0.8220     53.7547
08300     0.6359      0.7996     0.8220     54.3880
08400     0.6085      0.8165     0.8220     54.9839
08500     0.5946      0.8038     0.8220     53.8184
08600     0.6235      0.8165     0.8220     54.4845
08700     0.6158      0.8059     0.8220     54.0224
08800     0.5979      0.8228     0.8220     54.4134
08900     0.6017      0.8101     0.8227     54.8510
09000     0.6042      0.8165     0.8227     54.5066
09100     0.6542      0.7975     0.8227     54.3245
09200     0.6911      0.7806     0.8227     54.7542
09300     0.6528      0.8038     0.8227     54.1232
09400     0.5876      0.8207     0.8227     54.5760
09500     0.6064      0.8228     0.8227     54.4020
09600     0.6419      0.8017     0.8227     54.6961
09700     0.6227      0.8143     0.8227     53.9461
09800     0.5912      0.8249     0.8227     54.8971
09900     0.6403      0.8017     0.8227     54.3851
10000     0.6150      0.7911     0.8227     53.7243
10100     0.5523      0.8291     0.8227     54.7987
10200     0.5771      0.8101     0.8227     53.7567
10300     0.5710      0.8397     0.8247     53.9802
10400     0.5873      0.8249     0.8251     55.1293
10500     0.5604      0.8291     0.8260     53.7500
10600     0.5323      0.8354     0.8260     54.1491
10700     0.6023      0.8143     0.8260     54.6457
10800     0.5987      0.8186     0.8260     53.2500
10900     0.5613      0.8291     0.8260     54.2890
11000     0.5573      0.8439     0.8260     55.1105
11100     0.5028      0.8439     0.8260     53.1825
11200     0.5192      0.8418     0.8261     54.9332
11300     0.5401      0.8544     0.8261     54.6592
11400     0.5549      0.8418     0.8261     53.6267
11500     0.6478      0.7975     0.8262     54.9878
11600     0.6625      0.7911     0.8262     54.0216
11700     0.6566      0.7996     0.8262     53.9414
11800     0.6032      0.8207     0.8262     54.2472
11900     0.6205      0.8122     0.8262     54.1282
12000     0.6055      0.8165     0.8262     54.1255
12100     0.5891      0.8312     0.8272     54.3856
12200     0.5954      0.7996     0.8272     54.0526
12300     0.6006      0.8059     0.8272     54.7613
12400     0.5427      0.8333     0.8297     54.0254
12500     0.5808      0.8228     0.8297     54.8973
12600     0.6155      0.8165     0.8297     54.8393
12700     0.5885      0.8291     0.8297     54.7195
12800     0.5724      0.8228     0.8297     55.6850
12900     0.4983      0.8354     0.8297     54.6184
13000     0.5609      0.8291     0.8297     53.8623
13100     0.5282      0.8523     0.8297     53.8913
13200     0.5906      0.8270     0.8297     53.3208
13300     0.4964      0.8418     0.8297     55.5751
13400     0.5407      0.8481     0.8297     54.5433
13500     0.5811      0.8418     0.8297     56.4881
13600     0.5318      0.8586     0.8297     56.9166
13700     0.6366      0.7975     0.8297     54.3274
13800     0.6102      0.8122     0.8297     53.5754
13900     0.5885      0.8312     0.8297     53.3599
14000     0.5337      0.8439     0.8297     52.7203
14100     0.6106      0.8122     0.8297     54.1712
14200     0.5378      0.8228     0.8297     55.1123
14300     0.5358      0.8460     0.8297     53.8416
14400     0.5754      0.8207     0.8297     54.5503
14500     0.5660      0.8291     0.8297     53.5726
14600     0.5996      0.8207     0.8297     54.1817
14700     0.5618      0.8291     0.8297     54.9032
14800     0.5353      0.8418     0.8297     54.2474
14900     0.5315      0.8481     0.8297     55.2635
15000     0.5489      0.8376     0.8297     56.2036
15100     0.5320      0.8460     0.8302     54.5974
15200     0.5601      0.8270     0.8302     55.0030
15300     0.5418      0.8165     0.8302     54.6054
15400     0.5766      0.8291     0.8302     54.9818
15500     0.5496      0.8439     0.8302     55.0260
15600     0.5378      0.8460     0.8302     55.0007
15700     0.6524      0.7996     0.8302     56.0238
15800     0.5503      0.8312     0.8302     54.9601
15900     0.5989      0.8207     0.8302     55.2120
16000     0.5590      0.8397     0.8302     56.0538
16100     0.5912      0.8312     0.8302     55.6452
16200     0.5982      0.8312     0.8302     54.3899
16300     0.5930      0.8038     0.8302     54.9327
16400     0.5698      0.8439     0.8302     54.7914
16500     0.5180      0.8439     0.8302     54.0139
16600     0.4729      0.8650     0.8302     54.2374
16700     0.4773      0.8608     0.8302     55.1923
16800     0.5594      0.8354     0.8302     56.3081
16900     0.6165      0.8080     0.8302     54.1781
17000     0.5251      0.8460     0.8302     54.4065
17100     0.6126      0.8122     0.8302     54.7338
17200     0.5934      0.8207     0.8302     53.7882
17300     0.5411      0.8228     0.8302     54.7558
17400     0.5800      0.8143     0.8302     55.3986
17500     0.5389      0.8481     0.8302     54.5149
17600     0.5530      0.8376     0.8302     54.7078
17700     0.5557      0.8312     0.8302     54.0851
17800     0.5152      0.8376     0.8302     54.1870
17900     0.5625      0.8186     0.8302     55.1273
18000     0.4781      0.8650     0.8302     53.8899
18100     0.5760      0.8354     0.8302     54.0156
18200     0.6669      0.7890     0.8302     55.4650
18300     0.5882      0.8333     0.8302     56.1225
18400     0.5196      0.8481     0.8302     56.6575
18500     0.5772      0.8143     0.8302     54.6340
18600     0.5818      0.8228     0.8302     54.7380
18700     0.5727      0.8165     0.8302     56.5496
18800     0.5014      0.8650     0.8302     54.7865
18900     0.5962      0.8059     0.8302     54.8980
19000     0.5666      0.8439     0.8302     56.1322
19100     0.5530      0.8207     0.8340     55.4707
19200     0.5473      0.8397     0.8340     54.8739
19300     0.5797      0.8186     0.8340     54.5317
19400     0.6211      0.8080     0.8340     54.3984
19500     0.5350      0.8692     0.8340     54.2832
19600     0.5302      0.8565     0.8340     54.9312
19700     0.5166      0.8481     0.8340     54.2293
19800     0.5690      0.8165     0.8340     55.6363
19900     0.5427      0.8418     0.8340     54.4940
20000     0.5157      0.8481     0.8340     54.7096
20100     0.6374      0.8080     0.8340     56.1267
20199     0.5632      0.8270     0.8340     54.0877
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4379      0.8734     0.8233     8.6548
00100     0.4809      0.8629     0.8265     54.3189
00200     0.4838      0.8544     0.8267     54.2042
00300     0.4565      0.8671     0.8317     54.5724
00400     0.4865      0.8565     0.8317     54.8736
00500     0.5102      0.8502     0.8334     54.4928
00600     0.5240      0.8565     0.8334     55.7843
00700     0.5077      0.8523     0.8334     53.9338
00800     0.4742      0.8439     0.8334     53.9412
00900     0.5935      0.8186     0.8334     54.3907
01000     0.4964      0.8376     0.8334     54.1419
01100     0.4606      0.8544     0.8334     54.7986
01200     0.5254      0.8418     0.8334     54.3732
01300     0.5539      0.8439     0.8334     54.0194
01400     0.4968      0.8544     0.8334     55.4965
01500     0.4092      0.8840     0.8334     53.9604
01600     0.4994      0.8312     0.8334     54.1260
01700     0.4854      0.8608     0.8334     56.4090
01800     0.4036      0.8882     0.8334     54.8082
01900     0.4425      0.8629     0.8334     55.3646
02000     0.4520      0.8755     0.8339     55.5200
02100     0.4837      0.8586     0.8339     56.1338
02200     0.4726      0.8755     0.8339     55.1500
02300     0.4702      0.8650     0.8339     54.3755
02400     0.4084      0.8734     0.8339     54.2396
02500     0.4492      0.8671     0.8339     54.6998
02600     0.4796      0.8544     0.8339     54.4528
02700     0.4813      0.8565     0.8339     54.5266
02800     0.4849      0.8586     0.8344     55.7590
02900     0.4289      0.8840     0.8344     55.6648
03000     0.5111      0.8502     0.8344     55.1622
03100     0.5214      0.8502     0.8344     54.6084
03200     0.4525      0.8608     0.8344     54.4096
03300     0.4997      0.8650     0.8344     55.6552
03400     0.4923      0.8502     0.8344     54.9050
03500     0.4913      0.8544     0.8344     54.8508
03600     0.4176      0.8903     0.8344     54.3514
03700     0.5116      0.8397     0.8344     55.1939
03800     0.4993      0.8502     0.8344     54.9259
03900     0.5263      0.8397     0.8344     54.6636
04000     0.4905      0.8460     0.8344     54.3574
04100     0.4532      0.8544     0.8344     55.0936
04200     0.4962      0.8481     0.8344     53.9608
04300     0.5026      0.8565     0.8344     55.5831
04400     0.4892      0.8523     0.8344     53.8937
04500     0.4899      0.8439     0.8344     56.3242
04600     0.4678      0.8481     0.8344     54.5133
04700     0.4938      0.8523     0.8361     53.4558
04800     0.4754      0.8565     0.8361     54.9692
04900     0.4524      0.8755     0.8361     54.1241
05000     0.5548      0.8270     0.8361     54.8070
05100     0.4922      0.8481     0.8370     55.1429
05200     0.4144      0.8819     0.8370     55.6910
05300     0.4567      0.8565     0.8370     54.6505
05400     0.5582      0.8418     0.8370     54.4714
05500     0.5647      0.8333     0.8370     55.9179
05600     0.5333      0.8586     0.8370     54.7863
05700     0.4069      0.8650     0.8370     55.1775
05800     0.5057      0.8460     0.8370     55.4734
05900     0.4707      0.8460     0.8370     55.5284
06000     0.5377      0.8333     0.8370     55.0653
06100     0.5070      0.8608     0.8370     55.4998
06200     0.4234      0.8819     0.8370     54.8749
06300     0.4490      0.8608     0.8370     54.9114
06400     0.4690      0.8544     0.8370     56.7577
06500     0.4486      0.8713     0.8370     56.2621
06600     0.5357      0.8418     0.8370     54.4971
06700     0.4591      0.8776     0.8370     54.2617
06800     0.4622      0.8692     0.8370     55.4028
06900     0.4908      0.8586     0.8370     57.0537
07000     0.4043      0.8903     0.8370     54.8300
07100     0.5310      0.8291     0.8370     53.5830
07200     0.4753      0.8671     0.8370     54.8659
07300     0.4718      0.8755     0.8370     54.6524
07400     0.4552      0.8523     0.8379     54.8253
07500     0.5976      0.8291     0.8379     57.6859
07600     0.4541      0.8629     0.8379     54.2314
07700     0.4503      0.8776     0.8379     55.1082
07800     0.4355      0.8734     0.8379     54.7515
07900     0.4179      0.8755     0.8379     54.4449
08000     0.4622      0.8692     0.8379     56.3856
08100     0.3860      0.8966     0.8379     55.6131
08200     0.4792      0.8671     0.8379     56.1507
08300     0.4557      0.8776     0.8390     54.8693
08400     0.4478      0.8650     0.8390     55.6868
08500     0.5232      0.8376     0.8390     54.7323
08600     0.5684      0.8312     0.8393     54.8600
08700     0.4701      0.8671     0.8393     53.6850
08800     0.4514      0.8713     0.8393     54.6368
08900     0.5457      0.8312     0.8393     55.0800
09000     0.4999      0.8523     0.8393     55.5775
09100     0.5225      0.8481     0.8393     55.3342
09200     0.4802      0.8544     0.8393     54.6641
09300     0.3983      0.8966     0.8393     54.2231
09400     0.5195      0.8333     0.8393     54.4044
09500     0.4584      0.8755     0.8393     54.4098
09600     0.4027      0.8966     0.8393     55.0393
09700     0.4763      0.8586     0.8393     55.6314
09800     0.5572      0.8333     0.8393     54.6093
09900     0.4303      0.8629     0.8393     55.0207
Start testing:
Test Accuracy: 0.8301
