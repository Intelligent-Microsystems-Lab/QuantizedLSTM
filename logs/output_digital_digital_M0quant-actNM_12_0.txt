Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
c9851e63-1505-4db9-b903-d5fa15e4e42a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
34ea36fa-b559-40be-b90b-52d76bbf5df8
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
63e8edd6-bb91-4ba5-b94b-8246c5a3a61b
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).to(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
18f5b5db-5de5-4f17-8b1c-2912df1ae8c1
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8263      0.0696     0.0883     10.3848
00100     2.3663      0.2321     0.2612     55.3232
00200     1.8075      0.4135     0.4404     54.8278
00300     1.4537      0.5401     0.5414     55.1809
00400     1.3073      0.6224     0.6081     54.5878
00500     1.1768      0.6329     0.6612     54.2830
00600     1.0621      0.6730     0.6959     55.8607
00700     0.9453      0.7215     0.7175     54.5730
00800     0.9187      0.7300     0.7315     55.1341
00900     0.9785      0.6920     0.7454     54.8826
01000     0.8918      0.7426     0.7551     54.6990
01100     0.9195      0.7194     0.7559     55.5387
01200     0.8923      0.7532     0.7669     54.7281
01300     0.8005      0.7553     0.7676     55.2074
01400     0.8997      0.7300     0.7742     54.7867
01500     0.7676      0.7743     0.7742     54.8395
01600     0.8170      0.7489     0.7745     55.3766
01700     0.7546      0.7785     0.7764     55.3268
01800     0.7640      0.7700     0.7829     55.4658
01900     0.7582      0.7806     0.7853     55.7386
02000     0.7968      0.7700     0.7853     54.6619
02100     0.7445      0.7764     0.7853     55.0815
02200     0.6941      0.7869     0.7853     55.2128
02300     0.7003      0.7932     0.7936     55.7485
02400     0.6682      0.8038     0.7936     55.9590
02500     0.7514      0.7764     0.8007     55.1822
02600     0.7375      0.7911     0.8007     54.9631
02700     0.7175      0.7932     0.8007     55.6867
02800     0.7324      0.7700     0.8046     54.6896
02900     0.7453      0.7848     0.8100     55.3738
03000     0.7205      0.7954     0.8100     55.4899
03100     0.7104      0.7996     0.8100     54.7527
03200     0.7190      0.7848     0.8100     55.2024
03300     0.6051      0.8101     0.8116     54.5355
03400     0.7353      0.7869     0.8116     54.6460
03500     0.6869      0.7806     0.8116     55.9991
03600     0.7365      0.7722     0.8116     55.9725
03700     0.7153      0.7932     0.8121     54.6619
03800     0.6500      0.8038     0.8121     55.4757
03900     0.7563      0.7827     0.8121     54.9516
04000     0.6603      0.7975     0.8121     55.2033
04100     0.6388      0.8059     0.8121     54.4548
04200     0.6047      0.8270     0.8141     54.6622
04300     0.6469      0.8143     0.8141     55.1716
04400     0.6790      0.7996     0.8141     54.8724
04500     0.5910      0.8228     0.8141     54.6416
04600     0.6612      0.8207     0.8141     55.3998
04700     0.5735      0.8291     0.8141     54.4673
04800     0.6100      0.8207     0.8141     54.9545
04900     0.6073      0.8165     0.8141     54.6282
05000     0.6462      0.8038     0.8141     54.5370
05100     0.6581      0.8207     0.8152     56.4727
05200     0.6229      0.8122     0.8152     57.0118
05300     0.7045      0.8080     0.8152     55.2269
05400     0.6536      0.7996     0.8152     54.9434
05500     0.6393      0.8080     0.8172     54.0624
05600     0.6111      0.8143     0.8189     54.9292
05700     0.6015      0.8207     0.8189     55.3020
05800     0.6797      0.7996     0.8189     54.6859
05900     0.5762      0.8291     0.8306     55.2616
06000     0.7361      0.7679     0.8306     54.5404
06100     0.6234      0.8186     0.8306     54.7243
06200     0.6344      0.8101     0.8306     55.9746
06300     0.5294      0.8481     0.8306     54.5354
06400     0.6766      0.8059     0.8306     54.9920
06500     0.6514      0.7996     0.8306     54.8723
06600     0.6712      0.7869     0.8306     55.3993
06700     0.6546      0.8143     0.8306     55.3267
06800     0.6370      0.7954     0.8306     54.8355
06900     0.6258      0.8143     0.8306     54.3662
07000     0.6660      0.8143     0.8306     54.6922
07100     0.6030      0.8186     0.8306     55.3935
07200     0.5861      0.8376     0.8306     56.2926
07300     0.7169      0.7806     0.8306     54.7557
07400     0.6074      0.8270     0.8306     54.3724
07500     0.5469      0.8376     0.8306     55.3012
07600     0.6823      0.8059     0.8306     54.7584
07700     0.5164      0.8523     0.8306     54.7923
07800     0.5962      0.8207     0.8306     55.3035
07900     0.6778      0.7911     0.8306     54.6179
08000     0.6003      0.8439     0.8306     55.8298
08100     0.6567      0.8101     0.8321     56.4524
08200     0.5528      0.8354     0.8321     55.5626
08300     0.5434      0.8397     0.8321     55.3296
08400     0.6272      0.8122     0.8321     55.0410
08500     0.6130      0.8165     0.8321     55.4414
08600     0.5441      0.8418     0.8321     55.0636
08700     0.6114      0.8165     0.8321     54.6335
08800     0.6062      0.8080     0.8321     55.0660
08900     0.6443      0.8080     0.8321     54.9718
09000     0.5603      0.8376     0.8321     54.7817
09100     0.5587      0.8291     0.8321     54.7728
09200     0.6365      0.8143     0.8321     54.8431
09300     0.5835      0.8418     0.8321     54.4857
09400     0.5623      0.8354     0.8321     54.8281
09500     0.6221      0.8080     0.8321     54.2180
09600     0.5307      0.8333     0.8321     54.9251
09700     0.5832      0.8165     0.8321     54.4305
09800     0.5909      0.8333     0.8321     54.5301
09900     0.5613      0.8270     0.8321     55.0031
10000     0.5222      0.8460     0.8321     55.9813
10100     0.6467      0.7890     0.8321     54.7563
10200     0.5984      0.8270     0.8321     54.6146
10300     0.5551      0.8481     0.8321     55.5017
10400     0.5570      0.8397     0.8321     55.4537
10500     0.5177      0.8565     0.8321     55.1237
10600     0.5562      0.8418     0.8321     55.0514
10700     0.6037      0.8270     0.8321     55.6408
10800     0.5887      0.8333     0.8321     54.9672
10900     0.5773      0.8270     0.8321     55.0850
11000     0.4715      0.8439     0.8321     54.7908
11100     0.5150      0.8397     0.8321     54.6309
11200     0.4608      0.8565     0.8321     55.2359
11300     0.5928      0.8080     0.8321     54.3360
11400     0.5384      0.8439     0.8321     54.4461
11500     0.5324      0.8439     0.8321     56.2645
11600     0.6378      0.8228     0.8321     58.5000
11700     0.6118      0.7996     0.8321     57.4681
11800     0.6146      0.8080     0.8321     56.9536
11900     0.5870      0.8186     0.8321     55.8374
12000     0.4672      0.8629     0.8321     56.8141
12100     0.5539      0.8312     0.8321     57.2963
12200     0.5128      0.8333     0.8321     59.4597
12300     0.5730      0.8376     0.8321     58.0125
12400     0.5791      0.8080     0.8321     57.8785
12500     0.5805      0.8333     0.8321     56.4385
12600     0.5386      0.8502     0.8321     57.3161
12700     0.5780      0.8354     0.8321     56.5922
12800     0.5110      0.8460     0.8321     59.8073
12900     0.5393      0.8291     0.8321     57.1861
13000     0.5504      0.8354     0.8321     57.0441
13100     0.5390      0.8397     0.8321     57.0364
13200     0.5174      0.8397     0.8336     56.7495
13300     0.5773      0.8312     0.8336     56.6983
13400     0.5641      0.8354     0.8336     56.0821
13500     0.5520      0.8418     0.8357     55.7074
13600     0.5983      0.8038     0.8357     57.3872
13700     0.5180      0.8439     0.8357     55.1348
13800     0.5274      0.8354     0.8357     54.3856
13900     0.5383      0.8291     0.8357     55.1490
14000     0.5163      0.8629     0.8357     54.8551
14100     0.5465      0.8397     0.8357     54.6324
14200     0.5192      0.8481     0.8357     54.8089
14300     0.5260      0.8481     0.8357     55.3126
14400     0.5296      0.8439     0.8357     55.2064
14500     0.6028      0.8312     0.8357     54.4667
14600     0.5269      0.8565     0.8357     54.8542
14700     0.5488      0.8439     0.8357     55.3001
14800     0.6068      0.8312     0.8360     54.7538
14900     0.5012      0.8565     0.8360     54.5557
15000     0.4929      0.8629     0.8360     55.1193
15100     0.5766      0.8354     0.8360     55.0909
15200     0.5645      0.8354     0.8360     55.0749
15300     0.5501      0.8291     0.8360     54.3222
15400     0.5477      0.8249     0.8374     54.9230
15500     0.6182      0.8207     0.8374     56.5063
15600     0.5921      0.8354     0.8374     54.7223
15700     0.5364      0.8586     0.8374     54.2958
15800     0.6519      0.7848     0.8374     55.1820
15900     0.5313      0.8565     0.8385     54.6650
16000     0.5243      0.8523     0.8385     55.6329
16100     0.6526      0.7890     0.8385     54.7082
16200     0.5804      0.8312     0.8385     54.7824
16300     0.5810      0.8460     0.8385     55.3985
16400     0.4869      0.8418     0.8385     54.7117
16500     0.5386      0.8291     0.8385     55.2677
16600     0.5668      0.8122     0.8385     55.1078
16700     0.5066      0.8418     0.8385     54.6178
16800     0.5233      0.8333     0.8385     55.9348
16900     0.5859      0.8502     0.8385     55.2407
17000     0.5718      0.8101     0.8385     55.3967
17100     0.4975      0.8397     0.8385     56.5767
17200     0.6297      0.7932     0.8385     54.6275
17300     0.6173      0.8059     0.8385     54.2545
17400     0.5223      0.8354     0.8385     55.2797
17500     0.6279      0.8143     0.8385     54.8328
17600     0.5394      0.8376     0.8385     55.4665
17700     0.5447      0.8523     0.8385     54.6372
17800     0.5639      0.8291     0.8385     54.5108
17900     0.5696      0.8439     0.8385     55.6246
18000     0.5341      0.8439     0.8385     54.6993
18100     0.5217      0.8439     0.8385     54.7145
18200     0.5662      0.8481     0.8385     55.3446
18300     0.5615      0.8354     0.8385     54.9601
18400     0.5657      0.8544     0.8385     55.1195
18500     0.5406      0.8439     0.8385     54.3127
18600     0.6437      0.7911     0.8385     54.6021
18700     0.5641      0.8354     0.8385     54.9209
18800     0.4833      0.8481     0.8385     55.1619
18900     0.6331      0.7954     0.8385     55.1425
19000     0.5055      0.8502     0.8385     55.5392
19100     0.4418      0.8734     0.8385     54.4562
19200     0.4995      0.8439     0.8385     55.1610
19300     0.5974      0.8101     0.8385     54.6138
19400     0.5477      0.8439     0.8385     54.8505
19500     0.5148      0.8502     0.8385     54.9412
19600     0.4820      0.8565     0.8385     54.7498
19700     0.5273      0.8481     0.8386     55.1047
19800     0.6077      0.8122     0.8386     55.7415
19900     0.5771      0.8333     0.8386     56.6728
20000     0.6043      0.8249     0.8390     57.5415
20100     0.5334      0.8502     0.8390     56.1819
20199     0.5728      0.8291     0.8390     55.8213
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.5186      0.8312     0.8362     8.8606
00100     0.3533      0.9030     0.8440     54.7962
00200     0.4858      0.8544     0.8440     54.6761
00300     0.4893      0.8586     0.8440     54.7950
00400     0.3676      0.8882     0.8440     55.4023
00500     0.4107      0.8797     0.8440     55.1329
00600     0.4710      0.8671     0.8440     54.7978
00700     0.4616      0.8629     0.8440     54.6911
00800     0.4242      0.8608     0.8440     54.5412
00900     0.5072      0.8397     0.8440     55.0962
01000     0.3840      0.9072     0.8440     55.5905
01100     0.4834      0.8460     0.8440     55.1964
01200     0.5557      0.8270     0.8440     54.9294
01300     0.4712      0.8629     0.8440     54.3633
01400     0.5011      0.8565     0.8440     55.5079
01500     0.4715      0.8502     0.8440     54.7164
01600     0.4892      0.8713     0.8440     54.2086
01700     0.4872      0.8734     0.8440     55.7518
01800     0.3728      0.9051     0.8440     54.6257
01900     0.3799      0.9008     0.8440     55.3914
02000     0.5083      0.8523     0.8440     55.0193
02100     0.4522      0.8671     0.8440     55.1598
02200     0.4230      0.8840     0.8440     54.8456
02300     0.4190      0.8797     0.8440     54.3834
02400     0.4127      0.8924     0.8440     54.5871
02500     0.4633      0.8629     0.8451     55.1876
02600     0.4650      0.8629     0.8451     54.8113
02700     0.4316      0.8755     0.8455     55.4883
02800     0.4465      0.8608     0.8456     54.3236
02900     0.4452      0.8629     0.8458     55.0049
03000     0.4754      0.8608     0.8460     55.5664
03100     0.4764      0.8650     0.8460     54.6964
03200     0.4381      0.8755     0.8460     54.7691
03300     0.4483      0.8460     0.8460     55.2910
03400     0.4261      0.8692     0.8470     54.6530
03500     0.4683      0.8755     0.8470     55.3445
03600     0.4353      0.8776     0.8470     54.8084
03700     0.4792      0.8523     0.8479     54.2847
03800     0.4343      0.8629     0.8479     54.9605
03900     0.4067      0.8840     0.8479     54.5872
04000     0.4520      0.8840     0.8479     55.0690
04100     0.4516      0.8586     0.8479     54.8936
04200     0.4820      0.8439     0.8479     54.8349
04300     0.4314      0.8692     0.8479     55.2299
04400     0.4153      0.8861     0.8479     54.6304
04500     0.4560      0.8692     0.8479     55.3146
04600     0.4890      0.8629     0.8479     56.0456
04700     0.4962      0.8418     0.8479     55.4120
04800     0.3649      0.9072     0.8479     55.2541
04900     0.4932      0.8629     0.8479     55.4934
05000     0.4479      0.8692     0.8479     54.9552
05100     0.4415      0.8734     0.8479     55.4875
05200     0.4676      0.8629     0.8479     54.2157
05300     0.4510      0.8734     0.8479     54.4504
05400     0.4730      0.8671     0.8479     55.5570
05500     0.4104      0.8797     0.8479     55.2607
05600     0.4705      0.8586     0.8479     54.8095
05700     0.4962      0.8608     0.8479     55.2205
05800     0.4333      0.8755     0.8479     54.4122
05900     0.4296      0.8861     0.8500     55.9979
06000     0.4494      0.8755     0.8500     54.4244
06100     0.4504      0.8776     0.8500     55.1143
06200     0.4560      0.8692     0.8500     55.0893
06300     0.4818      0.8629     0.8500     54.7913
06400     0.4596      0.8629     0.8500     54.6053
06500     0.4578      0.8671     0.8500     54.8497
06600     0.4872      0.8608     0.8500     55.4244
06700     0.4876      0.8629     0.8500     55.5970
06800     0.4775      0.8586     0.8500     54.6243
06900     0.3521      0.9135     0.8500     55.3779
07000     0.4599      0.8523     0.8500     55.0456
07100     0.4354      0.8671     0.8500     54.7368
07200     0.4162      0.8924     0.8500     54.8766
07300     0.5128      0.8460     0.8500     55.2397
07400     0.4723      0.8523     0.8500     54.7796
07500     0.3865      0.8882     0.8500     54.9392
07600     0.4763      0.8544     0.8500     54.6617
07700     0.4249      0.8755     0.8500     55.1006
07800     0.4368      0.8755     0.8500     55.5854
07900     0.4686      0.8565     0.8500     55.5126
08000     0.4605      0.8629     0.8504     54.7409
08100     0.4176      0.8734     0.8504     55.8785
08200     0.4279      0.8713     0.8504     54.6999
08300     0.4002      0.8987     0.8504     55.4185
08400     0.4364      0.8608     0.8505     54.0233
08500     0.4298      0.8713     0.8505     54.5489
08600     0.4608      0.8629     0.8505     55.9418
08700     0.4264      0.8776     0.8505     54.6118
08800     0.4778      0.8629     0.8505     56.2058
08900     0.4227      0.8861     0.8505     55.2057
09000     0.4521      0.8776     0.8505     54.1795
09100     0.4402      0.8713     0.8505     55.0634
09200     0.4422      0.8713     0.8505     54.4347
09300     0.4792      0.8608     0.8505     55.0665
09400     0.4572      0.8629     0.8505     55.4296
09500     0.4644      0.8713     0.8505     54.9369
09600     0.4681      0.8671     0.8505     54.6967
09700     0.4758      0.8502     0.8505     55.5012
09800     0.4404      0.8861     0.8505     54.6469
09900     0.4515      0.8523     0.8505     54.7524
Start testing:
Test Accuracy: 0.8342
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=12, quant_actNM=12, quant_inp=12, quant_w=12, random_seed=193012823, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
6ec491c2-c5c2-4a54-adad-8874baa47d9c
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8016      0.0781     0.0607     10.5805
00100     1.3187      0.5738     0.6046     58.9168
00200     0.8130      0.7384     0.7815     57.7046
00300     0.6474      0.7996     0.8207     58.9869
00400     0.5645      0.8228     0.8407     57.3335
00500     0.5122      0.8376     0.8424     57.0697
00600     0.4575      0.8671     0.8569     57.2809
00700     0.4953      0.8333     0.8662     58.1009
00800     0.4033      0.8713     0.8746     58.2168
00900     0.4168      0.8966     0.8841     57.5373
01000     0.3972      0.8882     0.8841     58.0220
01100     0.3868      0.8903     0.8841     57.6624
01200     0.3760      0.8924     0.8864     59.4434
01300     0.3139      0.9219     0.8919     59.5437
01400     0.3429      0.8903     0.8919     58.1449
01500     0.3482      0.9051     0.8925     56.8558
01600     0.3232      0.9156     0.9028     57.8780
01700     0.2840      0.9304     0.9028     59.1219
01800     0.2918      0.9051     0.9028     57.8513
01900     0.3182      0.9093     0.9028     59.3923
02000     0.3052      0.9051     0.9028     58.0366
02100     0.2788      0.9135     0.9028     58.1339
02200     0.2475      0.9388     0.9028     59.0358
02300     0.2617      0.9262     0.9028     58.6963
02400     0.2823      0.9198     0.9028     59.7012
02500     0.2884      0.9241     0.9028     58.3238
02600     0.2560      0.9283     0.9042     57.2662
02700     0.2249      0.9367     0.9042     58.7766
02800     0.2313      0.9304     0.9042     58.8338
02900     0.2466      0.9409     0.9042     58.6956
03000     0.2344      0.9325     0.9052     58.8316
03100     0.2125      0.9536     0.9052     57.4108
03200     0.1828      0.9515     0.9052     58.8865
03300     0.2505      0.9262     0.9074     58.0746
03400     0.2617      0.9283     0.9074     58.9416
03500     0.1924      0.9451     0.9100     58.9140
03600     0.1742      0.9578     0.9100     57.7729
03700     0.2150      0.9515     0.9107     58.0128
03800     0.2147      0.9367     0.9107     58.6969
03900     0.2292      0.9430     0.9107     58.6622
04000     0.1743      0.9557     0.9108     58.2469
04100     0.1725      0.9620     0.9108     58.7968
04200     0.1973      0.9451     0.9108     58.7780
04300     0.2317      0.9409     0.9108     58.6782
04400     0.2198      0.9388     0.9108     58.3011
04500     0.1534      0.9620     0.9108     58.3085
04600     0.2384      0.9388     0.9109     58.8260
04700     0.1565      0.9662     0.9109     58.3686
04800     0.2178      0.9409     0.9109     58.5426
04900     0.1931      0.9430     0.9109     57.7122
05000     0.1680      0.9557     0.9109     57.7833
05100     0.1816      0.9557     0.9109     58.7126
05200     0.1918      0.9536     0.9109     57.9158
05300     0.1911      0.9473     0.9109     58.1467
05400     0.1359      0.9705     0.9122     58.6379
05500     0.1857      0.9451     0.9122     58.6642
05600     0.1664      0.9557     0.9122     58.9513
05700     0.1605      0.9662     0.9153     59.0019
05800     0.1724      0.9536     0.9153     58.3783
05900     0.1463      0.9599     0.9153     58.7797
06000     0.1916      0.9536     0.9153     60.0623
06100     0.1583      0.9599     0.9153     58.3237
06200     0.1690      0.9599     0.9153     59.4663
06300     0.1981      0.9515     0.9153     57.7133
06400     0.1399      0.9705     0.9153     58.0369
06500     0.1521      0.9578     0.9153     59.3025
06600     0.2095      0.9451     0.9153     59.0925
06700     0.1768      0.9515     0.9153     59.6701
06800     0.1668      0.9536     0.9153     58.1713
06900     0.1937      0.9494     0.9153     59.9361
07000     0.1943      0.9578     0.9153     59.3784
07100     0.1971      0.9388     0.9153     58.3386
07200     0.1585      0.9451     0.9153     58.3508
07300     0.1367      0.9620     0.9153     57.9067
07400     0.1661      0.9599     0.9153     57.9867
07500     0.1883      0.9536     0.9153     58.9466
07600     0.1719      0.9620     0.9153     58.1495
07700     0.1856      0.9515     0.9153     59.0351
07800     0.1516      0.9726     0.9153     58.9076
07900     0.1452      0.9641     0.9153     58.5444
08000     0.2046      0.9409     0.9153     59.6082
08100     0.2083      0.9451     0.9153     58.2704
08200     0.2101      0.9515     0.9153     58.3271
08300     0.1461      0.9662     0.9153     59.0675
08400     0.1738      0.9473     0.9153     57.8245
08500     0.1157      0.9768     0.9153     59.0106
08600     0.1607      0.9557     0.9153     59.0655
08700     0.2036      0.9473     0.9153     57.8030
08800     0.1565      0.9536     0.9153     59.6904
08900     0.1663      0.9578     0.9153     58.4781
09000     0.1302      0.9684     0.9153     59.9372
09100     0.1729      0.9620     0.9153     58.0811
09200     0.2136      0.9536     0.9153     58.2843
09300     0.1542      0.9620     0.9153     57.9268
09400     0.1887      0.9557     0.9153     59.3481
09500     0.1275      0.9726     0.9153     59.3254
09600     0.1423      0.9684     0.9182     59.8245
09700     0.2059      0.9451     0.9182     57.9596
09800     0.1441      0.9684     0.9182     57.9146
09900     0.1121      0.9747     0.9187     57.7188
10000     0.1468      0.9641     0.9187     57.3841
10100     0.1477      0.9705     0.9187     56.8665
10200     0.1521      0.9557     0.9187     57.2692
10300     0.1656      0.9620     0.9187     57.6890
10400     0.1068      0.9789     0.9187     58.7050
10500     0.1268      0.9726     0.9187     57.2695
10600     0.1209      0.9684     0.9187     58.0402
10700     0.1439      0.9641     0.9187     58.1490
10800     0.1140      0.9810     0.9187     56.7804
10900     0.1490      0.9599     0.9187     57.3392
11000     0.1631      0.9536     0.9187     57.8215
11100     0.1149      0.9705     0.9187     57.0082
11200     0.1536      0.9662     0.9187     58.4854
11300     0.1507      0.9726     0.9187     60.1285
11400     0.1212      0.9726     0.9187     57.5795
11500     0.1294      0.9662     0.9187     57.9048
11600     0.1387      0.9705     0.9187     57.0182
11700     0.1228      0.9684     0.9187     56.9503
11800     0.0991      0.9831     0.9187     57.8412
11900     0.1093      0.9768     0.9187     57.7368
12000     0.1893      0.9536     0.9187     57.9827
12100     0.1374      0.9620     0.9187     57.0786
12200     0.1132      0.9768     0.9187     57.5683
12300     0.1490      0.9641     0.9187     59.4685
12400     0.0984      0.9768     0.9187     57.3046
12500     0.1117      0.9789     0.9187     57.6150
12600     0.1060      0.9768     0.9188     57.8659
12700     0.1582      0.9641     0.9188     58.4185
12800     0.1141      0.9810     0.9188     58.0409
12900     0.1108      0.9789     0.9188     58.1498
13000     0.1129      0.9747     0.9188     58.0978
13100     0.0985      0.9789     0.9188     57.6859
13200     0.1270      0.9684     0.9188     57.1592
13300     0.1184      0.9747     0.9188     58.4988
13400     0.1387      0.9641     0.9188     57.9451
13500     0.0821      0.9873     0.9202     57.9132
13600     0.1584      0.9684     0.9202     58.2466
13700     0.1180      0.9705     0.9202     58.5082
13800     0.1015      0.9810     0.9202     57.2789
13900     0.0916      0.9789     0.9202     58.1642
14000     0.1402      0.9641     0.9202     58.1614
14100     0.1060      0.9789     0.9202     57.6986
14200     0.1046      0.9768     0.9202     57.4704
14300     0.1334      0.9705     0.9202     57.9852
14400     0.1063      0.9810     0.9202     58.3906
14500     0.1140      0.9726     0.9202     56.7170
14600     0.1077      0.9768     0.9202     58.5409
14700     0.1075      0.9726     0.9202     57.7064
14800     0.1094      0.9726     0.9202     57.6880
14900     0.0884      0.9852     0.9202     57.7526
15000     0.0913      0.9810     0.9202     58.5964
15100     0.1168      0.9768     0.9202     58.2388
15200     0.1010      0.9810     0.9202     57.9655
15300     0.1188      0.9705     0.9202     57.4725
15400     0.1289      0.9747     0.9202     58.1390
15500     0.1351      0.9662     0.9202     58.2250
15600     0.1130      0.9726     0.9202     57.6658
15700     0.1470      0.9620     0.9202     57.2208
15800     0.1056      0.9852     0.9202     57.8675
15900     0.0838      0.9810     0.9202     57.8781
16000     0.0944      0.9810     0.9202     57.8058
16100     0.1681      0.9662     0.9202     57.3814
16200     0.1291      0.9705     0.9202     58.2111
16300     0.1023      0.9789     0.9202     57.6892
16400     0.1228      0.9684     0.9202     56.4578
16500     0.0847      0.9895     0.9202     58.1213
16600     0.0970      0.9810     0.9202     58.7035
16700     0.1274      0.9705     0.9202     57.5902
16800     0.1082      0.9768     0.9202     57.6435
16900     0.1572      0.9641     0.9202     59.2234
17000     0.1287      0.9662     0.9202     58.2413
17100     0.1055      0.9810     0.9202     58.0105
17200     0.1258      0.9684     0.9202     58.0213
17300     0.1033      0.9810     0.9202     57.5048
17400     0.0893      0.9810     0.9202     57.8751
17500     0.1190      0.9747     0.9202     59.1750
17600     0.1075      0.9705     0.9202     59.6356
17700     0.1117      0.9789     0.9202     57.4944
17800     0.1183      0.9747     0.9202     57.0301
17900     0.1020      0.9831     0.9202     58.7579
18000     0.1123      0.9747     0.9202     57.9915
18100     0.1038      0.9705     0.9202     56.9120
18200     0.0797      0.9895     0.9202     58.5518
18300     0.1542      0.9557     0.9202     57.2728
18400     0.1008      0.9768     0.9202     58.2000
18500     0.1138      0.9705     0.9202     57.7828
18600     0.1023      0.9789     0.9202     57.5128
18700     0.1306      0.9684     0.9202     57.9493
18800     0.1393      0.9747     0.9202     57.0060
18900     0.1407      0.9747     0.9202     57.6738
19000     0.0974      0.9789     0.9202     58.3877
19100     0.0968      0.9810     0.9202     58.7102
19200     0.0911      0.9789     0.9202     57.7811
19300     0.1175      0.9684     0.9202     57.3772
19400     0.1098      0.9726     0.9202     58.9174
19500     0.0980      0.9810     0.9202     58.6069
19600     0.1214      0.9852     0.9202     57.3761
19700     0.1411      0.9747     0.9202     57.2050
19800     0.1292      0.9641     0.9202     57.8894
19900     0.1044      0.9747     0.9202     57.9872
20000     0.1113      0.9747     0.9202     57.2330
20100     0.0785      0.9895     0.9202     58.1732
20199     0.1003      0.9747     0.9202     56.7720
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.1062      0.9768     0.9157     8.9153
00100     0.0990      0.9831     0.9157     58.3561
00200     0.0872      0.9852     0.9157     58.0048
00300     0.0830      0.9873     0.9157     58.0678
00400     0.0990      0.9789     0.9157     57.1804
00500     0.0922      0.9768     0.9157     57.2352
00600     0.1269      0.9684     0.9157     58.4137
00700     0.0999      0.9831     0.9157     58.8142
00800     0.0743      0.9873     0.9157     57.3199
00900     0.0886      0.9789     0.9157     57.6333
01000     0.0782      0.9831     0.9157     57.4065
01100     0.0807      0.9852     0.9157     58.2680
01200     0.0980      0.9852     0.9157     58.1135
01300     0.0862      0.9831     0.9157     57.2995
01400     0.1002      0.9789     0.9157     57.4068
01500     0.1099      0.9726     0.9157     56.9798
01600     0.0979      0.9747     0.9157     56.4307
01700     0.0763      0.9852     0.9157     57.8877
01800     0.1047      0.9810     0.9157     57.8906
01900     0.0618      0.9916     0.9157     58.0673
02000     0.0866      0.9831     0.9157     58.6699
02100     0.0782      0.9852     0.9157     57.3630
02200     0.0768      0.9852     0.9157     58.1150
02300     0.1556      0.9578     0.9157     58.7347
02400     0.0650      0.9895     0.9157     57.7082
02500     0.0753      0.9831     0.9157     57.6662
02600     0.0907      0.9810     0.9157     58.9613
02700     0.0926      0.9831     0.9157     57.8122
02800     0.0762      0.9873     0.9157     57.2359
02900     0.0940      0.9831     0.9157     57.9112
03000     0.0812      0.9852     0.9157     59.7965
03100     0.0923      0.9768     0.9157     58.1679
03200     0.0866      0.9873     0.9157     56.9578
03300     0.1141      0.9747     0.9157     57.8131
03400     0.1033      0.9789     0.9157     58.9866
03500     0.1351      0.9768     0.9157     58.1100
03600     0.0931      0.9789     0.9157     58.8270
03700     0.0713      0.9916     0.9157     57.3474
03800     0.0800      0.9810     0.9157     58.4024
03900     0.0790      0.9831     0.9157     57.6553
04000     0.0997      0.9789     0.9157     57.8269
04100     0.0856      0.9810     0.9157     58.0714
04200     0.0872      0.9768     0.9157     57.5536
04300     0.0697      0.9916     0.9157     57.3492
04400     0.0812      0.9831     0.9157     57.6140
04500     0.0802      0.9831     0.9157     57.1163
04600     0.0723      0.9895     0.9157     57.8799
04700     0.0819      0.9852     0.9157     57.4951
04800     0.0767      0.9873     0.9157     57.6035
04900     0.0776      0.9852     0.9157     58.7198
05000     0.1016      0.9768     0.9157     59.3863
05100     0.0871      0.9831     0.9157     58.2333
05200     0.0909      0.9810     0.9157     57.4981
05300     0.0865      0.9852     0.9157     58.9160
05400     0.0890      0.9852     0.9157     58.2829
05500     0.0688      0.9852     0.9157     57.4374
05600     0.0857      0.9831     0.9157     58.3626
05700     0.0789      0.9873     0.9157     57.8326
05800     0.0797      0.9810     0.9157     56.8920
05900     0.0903      0.9810     0.9157     58.5763
06000     0.0865      0.9873     0.9157     58.1411
06100     0.0610      0.9895     0.9157     56.8533
06200     0.0938      0.9768     0.9157     57.1747
06300     0.0871      0.9831     0.9157     57.9420
06400     0.0890      0.9852     0.9157     58.1401
06500     0.0648      0.9916     0.9157     58.5752
06600     0.0863      0.9810     0.9157     57.3091
06700     0.0932      0.9852     0.9157     59.0871
06800     0.0891      0.9831     0.9157     57.7320
06900     0.0732      0.9852     0.9157     58.1997
07000     0.0782      0.9852     0.9157     56.9098
07100     0.0908      0.9810     0.9157     57.9007
07200     0.0991      0.9852     0.9157     57.5142
07300     0.1095      0.9726     0.9157     57.9428
07400     0.0765      0.9895     0.9157     59.3394
07500     0.0809      0.9810     0.9157     58.7538
07600     0.0627      0.9895     0.9157     58.1032
07700     0.0724      0.9916     0.9157     58.0910
07800     0.0849      0.9810     0.9157     58.1990
07900     0.1248      0.9705     0.9157     58.1528
08000     0.0691      0.9916     0.9157     58.8768
08100     0.0965      0.9810     0.9157     58.0567
08200     0.0740      0.9916     0.9157     57.6922
08300     0.0562      0.9958     0.9157     58.4250
08400     0.0959      0.9747     0.9157     57.9866
08500     0.0797      0.9873     0.9157     58.7027
08600     0.0791      0.9810     0.9157     58.0791
08700     0.0727      0.9873     0.9157     58.3553
08800     0.0805      0.9873     0.9157     57.6703
08900     0.0853      0.9895     0.9157     60.3303
09000     0.0831      0.9852     0.9157     56.4912
09100     0.0864      0.9768     0.9157     58.3767
09200     0.0836      0.9873     0.9157     59.2795
09300     0.0947      0.9810     0.9157     58.8466
09400     0.0988      0.9831     0.9157     59.2533
09500     0.0788      0.9852     0.9157     58.3376
09600     0.0849      0.9873     0.9157     58.6229
09700     0.0929      0.9810     0.9157     58.3778
09800     0.0727      0.9873     0.9157     57.8714
09900     0.0844      0.9810     0.9157     58.5903
Start testing:
Test Accuracy: 0.9040
