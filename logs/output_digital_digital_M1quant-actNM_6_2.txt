Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=6, quant_actNM=6, quant_inp=6, quant_w=6, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
adbec28e-7153-45d2-bd5f-8bf3db671164
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=6, quant_actNM=6, quant_inp=6, quant_w=6, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
50245c5f-9aea-4cb9-900d-8edc5ea5eff9
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=6, quant_actNM=6, quant_inp=6, quant_w=6, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
2ab2aab6-195c-4246-be82-e1addabe57f0
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.5431      0.0717     0.0605     9.9409
00100     2.4102      0.1709     0.1534     54.4437
00200     1.8995      0.3692     0.3994     53.9972
00300     1.6025      0.4388     0.4547     55.6777
00400     1.5770      0.4578     0.4906     54.0985
00500     1.5267      0.4705     0.5315     54.6431
00600     1.3386      0.5190     0.5433     54.9597
00700     1.2558      0.5549     0.5725     54.8061
00800     1.2089      0.5549     0.5910     54.7025
00900     1.1909      0.5612     0.5993     54.8104
01000     1.1612      0.6224     0.6181     55.4781
01100     1.2431      0.5591     0.6231     54.9675
01200     1.2498      0.5823     0.6534     55.1614
01300     1.1290      0.5992     0.6601     55.0178
01400     1.1588      0.6013     0.6601     54.8695
01500     1.0942      0.6371     0.6642     55.1645
01600     1.0329      0.6498     0.6683     55.0162
01700     1.0252      0.6667     0.6784     54.7647
01800     0.8884      0.6814     0.6784     54.5088
01900     1.0598      0.6308     0.6784     55.0457
02000     1.0847      0.6371     0.6968     55.6596
02100     0.9679      0.7046     0.6968     54.5787
02200     1.0426      0.6414     0.6968     55.6685
02300     0.9867      0.6519     0.7066     55.4285
02400     0.8800      0.6878     0.7131     55.2153
02500     0.9280      0.6835     0.7131     55.3457
02600     0.9680      0.6751     0.7145     54.5512
02700     0.9499      0.6835     0.7157     54.3226
02800     0.9803      0.6477     0.7307     54.5265
02900     0.8255      0.7110     0.7307     55.4410
03000     0.8773      0.6835     0.7445     55.0161
03100     0.8600      0.7110     0.7445     54.8208
03200     0.9178      0.7131     0.7445     55.0216
03300     1.0394      0.6181     0.7445     54.8981
03400     0.9621      0.6772     0.7445     54.8060
03500     0.8996      0.6920     0.7445     55.2036
03600     0.9170      0.6730     0.7484     54.4919
03700     0.9064      0.6709     0.7484     55.8110
03800     0.8482      0.6814     0.7484     55.0763
03900     0.8245      0.7278     0.7484     54.7281
04000     0.8507      0.7173     0.7504     55.6631
04100     0.9116      0.6667     0.7504     55.4016
04200     0.9034      0.6835     0.7575     54.8496
04300     0.8132      0.7215     0.7575     54.6562
04400     0.9341      0.6519     0.7577     55.3105
04500     0.8879      0.6983     0.7588     54.6693
04600     0.8226      0.7173     0.7588     55.1722
04700     0.8262      0.7068     0.7588     54.5964
04800     0.7688      0.7384     0.7588     54.9196
04900     0.8547      0.7173     0.7588     55.5356
05000     0.8786      0.7068     0.7588     54.5615
05100     0.8763      0.7278     0.7588     55.3652
05200     0.8461      0.7089     0.7684     55.0639
05300     0.7900      0.7173     0.7684     54.6901
05400     0.8092      0.6941     0.7684     55.0359
05500     0.9332      0.6878     0.7684     54.7211
05600     0.8132      0.7278     0.7684     55.2539
05700     0.7742      0.7278     0.7684     55.8317
05800     0.8236      0.7321     0.7759     54.6724
05900     0.8342      0.7152     0.7759     55.1880
06000     0.7968      0.7236     0.7759     55.2621
06100     0.8984      0.6857     0.7774     55.3699
06200     0.8729      0.7004     0.7774     55.7256
06300     0.7808      0.7342     0.7838     56.7265
06400     0.8095      0.7300     0.7838     57.9122
06500     0.7299      0.7553     0.7838     57.6408
06600     0.6777      0.7511     0.7838     56.3903
06700     0.7349      0.7447     0.7838     59.0757
06800     0.8267      0.7110     0.7838     55.7643
06900     0.7444      0.7679     0.7838     55.5738
07000     0.7799      0.7785     0.7878     55.5184
07100     0.8018      0.7110     0.7878     54.9680
07200     0.8389      0.7004     0.7878     55.1247
07300     0.8761      0.7089     0.7878     55.0917
07400     0.7521      0.7363     0.7878     54.9428
07500     0.7208      0.7532     0.7878     55.4955
07600     0.8150      0.7278     0.7878     55.0827
07700     0.6934      0.7722     0.7878     57.0493
07800     0.8063      0.7300     0.7878     55.8425
07900     0.7341      0.7489     0.7878     54.7583
08000     0.8430      0.6835     0.7878     55.7715
08100     0.6609      0.7785     0.7878     54.6106
08200     0.8320      0.7236     0.7878     54.6308
08300     0.7226      0.7637     0.7878     55.7748
08400     0.8410      0.7215     0.7878     55.4501
08500     0.8365      0.7405     0.7878     55.0460
08600     0.7395      0.7447     0.7878     55.7376
08700     0.7527      0.7426     0.7878     54.5248
08800     0.8169      0.7068     0.7878     55.5186
08900     0.7427      0.7468     0.7878     55.3562
09000     0.7627      0.7321     0.7878     55.0298
09100     0.7157      0.7553     0.7878     55.5424
09200     0.8005      0.7236     0.7878     54.7392
09300     0.8068      0.7342     0.7878     55.4769
09400     0.8152      0.7257     0.7878     57.1616
09500     0.6817      0.7658     0.7878     56.8202
09600     0.7338      0.7637     0.7878     57.2502
09700     0.7545      0.7363     0.7878     56.1113
09800     0.8536      0.7046     0.7878     58.4965
09900     0.8106      0.7511     0.7878     56.5691
10000     0.7997      0.7384     0.7928     56.4469
10100     0.7687      0.7384     0.7928     56.0232
10200     0.7144      0.7616     0.7986     57.1702
10300     0.7680      0.7321     0.8018     57.5050
10400     0.6811      0.7743     0.8018     57.5891
10500     0.6223      0.7658     0.8049     56.5428
10600     0.6752      0.7679     0.8049     57.4447
10700     0.7537      0.7616     0.8049     57.0699
10800     0.7894      0.7278     0.8049     58.2926
10900     0.7931      0.7511     0.8057     57.2800
11000     0.8217      0.7278     0.8057     55.9886
11100     0.7907      0.7194     0.8057     56.1140
11200     0.6957      0.7722     0.8057     57.7125
11300     0.7446      0.7278     0.8057     56.1853
11400     0.6978      0.7785     0.8057     55.5229
11500     0.6125      0.7806     0.8057     56.5481
11600     0.7571      0.7447     0.8057     57.0683
11700     0.7888      0.7194     0.8057     56.6200
11800     0.8922      0.7152     0.8057     57.0604
11900     0.8260      0.7300     0.8057     55.2869
12000     0.6869      0.7616     0.8057     57.0467
12100     0.7746      0.7173     0.8057     55.2337
12200     0.7848      0.7257     0.8057     55.5716
12300     0.7474      0.7679     0.8057     55.2855
12400     0.7170      0.7532     0.8057     54.5183
12500     0.7266      0.7574     0.8057     54.8495
12600     0.6489      0.7996     0.8057     55.1515
12700     0.6927      0.7722     0.8057     54.4922
12800     0.7365      0.7574     0.8057     55.3782
12900     0.7056      0.7722     0.8057     54.8446
13000     0.7325      0.7616     0.8057     55.3540
13100     0.8213      0.7068     0.8057     57.3010
13200     0.7337      0.7468     0.8057     57.0155
13300     0.7707      0.7321     0.8057     57.4736
13400     0.6944      0.7489     0.8057     56.5135
13500     0.7903      0.7300     0.8057     57.3244
13600     0.8259      0.7068     0.8057     56.4545
13700     0.7292      0.7511     0.8057     56.5369
13800     0.7193      0.7447     0.8057     54.8631
13900     0.6433      0.7827     0.8057     57.2475
14000     0.6127      0.7764     0.8057     56.6317
14100     0.7024      0.7743     0.8057     56.3520
14200     0.7916      0.7300     0.8057     57.1210
14300     0.6700      0.7827     0.8057     56.1273
14400     0.7152      0.7489     0.8057     56.8075
14500     0.7251      0.7637     0.8057     57.1776
14600     0.7185      0.7489     0.8057     57.5119
14700     0.7249      0.7553     0.8057     57.7141
14800     0.7063      0.7489     0.8057     56.7271
14900     0.7217      0.7574     0.8057     57.0647
15000     0.6848      0.7679     0.8057     57.3706
15100     0.7454      0.7468     0.8057     56.7031
15200     0.8767      0.7426     0.8057     57.1404
15300     0.7723      0.7489     0.8057     57.3321
15400     0.7344      0.7468     0.8057     58.3362
15500     0.6953      0.7764     0.8057     57.1038
15600     0.6536      0.7700     0.8057     56.5444
15700     0.6390      0.8080     0.8057     57.6302
15800     0.6395      0.7869     0.8057     57.7777
15900     0.7298      0.7637     0.8057     58.0335
16000     0.6833      0.7363     0.8057     57.5589
16100     0.7098      0.7700     0.8057     55.6863
16200     0.6903      0.7764     0.8057     56.8673
16300     0.6985      0.7806     0.8057     57.0474
16400     0.8463      0.7215     0.8057     58.1008
16500     0.5932      0.8038     0.8057     57.6005
16600     0.7146      0.7511     0.8057     56.2306
16700     0.6976      0.7489     0.8057     57.2341
16800     0.7537      0.7595     0.8057     56.9470
16900     0.7906      0.7300     0.8057     56.8888
17000     0.7620      0.7637     0.8057     56.3514
17100     0.8164      0.7342     0.8065     57.4482
17200     0.7225      0.7806     0.8065     57.1630
17300     0.7751      0.7236     0.8065     56.7298
17400     0.7883      0.7152     0.8065     56.5652
17500     0.7373      0.7553     0.8065     56.9169
17600     0.7751      0.7405     0.8065     57.0646
17700     0.7458      0.7426     0.8065     56.4037
17800     0.8219      0.7447     0.8065     56.7791
17900     0.7404      0.7173     0.8065     56.8165
18000     0.7134      0.7468     0.8065     56.1375
18100     0.7379      0.7532     0.8065     54.3641
18200     0.6683      0.7932     0.8065     57.5227
18300     0.8228      0.7046     0.8065     55.4394
18400     0.6830      0.7616     0.8065     56.8636
18500     0.7630      0.7405     0.8065     56.3057
18600     0.6655      0.7743     0.8065     55.8817
18700     0.7540      0.7278     0.8065     56.5672
18800     0.7682      0.7363     0.8065     57.4662
18900     0.7621      0.7236     0.8065     56.3900
19000     0.6909      0.7658     0.8065     55.7666
19100     0.7950      0.7384     0.8065     54.6803
19200     0.7729      0.7215     0.8106     55.5445
19300     0.7708      0.7405     0.8106     54.3979
19400     0.7438      0.7722     0.8106     54.7652
19500     0.7295      0.7511     0.8106     55.6350
19600     0.8115      0.7215     0.8106     54.2959
19700     0.8249      0.7194     0.8106     54.7886
19800     0.8167      0.7300     0.8106     55.6360
19900     0.7130      0.7616     0.8106     54.9437
20000     0.7472      0.7489     0.8106     55.2762
20100     0.7952      0.7257     0.8106     54.9891
20199     0.7411      0.7658     0.8106     54.0682
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.6371      0.7890     0.7897     9.2332
00100     0.6580      0.7743     0.8058     55.7669
00200     0.6480      0.8038     0.8058     53.9805
00300     0.6688      0.7764     0.8058     55.2808
00400     0.6840      0.7616     0.8058     54.8896
00500     0.6475      0.7806     0.8058     54.6546
00600     0.6366      0.7511     0.8058     55.3368
00700     0.6649      0.7848     0.8058     55.3558
00800     0.6937      0.7616     0.8058     55.5747
00900     0.6496      0.7764     0.8058     55.3787
01000     0.6613      0.7700     0.8058     55.2686
01100     0.6161      0.7785     0.8072     55.4337
01200     0.6562      0.7616     0.8072     54.9663
01300     0.7298      0.7511     0.8072     55.0675
01400     0.6979      0.7806     0.8072     55.4597
01500     0.6648      0.7848     0.8072     55.0859
01600     0.6585      0.8017     0.8072     56.2183
01700     0.6659      0.7785     0.8072     55.3550
01800     0.7092      0.7637     0.8072     55.3005
01900     0.5460      0.7996     0.8072     55.6663
02000     0.6871      0.7700     0.8072     54.9166
02100     0.6294      0.7658     0.8072     54.3381
02200     0.5641      0.8143     0.8072     54.8126
02300     0.6538      0.7743     0.8072     54.8746
02400     0.5792      0.8122     0.8072     57.2631
02500     0.6137      0.7806     0.8072     57.6428
02600     0.5944      0.7954     0.8072     57.3273
02700     0.6906      0.7700     0.8072     57.4639
02800     0.7287      0.7848     0.8072     57.4966
02900     0.6735      0.7785     0.8072     57.6929
03000     0.6445      0.7890     0.8096     55.0530
03100     0.6196      0.8017     0.8096     54.6546
03200     0.6394      0.8017     0.8096     54.5972
03300     0.5795      0.8017     0.8096     55.0708
03400     0.7131      0.7637     0.8096     54.0954
03500     0.7006      0.7447     0.8096     55.5867
03600     0.6465      0.7785     0.8096     53.7357
03700     0.6255      0.7785     0.8096     53.7091
03800     0.6921      0.7722     0.8096     54.8055
03900     0.6218      0.7848     0.8098     54.0058
04000     0.5895      0.7911     0.8098     54.8638
04100     0.6176      0.7764     0.8098     54.8517
04200     0.6099      0.8038     0.8098     55.3704
04300     0.6754      0.7637     0.8098     55.1900
04400     0.5926      0.7975     0.8098     54.0290
04500     0.6917      0.7489     0.8098     53.8391
04600     0.7074      0.7405     0.8098     54.7039
04700     0.6721      0.8017     0.8098     54.0846
04800     0.7383      0.7553     0.8098     54.7346
04900     0.7182      0.7595     0.8098     54.8603
05000     0.6507      0.7785     0.8098     54.3997
05100     0.6559      0.7658     0.8098     54.8284
05200     0.5859      0.8038     0.8098     54.7089
05300     0.6219      0.7806     0.8098     54.5506
05400     0.6819      0.7869     0.8098     54.8708
05500     0.6821      0.7848     0.8098     54.2763
05600     0.7221      0.7743     0.8098     54.6819
05700     0.6197      0.7848     0.8098     54.9074
05800     0.7373      0.7679     0.8098     54.0490
05900     0.5471      0.8080     0.8098     55.6006
06000     0.5501      0.8122     0.8098     55.5800
06100     0.5649      0.8143     0.8098     54.6307
06200     0.6483      0.7827     0.8098     54.9937
06300     0.7228      0.7553     0.8098     54.3941
06400     0.6398      0.8101     0.8098     54.4697
06500     0.6235      0.7722     0.8098     54.3563
06600     0.7241      0.7637     0.8098     55.1409
06700     0.7664      0.7532     0.8098     55.2573
06800     0.5752      0.7932     0.8098     54.7207
06900     0.6809      0.7574     0.8098     55.3830
07000     0.6141      0.7806     0.8098     55.5508
07100     0.6374      0.7975     0.8098     54.4512
07200     0.6998      0.7764     0.8098     54.7068
07300     0.6063      0.8059     0.8098     55.3636
07400     0.6274      0.7806     0.8098     54.3005
07500     0.6612      0.7722     0.8098     54.7889
07600     0.6835      0.7658     0.8098     54.7163
07700     0.6051      0.8122     0.8138     54.5539
07800     0.7579      0.7722     0.8138     56.7713
07900     0.6438      0.7890     0.8138     56.7845
08000     0.6050      0.7722     0.8138     56.2427
08100     0.6631      0.7848     0.8138     56.2600
08200     0.5976      0.7996     0.8138     54.9335
08300     0.6568      0.7932     0.8138     55.2588
08400     0.7144      0.7574     0.8138     54.7708
08500     0.6654      0.7658     0.8138     54.8461
08600     0.5804      0.7975     0.8138     54.7938
08700     0.6389      0.7890     0.8138     54.7648
08800     0.5949      0.8059     0.8138     55.0821
08900     0.6113      0.7890     0.8138     58.7986
09000     0.6970      0.7595     0.8138     56.5791
09100     0.6560      0.7890     0.8138     56.6777
09200     0.5982      0.7954     0.8138     56.8889
09300     0.6388      0.7785     0.8138     56.7201
09400     0.6111      0.7911     0.8138     58.1456
09500     0.7161      0.7616     0.8138     55.5001
09600     0.6438      0.7637     0.8138     56.9518
09700     0.6659      0.7869     0.8138     56.6887
09800     0.7021      0.7574     0.8138     56.0651
09900     0.6157      0.8165     0.8138     55.7508
Start testing:
Test Accuracy: 0.7708
