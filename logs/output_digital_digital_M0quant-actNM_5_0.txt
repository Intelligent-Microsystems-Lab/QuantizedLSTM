Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
0fb5b5f4-fa87-4c23-a387-c5d211227fa2
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
dda42298-0626-4c78-a3e0-9c806bb70245
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
014af1b3-309e-48dd-a09c-ae74c42b13a1
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]).device(input.device))
TypeError: 'torch.device' object is not callable
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
8d16b852-a939-423e-b543-911639b1165b
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8573      0.0654     0.0846     9.7828
00100     2.5158      0.0970     0.0935     70.1551
00200     2.4901      0.1857     0.1843     71.0003
00300     2.3938      0.1751     0.2425     71.4924
00400     2.2978      0.1793     0.2425     72.0358
00500     2.1205      0.2637     0.2848     71.3931
00600     1.9860      0.3629     0.3866     70.7421
00700     1.8294      0.4409     0.4434     70.9794
00800     1.6636      0.4916     0.5288     71.1628
00900     1.6099      0.5084     0.5484     72.1534
01000     1.4741      0.5443     0.5534     71.5123
01100     1.4708      0.5527     0.5711     70.9687
01200     1.3838      0.5527     0.5833     70.7282
01300     1.3606      0.5802     0.6080     70.9191
01400     1.4537      0.5464     0.6080     70.6219
01500     1.4284      0.5633     0.6080     70.5113
01600     1.3724      0.5759     0.6243     72.1654
01700     1.3362      0.6160     0.6298     70.6127
01800     1.3474      0.5696     0.6298     70.7298
01900     1.2625      0.5886     0.6332     71.2695
02000     1.2851      0.6034     0.6536     70.5685
02100     1.1977      0.6371     0.6536     70.0577
02200     1.1772      0.6118     0.6599     70.5625
02300     1.2554      0.5907     0.6599     69.9715
02400     1.1686      0.6245     0.6599     71.0063
02500     1.3020      0.5823     0.6628     71.2500
02600     1.2195      0.6076     0.6628     71.0985
02700     1.2305      0.6435     0.6628     70.9756
02800     1.1990      0.6350     0.6760     70.6403
02900     1.2891      0.6224     0.6760     70.9884
03000     1.1541      0.6624     0.6760     71.4764
03100     1.1424      0.6456     0.6760     73.1855
03200     1.2123      0.6181     0.6760     72.7159
03300     1.1657      0.6392     0.6780     71.5422
03400     1.2325      0.5992     0.6780     71.3364
03500     1.2872      0.5823     0.6780     72.2318
03600     1.1597      0.6392     0.6780     71.2118
03700     1.1865      0.6371     0.6904     70.9794
03800     1.1726      0.6561     0.6904     71.2994
03900     1.1826      0.6266     0.6904     71.7860
04000     1.1395      0.6456     0.6904     71.9034
04100     1.0950      0.6456     0.6904     72.0785
04200     1.2390      0.6308     0.6905     71.1632
04300     1.2210      0.6329     0.7027     71.9134
04400     1.2040      0.6350     0.7099     71.3275
04500     1.0838      0.6667     0.7099     71.3248
04600     1.1201      0.6392     0.7113     70.6820
04700     1.0267      0.6709     0.7115     70.5692
04800     1.0564      0.6941     0.7115     71.9520
04900     1.0841      0.6646     0.7115     71.0034
05000     1.0376      0.6835     0.7115     71.0696
05100     1.0816      0.6603     0.7115     71.5319
05200     1.1014      0.6688     0.7115     72.4887
05300     1.1665      0.6266     0.7115     71.8220
05400     1.1414      0.6287     0.7115     71.3461
05500     1.0856      0.6582     0.7115     70.9394
05600     1.0882      0.6709     0.7119     72.1164
05700     1.1433      0.6414     0.7140     70.4826
05800     1.1330      0.6498     0.7178     71.1581
05900     1.1260      0.6477     0.7178     71.0417
06000     1.1474      0.6287     0.7178     70.6378
06100     1.2169      0.6203     0.7178     71.2323
06200     1.0970      0.6519     0.7178     70.9854
06300     1.0898      0.6688     0.7178     71.2051
06400     1.0721      0.6709     0.7178     71.8010
06500     1.1278      0.6477     0.7178     71.4346
06600     1.1220      0.6646     0.7178     72.6961
06700     1.0577      0.6793     0.7178     71.8212
06800     1.1000      0.6435     0.7221     71.3805
06900     1.0312      0.7046     0.7221     71.5859
07000     1.1633      0.6582     0.7221     72.2767
07100     1.0656      0.6414     0.7221     71.6628
07200     1.1088      0.6582     0.7221     71.6042
07300     1.2205      0.6245     0.7221     71.2957
07400     1.0882      0.6941     0.7221     71.9271
07500     1.0346      0.6793     0.7221     71.6771
07600     1.1171      0.6582     0.7221     71.4154
07700     0.9911      0.7194     0.7221     71.5412
07800     1.1253      0.6287     0.7221     72.3418
07900     1.1810      0.6371     0.7221     71.5509
08000     1.1122      0.6477     0.7221     71.7524
08100     1.1596      0.6540     0.7221     71.9825
08200     1.0273      0.6793     0.7221     72.0366
08300     1.0315      0.6878     0.7221     71.8142
08400     1.1128      0.6561     0.7221     70.9124
08500     1.0565      0.6814     0.7221     71.8894
08600     1.0589      0.6857     0.7221     72.2764
08700     1.0108      0.6814     0.7221     72.9279
08800     1.0797      0.6814     0.7221     72.6863
08900     1.1102      0.6287     0.7221     71.8916
09000     1.1214      0.6667     0.7221     71.7332
09100     1.0413      0.6709     0.7221     72.1280
09200     1.1461      0.6477     0.7221     71.8314
09300     1.0373      0.6688     0.7221     71.7984
09400     1.0510      0.6751     0.7221     71.9176
09500     1.2142      0.6329     0.7221     72.3344
09600     1.0521      0.6709     0.7280     71.4133
09700     1.0980      0.6603     0.7280     71.5042
09800     1.0889      0.6435     0.7280     71.4262
09900     1.0651      0.6730     0.7280     72.8512
10000     1.0269      0.6899     0.7280     72.4060
10100     1.0792      0.6857     0.7287     71.7629
10200     1.0437      0.6793     0.7287     73.1415
10300     1.0590      0.6477     0.7287     72.2191
10400     1.0288      0.6814     0.7287     71.4818
10500     1.0016      0.6793     0.7287     72.2847
10600     1.0334      0.6899     0.7287     72.0645
10700     1.0571      0.6624     0.7317     71.9609
10800     1.1008      0.6582     0.7347     72.6670
10900     1.0814      0.6793     0.7347     72.2877
11000     0.9790      0.6878     0.7347     72.3417
11100     1.0211      0.7046     0.7347     72.3149
11200     0.9394      0.6983     0.7347     72.4810
11300     1.1019      0.6519     0.7347     71.9326
11400     1.1205      0.6519     0.7347     71.5701
11500     1.0575      0.6688     0.7347     73.1775
11600     1.0739      0.6350     0.7347     73.3281
11700     1.0922      0.6392     0.7347     71.4968
11800     0.9931      0.7004     0.7347     72.8093
11900     1.0586      0.6730     0.7347     72.1726
12000     1.0138      0.6835     0.7381     72.1035
12100     0.9538      0.7046     0.7381     71.9590
12200     1.0899      0.6603     0.7381     71.4809
12300     1.0065      0.6920     0.7381     71.9937
12400     1.1177      0.6540     0.7381     72.6215
12500     1.0843      0.6371     0.7381     71.8127
12600     1.1435      0.6519     0.7381     72.0726
12700     1.0924      0.6582     0.7381     72.5776
12800     1.0612      0.6814     0.7381     73.1808
12900     1.0395      0.6920     0.7381     72.6322
13000     1.0307      0.6857     0.7381     72.5732
13100     1.0652      0.6814     0.7381     72.7482
13200     1.0632      0.6667     0.7381     72.2674
13300     1.0775      0.6688     0.7381     72.2869
13400     1.0842      0.6857     0.7381     73.6213
13500     1.1485      0.6456     0.7381     73.0516
13600     1.0834      0.6498     0.7381     72.8840
13700     1.0714      0.6646     0.7381     73.0279
13800     1.0189      0.6646     0.7381     72.6372
13900     0.9681      0.6962     0.7381     74.0910
14000     1.0727      0.6709     0.7381     73.0814
14100     1.0191      0.6793     0.7381     72.2656
14200     0.9678      0.7068     0.7381     72.8241
14300     1.0580      0.6709     0.7381     72.9164
14400     1.0760      0.6582     0.7381     73.0366
14500     1.0462      0.6793     0.7381     72.2887
14600     1.0607      0.6667     0.7381     71.5402
14700     0.9463      0.7173     0.7412     73.1413
14800     1.1038      0.6519     0.7412     73.2083
14900     1.1577      0.6435     0.7412     73.2447
15000     1.0058      0.7004     0.7412     73.0218
15100     1.1059      0.6456     0.7415     73.5545
15200     1.0019      0.6899     0.7415     73.6156
15300     0.9772      0.7173     0.7415     72.8762
15400     1.0604      0.6772     0.7415     74.1937
15500     1.1405      0.6498     0.7415     73.5460
15600     1.0449      0.6624     0.7415     73.0760
15700     0.9664      0.7131     0.7415     73.6830
15800     1.1877      0.6245     0.7415     72.7914
15900     1.0051      0.6709     0.7415     73.7195
16000     0.9916      0.6899     0.7415     72.7724
16100     1.0854      0.6603     0.7435     73.3121
16200     1.0242      0.6983     0.7435     72.3725
16300     1.0483      0.6793     0.7435     73.5786
16400     0.9180      0.7215     0.7435     72.6752
16500     1.0060      0.6878     0.7435     73.5391
16600     1.0892      0.6582     0.7435     72.7176
16700     0.9990      0.6920     0.7435     72.9740
16800     1.0228      0.6646     0.7435     73.5816
16900     1.0751      0.6793     0.7435     73.1130
17000     1.1397      0.6350     0.7451     73.4875
17100     0.9596      0.7025     0.7451     72.9820
17200     1.0557      0.6603     0.7451     73.5866
17300     1.0847      0.6498     0.7451     72.8136
17400     1.1431      0.6350     0.7451     73.4243
17500     1.2473      0.6203     0.7451     72.5138
17600     1.0996      0.6308     0.7451     73.2248
17700     1.0396      0.6899     0.7451     72.6681
17800     0.9932      0.6814     0.7451     72.6479
17900     1.0353      0.6730     0.7451     73.3316
18000     0.9993      0.6899     0.7451     73.3521
18100     1.0797      0.6646     0.7451     73.7378
18200     1.1417      0.6287     0.7451     72.3809
18300     1.0425      0.6962     0.7451     72.8443
18400     1.0982      0.6498     0.7451     72.8066
18500     0.9943      0.6857     0.7451     72.0876
18600     1.1159      0.6435     0.7451     72.9551
18700     1.0507      0.6624     0.7451     73.0854
18800     1.0606      0.6899     0.7451     72.4959
18900     1.0049      0.6899     0.7451     72.7107
19000     1.0553      0.6878     0.7451     73.2588
19100     0.9482      0.7131     0.7451     72.7878
19200     1.0613      0.6371     0.7451     73.3110
19300     1.1098      0.6561     0.7451     73.7118
19400     1.1279      0.6287     0.7451     72.5973
19500     1.0415      0.6920     0.7451     72.7075
19600     1.0352      0.6730     0.7451     73.1544
19700     1.0361      0.6582     0.7451     73.7963
19800     1.1324      0.6371     0.7451     73.2150
19900     1.0992      0.6582     0.7451     72.7198
20000     1.0071      0.6920     0.7451     74.7415
20100     1.1197      0.6498     0.7451     74.6386
20199     1.0242      0.6709     0.7451     72.7847
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     1.0413      0.6835     0.7299     10.6659
00100     0.8750      0.7236     0.7489     70.6595
00200     1.0537      0.6793     0.7489     71.5347
00300     0.9707      0.7046     0.7492     71.9461
00400     0.9484      0.6920     0.7492     70.7946
00500     0.9499      0.6920     0.7492     72.5124
00600     0.9643      0.7068     0.7492     70.7999
00700     0.9560      0.7004     0.7492     70.9631
00800     0.8846      0.7405     0.7492     70.9426
00900     1.0135      0.6772     0.7492     71.3349
01000     1.0111      0.6793     0.7492     71.5021
01100     1.0263      0.6920     0.7492     70.6474
01200     1.0338      0.6857     0.7492     70.0856
01300     0.9622      0.6878     0.7492     70.8381
01400     1.0427      0.6772     0.7492     70.9802
01500     0.9763      0.6941     0.7492     70.9302
01600     1.0144      0.6793     0.7492     70.6167
01700     0.9588      0.7152     0.7492     71.1504
01800     0.8654      0.7363     0.7492     71.0566
01900     0.8928      0.7215     0.7492     71.3743
02000     1.0449      0.6561     0.7492     71.1146
02100     0.9496      0.7046     0.7492     70.5019
02200     0.9124      0.7278     0.7492     70.8628
02300     0.9170      0.7173     0.7492     70.9636
02400     0.8895      0.7321     0.7492     70.1972
02500     0.9207      0.7236     0.7492     70.8796
02600     1.0702      0.6751     0.7492     71.0028
02700     0.9761      0.6920     0.7492     70.8919
02800     0.9786      0.7089     0.7492     71.1950
02900     0.9233      0.7046     0.7492     70.3250
03000     0.9491      0.7257     0.7492     71.5592
03100     1.0284      0.6899     0.7492     71.6606
03200     0.9638      0.7046     0.7518     72.1545
03300     0.8587      0.7384     0.7518     71.6695
03400     0.9040      0.7278     0.7518     71.9086
03500     1.1272      0.6456     0.7518     72.8479
03600     0.8977      0.7131     0.7518     72.4377
03700     1.0047      0.6899     0.7518     72.6814
03800     0.9502      0.7173     0.7518     72.5696
03900     0.9198      0.7068     0.7518     72.4268
04000     0.9717      0.7173     0.7518     72.9451
04100     1.0211      0.6772     0.7518     73.2395
04200     0.9605      0.7004     0.7518     72.3787
04300     0.9176      0.7152     0.7518     72.9685
04400     0.9551      0.7194     0.7518     71.4491
04500     0.9518      0.7004     0.7518     71.4464
04600     0.9129      0.7110     0.7518     72.1584
04700     1.0066      0.6878     0.7518     72.3198
04800     0.9020      0.7173     0.7518     72.3269
04900     0.9717      0.6899     0.7518     73.3459
05000     0.9433      0.7363     0.7518     72.7950
05100     0.9511      0.7110     0.7518     73.8910
05200     1.0165      0.7004     0.7518     72.8619
05300     0.9867      0.6941     0.7518     72.5917
05400     1.0479      0.6624     0.7518     73.5931
05500     0.9463      0.7173     0.7518     75.8004
05600     0.8879      0.7342     0.7518     70.4086
05700     0.9908      0.6878     0.7518     73.1266
05800     0.9818      0.6814     0.7518     72.6456
05900     1.0166      0.6878     0.7518     72.3451
06000     0.9060      0.7173     0.7518     71.5775
06100     1.0775      0.6667     0.7518     72.1037
06200     0.9444      0.7300     0.7562     72.6989
06300     1.0288      0.6899     0.7562     72.9298
06400     0.9583      0.7131     0.7562     74.9631
06500     0.9595      0.7110     0.7562     75.9626
06600     0.8903      0.7257     0.7562     74.2148
06700     1.0166      0.6793     0.7562     73.6607
06800     0.9837      0.6962     0.7562     72.6727
06900     0.8361      0.7722     0.7562     70.8450
07000     0.9062      0.7215     0.7562     72.6920
07100     0.9601      0.6983     0.7562     72.6769
07200     0.9729      0.7131     0.7562     71.6327
07300     1.0244      0.6793     0.7562     72.8158
07400     0.9401      0.7046     0.7562     72.5209
07500     0.7809      0.7743     0.7562     72.2254
07600     0.9700      0.6941     0.7562     71.4580
07700     0.9936      0.6920     0.7562     72.5315
07800     0.9235      0.7257     0.7562     71.5290
07900     0.9544      0.6983     0.7562     71.5110
08000     0.9067      0.7152     0.7562     70.7153
08100     0.9046      0.7068     0.7562     72.2470
08200     0.9391      0.7278     0.7562     71.0054
08300     0.8685      0.7489     0.7562     72.7189
08400     0.9352      0.7046     0.7562     73.5655
08500     0.9226      0.7384     0.7562     74.4904
08600     0.9737      0.6962     0.7562     74.3304
08700     0.9034      0.7489     0.7562     72.4965
08800     1.0099      0.6920     0.7562     72.7472
08900     0.9276      0.7342     0.7562     73.2084
09000     0.8893      0.7426     0.7562     72.9681
09100     0.9515      0.7068     0.7562     72.7544
09200     0.9667      0.6920     0.7562     71.1404
09300     0.9479      0.6899     0.7562     72.0800
09400     0.9805      0.6941     0.7562     72.2205
09500     0.9603      0.6962     0.7562     71.1656
09600     0.9645      0.7110     0.7562     71.3821
09700     1.0737      0.6624     0.7562     73.2327
09800     0.9521      0.7257     0.7562     72.8108
09900     0.9553      0.7004     0.7562     72.4963
Start testing:
Test Accuracy: 0.7235
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
8ac64cf7-da14-49b8-943f-5084bacae123
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.8613      0.0802     0.0631     12.4889
00100     1.9800      0.2890     0.3443     72.2666
00200     1.2976      0.5633     0.5767     73.9520
00300     1.1292      0.6160     0.6690     74.1365
00400     0.9363      0.6899     0.7136     73.1618
00500     0.8118      0.7426     0.7595     74.0184
00600     0.7746      0.7595     0.7694     74.8255
00700     0.9062      0.7342     0.7901     72.4669
00800     0.7313      0.7700     0.7901     74.4187
00900     0.6723      0.8017     0.8138     74.3841
01000     0.6166      0.7890     0.8138     75.0865
01100     0.6239      0.8122     0.8138     75.2998
01200     0.6760      0.7890     0.8357     74.3412
01300     0.5830      0.8376     0.8357     73.3493
01400     0.6961      0.7806     0.8414     73.3238
01500     0.6067      0.8249     0.8414     75.0649
01600     0.6041      0.8228     0.8425     73.7559
01700     0.4988      0.8397     0.8488     75.7082
01800     0.5550      0.8249     0.8488     75.6013
01900     0.5482      0.8080     0.8572     73.8445
02000     0.5105      0.8312     0.8572     74.3869
02100     0.5312      0.8376     0.8572     74.7564
02200     0.5190      0.8439     0.8635     73.3025
02300     0.5005      0.8460     0.8635     74.5480
02400     0.5109      0.8586     0.8635     74.4940
02500     0.4945      0.8502     0.8635     76.1915
02600     0.5384      0.8544     0.8635     74.2911
02700     0.4549      0.8460     0.8635     74.8816
02800     0.4504      0.8692     0.8635     75.7099
02900     0.5058      0.8333     0.8725     74.1762
03000     0.5124      0.8481     0.8725     77.6694
03100     0.4139      0.8713     0.8725     74.8456
03200     0.4100      0.8692     0.8725     74.7942
03300     0.5053      0.8481     0.8725     75.3710
03400     0.4762      0.8586     0.8732     75.2692
03500     0.4130      0.8861     0.8732     73.4392
03600     0.4245      0.8629     0.8732     75.0130
03700     0.4348      0.8692     0.8732     74.3151
03800     0.3963      0.8840     0.8732     75.6633
03900     0.4887      0.8502     0.8732     73.8502
04000     0.3936      0.8776     0.8732     73.8041
04100     0.4333      0.8650     0.8732     73.0246
04200     0.3798      0.8755     0.8732     73.4818
04300     0.4759      0.8481     0.8732     74.7487
04400     0.5038      0.8481     0.8732     73.7474
04500     0.3611      0.8924     0.8773     73.9445
04600     0.4996      0.8650     0.8773     74.8244
04700     0.3811      0.8903     0.8773     75.3497
04800     0.3907      0.8776     0.8825     73.7949
04900     0.4358      0.8776     0.8825     76.7865
05000     0.3896      0.8924     0.8825     74.2299
05100     0.3685      0.8924     0.8825     74.5731
05200     0.4042      0.8776     0.8825     75.3296
05300     0.3757      0.8776     0.8825     76.4041
05400     0.3532      0.8819     0.8852     74.4754
05500     0.4070      0.8840     0.8852     74.2260
05600     0.3627      0.8755     0.8852     76.1506
05700     0.3402      0.8819     0.8852     74.9733
05800     0.3775      0.8945     0.8852     74.6463
05900     0.3860      0.8903     0.8852     76.6751
06000     0.4383      0.8776     0.8887     72.4829
06100     0.3775      0.8671     0.8887     74.0396
06200     0.3500      0.8987     0.8887     74.7066
06300     0.3502      0.8987     0.8887     75.3052
06400     0.3506      0.8945     0.8887     73.2440
06500     0.3349      0.9030     0.8887     75.2855
06600     0.3511      0.8924     0.8887     73.4418
06700     0.4042      0.8819     0.8887     75.3714
06800     0.3522      0.8987     0.8887     78.2666
06900     0.4224      0.8755     0.8887     75.6352
07000     0.3808      0.8861     0.8887     73.7152
07100     0.3851      0.8734     0.8887     73.9048
07200     0.3150      0.9093     0.8887     74.2659
07300     0.3126      0.8966     0.8887     73.7838
07400     0.4164      0.8544     0.8923     73.5746
07500     0.3666      0.8734     0.8923     73.9215
07600     0.3756      0.8882     0.8923     74.7843
07700     0.3529      0.8966     0.8932     73.8525
07800     0.3123      0.8945     0.8932     74.9195
07900     0.3138      0.9135     0.8932     74.7917
08000     0.3528      0.8987     0.8932     73.5578
08100     0.3710      0.9051     0.8932     73.9870
08200     0.3815      0.8797     0.8932     74.0384
08300     0.3305      0.8945     0.8932     73.1367
08400     0.2918      0.9093     0.8932     75.8856
08500     0.2732      0.9219     0.8932     77.7849
08600     0.3362      0.8945     0.8932     74.3223
08700     0.3564      0.8924     0.8932     73.4163
08800     0.3589      0.8840     0.8932     73.6221
08900     0.3358      0.8882     0.8932     73.5019
09000     0.2795      0.9156     0.8932     74.1621
09100     0.3121      0.9135     0.8932     73.0609
09200     0.3823      0.8945     0.8932     74.1136
09300     0.3564      0.9030     0.8932     74.3154
09400     0.4016      0.8650     0.8958     73.4029
09500     0.3242      0.9030     0.8958     72.7882
09600     0.3005      0.9177     0.8958     73.7302
09700     0.4073      0.8734     0.8958     75.6619
09800     0.3838      0.8755     0.8958     74.9734
09900     0.3214      0.8966     0.8958     74.8751
10000     0.3837      0.8924     0.8958     73.3603
10100     0.2802      0.9177     0.8958     73.3186
10200     0.3345      0.8966     0.8958     73.9077
10300     0.3157      0.9051     0.8958     73.0443
10400     0.2540      0.9241     0.8958     76.2890
10500     0.3424      0.8924     0.8958     73.8134
10600     0.2577      0.9304     0.8958     74.4022
10700     0.3594      0.9051     0.8963     75.0774
10800     0.2813      0.9156     0.8964     76.1383
10900     0.3038      0.9135     0.8965     75.9681
11000     0.3465      0.9051     0.8965     77.7239
11100     0.3266      0.9008     0.8971     76.0386
11200     0.3096      0.9093     0.8971     77.1272
11300     0.2438      0.9304     0.8971     74.4502
11400     0.2809      0.8966     0.8994     73.6056
11500     0.2272      0.9451     0.8994     73.7667
11600     0.3563      0.8861     0.8994     73.6555
11700     0.3374      0.9008     0.8994     74.7095
11800     0.2933      0.9156     0.8994     76.3730
11900     0.3007      0.9219     0.8994     73.9874
12000     0.3151      0.9198     0.8994     75.2121
12100     0.2900      0.9156     0.8994     73.3337
12200     0.2762      0.9114     0.8994     75.2658
12300     0.3126      0.9135     0.8994     73.4208
12400     0.2681      0.9283     0.8994     73.1537
12500     0.2377      0.9304     0.8994     72.2378
12600     0.2804      0.9219     0.8994     75.2508
12700     0.3350      0.9135     0.9023     73.6639
12800     0.2520      0.9367     0.9023     76.2901
12900     0.3307      0.9114     0.9023     74.7825
13000     0.2787      0.9283     0.9023     74.5493
13100     0.2721      0.9262     0.9023     76.0595
13200     0.3025      0.9008     0.9023     77.0419
13300     0.3453      0.8903     0.9023     74.4826
13400     0.3336      0.9156     0.9023     75.3901
13500     0.2340      0.9367     0.9023     77.1430
13600     0.3075      0.9093     0.9023     76.4510
13700     0.2917      0.9198     0.9023     73.7443
13800     0.2895      0.9219     0.9023     74.5259
13900     0.2810      0.9156     0.9023     74.6792
14000     0.2823      0.9177     0.9023     74.7492
14100     0.2770      0.9219     0.9023     73.7581
14200     0.2840      0.9283     0.9023     75.7947
14300     0.3018      0.9114     0.9023     74.4814
14400     0.2833      0.9114     0.9023     72.8586
14500     0.2641      0.9219     0.9023     76.6089
14600     0.2694      0.9304     0.9023     73.3072
14700     0.2644      0.9177     0.9023     76.5133
14800     0.2959      0.9156     0.9023     74.2713
14900     0.2718      0.9114     0.9023     73.5920
15000     0.2714      0.9304     0.9023     74.6087
15100     0.3058      0.8966     0.9023     76.2809
15200     0.2412      0.9367     0.9023     74.9143
15300     0.2699      0.9325     0.9023     74.3772
15400     0.3063      0.9072     0.9023     73.3881
15500     0.2949      0.9093     0.9023     74.0193
15600     0.2808      0.9156     0.9023     73.5384
15700     0.2838      0.9241     0.9023     73.7371
15800     0.2747      0.9219     0.9023     73.1258
15900     0.2919      0.9156     0.9023     74.0271
16000     0.3409      0.9030     0.9023     73.2964
16100     0.3321      0.8945     0.9023     73.9973
16200     0.3092      0.9008     0.9023     73.1603
16300     0.2784      0.9262     0.9023     75.7022
16400     0.2537      0.9262     0.9023     75.3040
16500     0.2359      0.9346     0.9023     73.2071
16600     0.3316      0.8945     0.9023     73.6344
16700     0.3084      0.9093     0.9023     74.6735
16800     0.3083      0.9114     0.9023     74.1556
16900     0.2928      0.9241     0.9023     74.4676
17000     0.2984      0.9135     0.9023     73.6427
17100     0.2561      0.9262     0.9023     73.7302
17200     0.3002      0.9093     0.9023     74.8561
17300     0.2867      0.9135     0.9023     74.0420
17400     0.2612      0.9241     0.9023     73.2374
17500     0.2205      0.9409     0.9023     74.5065
17600     0.2877      0.9198     0.9023     73.3551
17700     0.2945      0.9030     0.9023     74.0373
17800     0.2457      0.9325     0.9023     75.0888
17900     0.2507      0.9304     0.9023     75.6233
18000     0.3089      0.9030     0.9023     73.2190
18100     0.3030      0.9051     0.9023     73.7167
18200     0.2189      0.9451     0.9023     72.9414
18300     0.3153      0.9072     0.9023     74.6882
18400     0.3230      0.8840     0.9023     73.9049
18500     0.3063      0.9093     0.9023     73.8742
18600     0.3248      0.9030     0.9023     73.1474
18700     0.2724      0.9283     0.9023     74.9940
18800     0.2332      0.9346     0.9023     75.3654
18900     0.3188      0.9135     0.9023     73.6199
19000     0.2736      0.9219     0.9023     74.2226
19100     0.2449      0.9325     0.9023     75.1266
19200     0.2516      0.9283     0.9023     74.5065
19300     0.3398      0.9008     0.9023     75.6838
19400     0.3323      0.8987     0.9023     74.2688
19500     0.2638      0.9304     0.9023     75.3251
19600     0.2930      0.9114     0.9023     73.9132
19700     0.2696      0.9262     0.9023     74.7403
19800     0.2839      0.9346     0.9023     76.7536
19900     0.2580      0.9262     0.9023     73.5805
20000     0.2272      0.9367     0.9023     75.2996
20100     0.2323      0.9283     0.9023     75.9011
20199     0.3015      0.9114     0.9023     72.9989
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.3106      0.9262     0.8987     10.7680
00100     0.2320      0.9367     0.8987     75.9054
00200     0.2325      0.9304     0.8989     73.9008
00300     0.2245      0.9367     0.9045     74.9521
00400     0.2573      0.9346     0.9045     74.4826
00500     0.2376      0.9367     0.9045     73.6542
00600     0.2417      0.9325     0.9045     72.5281
00700     0.2592      0.9198     0.9045     72.5497
00800     0.2303      0.9304     0.9045     72.4372
00900     0.2839      0.9135     0.9045     73.1613
01000     0.2246      0.9346     0.9045     74.4877
01100     0.2468      0.9388     0.9045     73.4977
01200     0.2504      0.9346     0.9045     71.5847
01300     0.2607      0.9219     0.9045     72.8213
01400     0.2513      0.9241     0.9045     76.9656
01500     0.2468      0.9198     0.9045     73.7033
01600     0.2108      0.9367     0.9045     74.1220
01700     0.2117      0.9494     0.9045     74.6151
01800     0.2317      0.9325     0.9045     74.4648
01900     0.1765      0.9536     0.9045     73.8700
02000     0.1913      0.9494     0.9045     75.1666
02100     0.2089      0.9346     0.9045     73.6836
02200     0.2126      0.9367     0.9045     73.6552
02300     0.2952      0.9072     0.9045     73.8548
02400     0.1544      0.9557     0.9045     73.3035
02500     0.2005      0.9515     0.9045     74.7371
02600     0.2370      0.9388     0.9045     74.2329
02700     0.2309      0.9346     0.9045     75.8510
02800     0.2431      0.9536     0.9045     73.6932
02900     0.2175      0.9430     0.9045     72.1116
03000     0.2178      0.9430     0.9045     74.9922
03100     0.2733      0.9325     0.9045     74.0653
03200     0.2463      0.9325     0.9045     73.3395
03300     0.2275      0.9388     0.9045     73.4155
03400     0.2725      0.9093     0.9045     73.3243
03500     0.2716      0.9325     0.9045     73.8714
03600     0.2515      0.9325     0.9045     74.3084
03700     0.1984      0.9409     0.9045     72.7037
03800     0.2154      0.9346     0.9045     72.7328
03900     0.2429      0.9304     0.9045     73.6983
04000     0.2724      0.9304     0.9045     75.8875
04100     0.2087      0.9325     0.9045     74.9684
04200     0.2208      0.9346     0.9045     73.8777
04300     0.2378      0.9388     0.9045     73.3725
04400     0.2038      0.9430     0.9045     74.2394
04500     0.2082      0.9409     0.9045     73.6801
04600     0.2131      0.9304     0.9045     74.1372
04700     0.2584      0.9262     0.9045     75.2064
04800     0.2134      0.9430     0.9045     72.9698
04900     0.2363      0.9304     0.9045     73.2024
05000     0.2934      0.9156     0.9045     73.2727
05100     0.2903      0.9135     0.9045     75.0136
05200     0.2120      0.9430     0.9045     72.8710
05300     0.2238      0.9430     0.9045     73.1618
05400     0.3004      0.9051     0.9045     72.5726
05500     0.2098      0.9494     0.9045     73.4564
05600     0.2071      0.9388     0.9045     72.7116
05700     0.2696      0.9325     0.9045     74.0669
05800     0.2665      0.9304     0.9045     73.6720
05900     0.1818      0.9494     0.9045     72.7522
06000     0.2350      0.9346     0.9045     72.9066
06100     0.2091      0.9304     0.9045     74.1469
06200     0.2090      0.9451     0.9045     73.5550
06300     0.2263      0.9325     0.9045     73.9697
06400     0.1909      0.9557     0.9045     74.7775
06500     0.1960      0.9473     0.9045     74.5601
06600     0.2443      0.9325     0.9045     72.9869
06700     0.2095      0.9451     0.9045     74.5745
06800     0.2452      0.9198     0.9045     73.1760
06900     0.2494      0.9304     0.9045     73.0729
07000     0.2491      0.9325     0.9045     73.1173
07100     0.2591      0.9198     0.9045     73.5138
07200     0.2342      0.9388     0.9045     73.6238
07300     0.2523      0.9325     0.9045     74.0185
07400     0.1987      0.9430     0.9045     73.8588
07500     0.2532      0.9262     0.9045     73.0325
07600     0.1973      0.9473     0.9045     74.0143
07700     0.2300      0.9325     0.9045     75.0748
07800     0.2184      0.9451     0.9045     75.0450
07900     0.2901      0.9135     0.9045     73.4164
08000     0.2162      0.9367     0.9045     74.4102
08100     0.2444      0.9325     0.9045     75.7819
08200     0.1535      0.9536     0.9045     76.4008
08300     0.1794      0.9473     0.9045     74.3720
08400     0.2057      0.9451     0.9045     73.8271
08500     0.2395      0.9283     0.9045     74.7900
08600     0.2582      0.9283     0.9045     74.0522
08700     0.1916      0.9367     0.9045     75.6246
08800     0.2494      0.9367     0.9045     75.5801
08900     0.1707      0.9620     0.9045     75.7147
09000     0.2103      0.9346     0.9045     75.6366
09100     0.2221      0.9430     0.9045     75.1333
09200     0.2072      0.9494     0.9045     74.2824
09300     0.1998      0.9473     0.9045     72.9831
09400     0.2297      0.9325     0.9045     73.2375
09500     0.1963      0.9388     0.9045     76.2803
09600     0.2494      0.9367     0.9045     78.8873
09700     0.2307      0.9283     0.9045     78.5576
09800     0.1787      0.9599     0.9045     75.9784
09900     0.2163      0.9451     0.9045     74.8853
Start testing:
Test Accuracy: 0.8859
