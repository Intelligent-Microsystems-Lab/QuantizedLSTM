Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=0.1, method=1, n_mfcc=40, n_msb=6, noise_injectionI=0.1, noise_injectionT=0.16, pact_a=True, quant_actMVM=6, quant_actNM=8, quant_inp=4, quant_w=None, random_seed=235899598, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
77355682-2c08-415b-b734-caf36ce8c7e9
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 167, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 212, in forward
    gates = quant_pass(pact_a_bmm( quant_pass(pact_a_bmm(part1, self.a12), self.abMVM, self.a12) + quant_pass(pact_a_bmm(part2, self.a13), self.abMVM, self.a13), self.a14), self.abNM, self.a14)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 89, in forward
    x01q =  torch.round(x01 * step_d ) / step_d
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 9.70 GiB already allocated; 11.12 MiB free; 9.79 GiB reserved in total by PyTorch)
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
usage: KWS_LSTM.py [-h] [--random-seed RANDOM_SEED] [--method METHOD]
                   [--dataset-path-train DATASET_PATH_TRAIN]
                   [--dataset-path-test DATASET_PATH_TEST]
                   [--word-list WORD_LIST [WORD_LIST ...]]
                   [--batch-size BATCH_SIZE] [--training-steps TRAINING_STEPS]
                   [--learning-rate LEARNING_RATE]
                   [--finetuning-epochs FINETUNING_EPOCHS]
                   [--dataloader-num-workers DATALOADER_NUM_WORKERS]
                   [--validation-percentage VALIDATION_PERCENTAGE]
                   [--testing-percentage TESTING_PERCENTAGE]
                   [--sample-rate SAMPLE_RATE]
                   [--canonical-testing CANONICAL_TESTING]
                   [--background-volume BACKGROUND_VOLUME]
                   [--background-frequency BACKGROUND_FREQUENCY]
                   [--silence-percentage SILENCE_PERCENTAGE]
                   [--unknown-percentage UNKNOWN_PERCENTAGE]
                   [--time-shift-ms TIME_SHIFT_MS] [--win-length WIN_LENGTH]
                   [--hop-length HOP_LENGTH] [--hidden HIDDEN]
                   [--n-mfcc N_MFCC] [--noise-injectionT NOISE_INJECTIONT]
                   [--noise-injectionI NOISE_INJECTIONI]
                   [--quant-actMVM QUANT_ACTMVM] [--quant-actNM QUANT_ACTNM]
                   [--quant-inp QUANT_INP] [--quant-w QUANT_W] [--l2 L2]
                   [--n-msb N_MSB] [--cs CS] [--max-w MAX_W] [--drop-p DROP_P]
                   [--pact-a PACT_A] [--rows-bias ROWS_BIAS]
                   [--gain-blocks GAIN_BLOCKS]
KWS_LSTM.py: error: argument --method: expected one argument
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=0.1, method=1, n_mfcc=40, n_msb=6, noise_injectionI=0.1, noise_injectionT=0.16, pact_a=True, quant_actMVM=6, quant_actNM=8, quant_inp=4, quant_w=None, random_seed=235899598, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
5fb45048-3652-492f-adf0-a7266319fabb
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     3.5753      0.0738     0.0861     20.9681
00100     1.6694      0.4409     0.4628     52.4654
00200     1.3645      0.5401     0.6132     53.4509
00300     1.1345      0.6329     0.6827     52.8938
00400     0.9991      0.6962     0.7197     53.2529
00500     0.8816      0.7173     0.7377     52.3121
00600     0.9290      0.7025     0.7705     53.1598
00700     0.7671      0.7384     0.7784     53.0549
00800     0.7825      0.7384     0.7936     52.5669
00900     0.7857      0.7405     0.7936     51.1306
01000     0.7200      0.7574     0.7936     51.6579
01100     0.7157      0.7553     0.8042     52.6069
01200     0.7157      0.7764     0.8085     51.6898
01300     0.6258      0.8017     0.8085     52.2404
01400     0.6923      0.7827     0.8090     53.5506
01500     0.7923      0.7363     0.8176     52.6637
01600     0.6489      0.7785     0.8176     51.4583
01700     0.7670      0.7321     0.8176     49.8676
01800     0.6852      0.7869     0.8176     50.2892
01900     0.6110      0.8017     0.8222     50.5092
02000     0.6625      0.7785     0.8228     50.0646
02100     0.6288      0.8122     0.8240     51.3675
02200     0.6448      0.8038     0.8240     52.8460
02300     0.6507      0.7743     0.8240     51.8706
02400     0.6917      0.7764     0.8240     51.9956
02500     0.5933      0.8038     0.8240     51.8688
02600     0.7345      0.7468     0.8240     51.9152
02700     0.5785      0.8122     0.8240     52.2075
02800     0.6300      0.8017     0.8337     54.3783
02900     0.6074      0.7975     0.8337     52.3453
03000     0.6108      0.7932     0.8337     54.7481
03100     0.5109      0.8312     0.8337     54.6575
03200     0.5322      0.8291     0.8337     54.1017
03300     0.5448      0.8397     0.8380     54.4835
03400     0.5959      0.7954     0.8380     54.4574
03500     0.5330      0.8354     0.8406     54.1782
03600     0.6613      0.7890     0.8406     52.6846
03700     0.5522      0.8291     0.8406     51.8642
03800     0.5655      0.8249     0.8406     51.8340
03900     0.5419      0.8354     0.8406     52.5171
04000     0.6013      0.7996     0.8406     53.2631
04100     0.5389      0.8418     0.8406     52.1484
04200     0.6098      0.8080     0.8410     52.6249
04300     0.6035      0.8101     0.8410     53.5509
04400     0.5963      0.8017     0.8510     51.6550
04500     0.5399      0.8481     0.8510     50.3471
04600     0.5479      0.8186     0.8510     50.4840
04700     0.6030      0.8059     0.8510     50.6839
04800     0.5710      0.8080     0.8510     52.0890
04900     0.5527      0.8165     0.8510     51.8434
05000     0.5183      0.8460     0.8510     51.9856
05100     0.6090      0.8038     0.8510     51.8635
05200     0.5138      0.8333     0.8510     52.0161
05300     0.4729      0.8439     0.8524     52.3152
05400     0.5703      0.8249     0.8526     55.1818
05500     0.5650      0.8207     0.8526     52.4860
05600     0.6087      0.7975     0.8526     52.7317
05700     0.5180      0.8376     0.8536     53.0962
05800     0.5234      0.8312     0.8536     51.5978
05900     0.5094      0.8249     0.8536     52.5595
06000     0.5639      0.8249     0.8536     52.1376
06100     0.4994      0.8376     0.8536     51.7184
06200     0.5354      0.8291     0.8536     53.1217
06300     0.4309      0.8523     0.8536     52.9918
06400     0.6087      0.7996     0.8548     53.7986
06500     0.6241      0.7975     0.8548     53.1656
06600     0.5736      0.8312     0.8548     52.2846
06700     0.5474      0.8143     0.8548     52.9705
06800     0.5561      0.8249     0.8548     52.0027
06900     0.5172      0.8439     0.8548     51.3556
07000     0.4524      0.8439     0.8548     52.1144
07100     0.5474      0.8312     0.8548     51.2665
07200     0.5064      0.8376     0.8581     52.9023
07300     0.4618      0.8544     0.8581     53.2810
07400     0.5173      0.8418     0.8581     54.3117
07500     0.4925      0.8586     0.8581     53.4475
07600     0.4712      0.8439     0.8581     53.6377
07700     0.5001      0.8481     0.8581     52.4725
07800     0.5280      0.8249     0.8646     52.1595
07900     0.5033      0.8312     0.8646     51.8491
08000     0.5112      0.8186     0.8646     54.0771
08100     0.5172      0.8439     0.8646     52.7335
08200     0.5346      0.8270     0.8646     53.0075
08300     0.4893      0.8376     0.8646     52.1305
08400     0.4532      0.8650     0.8646     51.2667
08500     0.5105      0.8333     0.8646     51.5035
08600     0.5653      0.8249     0.8646     52.4211
08700     0.5070      0.8418     0.8646     52.0106
08800     0.4991      0.8418     0.8646     52.7530
08900     0.4983      0.8207     0.8646     53.8058
09000     0.5364      0.8481     0.8646     53.0139
09100     0.4716      0.8460     0.8646     53.0463
09200     0.5373      0.8418     0.8654     52.6589
09300     0.4926      0.8418     0.8654     53.0866
09400     0.4826      0.8333     0.8654     52.7331
09500     0.4512      0.8523     0.8654     51.3076
09600     0.4250      0.8776     0.8654     51.5908
09700     0.4808      0.8397     0.8654     50.6998
09800     0.4750      0.8523     0.8654     51.6816
09900     0.4457      0.8608     0.8654     53.5482
10000     0.5053      0.8481     0.8654     52.7314
10100     0.4396      0.8565     0.8654     53.2213
10200     0.3966      0.8755     0.8654     53.0412
10300     0.4644      0.8586     0.8654     51.2262
10400     0.3974      0.8692     0.8654     51.1971
10500     0.4530      0.8460     0.8654     51.2820
10600     0.4627      0.8692     0.8654     51.9727
10700     0.3697      0.8840     0.8654     52.2341
10800     0.4077      0.8671     0.8654     52.0029
10900     0.4032      0.8671     0.8654     52.0233
11000     0.4474      0.8671     0.8654     51.3932
11100     0.4872      0.8460     0.8676     51.9757
11200     0.4050      0.8797     0.8676     52.9340
11300     0.4005      0.8629     0.8676     52.0553
11400     0.4757      0.8565     0.8676     51.3788
11500     0.4521      0.8586     0.8676     52.0744
11600     0.4085      0.8629     0.8676     50.8236
11700     0.4552      0.8586     0.8676     51.3796
11800     0.4934      0.8418     0.8676     51.3737
11900     0.3581      0.8882     0.8676     51.0014
12000     0.3935      0.8755     0.8676     51.5357
12100     0.4270      0.8692     0.8676     50.7131
12200     0.4043      0.8671     0.8676     50.7320
12300     0.3905      0.8713     0.8676     51.4800
12400     0.4097      0.8840     0.8676     52.4987
12500     0.3922      0.8755     0.8676     52.7236
12600     0.4557      0.8629     0.8676     52.6802
12700     0.4195      0.8713     0.8676     50.8663
12800     0.4586      0.8671     0.8676     51.7911
12900     0.4072      0.8481     0.8676     50.7177
13000     0.3624      0.8924     0.8676     51.3828
13100     0.4341      0.8629     0.8676     53.5041
13200     0.3955      0.8608     0.8676     52.6177
13300     0.4191      0.8544     0.8676     52.1666
13400     0.4903      0.8565     0.8676     54.1415
13500     0.3801      0.8819     0.8676     54.2332
13600     0.4557      0.8544     0.8676     53.5869
13700     0.4082      0.8713     0.8676     52.2589
13800     0.4515      0.8544     0.8676     51.7180
13900     0.3912      0.8586     0.8676     52.3375
14000     0.4203      0.8713     0.8676     53.4962
14100     0.3811      0.8776     0.8716     52.9924
14200     0.4013      0.8966     0.8716     54.0080
14300     0.2976      0.9093     0.8716     53.2991
14400     0.4456      0.8481     0.8716     52.6171
14500     0.4154      0.8776     0.8716     52.7335
14600     0.3518      0.8945     0.8716     52.3473
14700     0.4398      0.8376     0.8716     53.0521
14800     0.3913      0.8861     0.8716     52.6954
14900     0.4115      0.8671     0.8716     52.7869
15000     0.3479      0.8987     0.8716     51.4299
15100     0.3908      0.8713     0.8716     50.9733
15200     0.3918      0.8840     0.8716     51.2672
15300     0.4738      0.8502     0.8716     51.8699
15400     0.3973      0.8797     0.8716     52.0312
15500     0.4228      0.8797     0.8716     53.6262
15600     0.4010      0.8903     0.8716     51.8372
15700     0.4021      0.8692     0.8716     56.1213
15800     0.3515      0.8945     0.8716     54.3693
15900     0.4126      0.8650     0.8716     52.7336
16000     0.4197      0.8629     0.8716     53.3460
16100     0.3971      0.8882     0.8716     51.2922
16200     0.3681      0.8797     0.8716     49.9175
16300     0.3456      0.8840     0.8716     50.3813
16400     0.3970      0.8755     0.8716     49.7883
16500     0.3645      0.8755     0.8716     50.9687
16600     0.3539      0.8840     0.8716     54.3373
16700     0.4476      0.8586     0.8716     52.0348
16800     0.3579      0.8945     0.8716     51.7447
16900     0.3862      0.8671     0.8716     50.2055
17000     0.3547      0.8819     0.8716     50.0812
17100     0.3837      0.8861     0.8716     52.0723
17200     0.4102      0.8692     0.8716     52.5737
17300     0.4071      0.8713     0.8716     53.7415
17400     0.3660      0.8945     0.8716     52.8744
17500     0.4077      0.8776     0.8716     53.3426
17600     0.3565      0.8819     0.8716     52.4158
17700     0.3576      0.8797     0.8716     51.8211
17800     0.3828      0.8776     0.8716     51.2455
17900     0.3900      0.8586     0.8716     50.8395
18000     0.3513      0.8987     0.8716     52.2911
18100     0.3364      0.8882     0.8716     51.5472
18200     0.3716      0.8755     0.8716     51.0406
18300     0.3393      0.8924     0.8716     50.0061
18400     0.3755      0.8734     0.8716     51.8743
18500     0.3021      0.9177     0.8716     51.5910
18600     0.3779      0.8586     0.8716     52.6453
18700     0.4510      0.8565     0.8716     55.2320
18800     0.3672      0.8840     0.8716     55.0708
18900     0.3931      0.8713     0.8716     54.2579
19000     0.3633      0.8840     0.8716     53.0521
19100     0.4456      0.8523     0.8716     52.5700
19200     0.3440      0.8903     0.8716     52.3156
19300     0.3320      0.8882     0.8716     51.8655
19400     0.3640      0.8819     0.8716     54.3960
19500     0.3672      0.8819     0.8716     55.3669
19600     0.3947      0.8755     0.8716     52.4663
19700     0.4035      0.8629     0.8716     53.6862
19800     0.2939      0.8987     0.8716     53.4135
19900     0.3513      0.8903     0.8716     52.5225
20000     0.3745      0.8903     0.8716     53.6264
20100     0.3183      0.9072     0.8716     52.7136
20199     0.3026      0.9114     0.8716     50.5725
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.6008      0.8080     0.7951     8.9732
00100     0.4372      0.8650     0.8758     51.3269
00200     0.3465      0.8861     0.8776     50.5309
00300     0.3580      0.8945     0.8789     50.8973
00400     0.3634      0.8861     0.8800     50.4619
00500     0.4303      0.8565     0.8800     51.2828
00600     0.4052      0.8671     0.8800     51.8597
00700     0.3585      0.8861     0.8800     51.2683
00800     0.4054      0.8650     0.8800     50.7241
00900     0.4079      0.8797     0.8800     51.3482
01000     0.3758      0.8987     0.8839     52.2351
01100     0.3792      0.8882     0.8839     52.1507
01200     0.3984      0.8629     0.8839     51.4792
01300     0.4461      0.8439     0.8839     52.1012
01400     0.3950      0.8692     0.8839     52.1515
01500     0.4401      0.8692     0.8839     52.1086
01600     0.4074      0.8692     0.8839     51.5766
01700     0.3306      0.9008     0.8839     52.7372
01800     0.3439      0.9072     0.8839     52.9138
01900     0.3977      0.8629     0.8839     53.1826
02000     0.3271      0.8819     0.8839     54.1037
02100     0.4625      0.8460     0.8839     51.7820
02200     0.4111      0.8565     0.8839     50.9688
02300     0.3812      0.8840     0.8839     50.8351
02400     0.4102      0.8755     0.8839     50.9946
02500     0.4224      0.8502     0.8839     51.6115
02600     0.4194      0.8755     0.8839     52.1278
02700     0.3982      0.8734     0.8839     53.3188
02800     0.4111      0.8755     0.8839     55.1903
02900     0.3372      0.8797     0.8839     52.1475
03000     0.3997      0.8734     0.8839     51.8910
03100     0.4077      0.8755     0.8839     50.9853
03200     0.3773      0.8755     0.8839     51.0729
03300     0.3656      0.8797     0.8839     51.6964
03400     0.4106      0.8734     0.8839     51.0415
03500     0.3726      0.8840     0.8839     52.1782
03600     0.4366      0.8608     0.8839     52.9697
03700     0.4194      0.8586     0.8839     52.1891
03800     0.4053      0.8608     0.8839     51.9289
03900     0.4448      0.8544     0.8839     52.7887
04000     0.3522      0.8840     0.8839     50.9467
04100     0.3599      0.8797     0.8839     51.8539
04200     0.3666      0.8882     0.8839     51.8768
04300     0.3341      0.9008     0.8839     50.8169
04400     0.3041      0.8903     0.8839     49.6319
04500     0.3688      0.8819     0.8839     50.6552
04600     0.3459      0.8945     0.8839     51.9989
04700     0.3992      0.8671     0.8839     51.1076
04800     0.4275      0.8755     0.8844     50.4927
04900     0.3499      0.9030     0.8844     52.1466
05000     0.4391      0.8608     0.8844     51.9640
05100     0.3784      0.8692     0.8844     51.8586
05200     0.3673      0.8819     0.8844     51.1715
05300     0.3323      0.8924     0.8844     52.9782
05400     0.3911      0.8629     0.8844     53.1534
05500     0.4369      0.8586     0.8844     51.7528
05600     0.3952      0.8861     0.8894     54.1440
05700     0.3768      0.8692     0.8894     54.1625
05800     0.4213      0.8713     0.8894     51.8640
05900     0.4429      0.8671     0.8894     53.2835
06000     0.4035      0.8629     0.8894     51.8742
06100     0.3969      0.8608     0.8894     51.9888
06200     0.3677      0.9051     0.8894     52.9582
06300     0.3435      0.8945     0.8894     53.1936
06400     0.4669      0.8523     0.8894     51.3079
06500     0.3774      0.8734     0.8894     53.0553
06600     0.3772      0.8861     0.8894     52.3492
06700     0.3836      0.8734     0.8894     51.6449
06800     0.3720      0.8966     0.8894     52.7800
06900     0.4009      0.8713     0.8894     52.7771
07000     0.4095      0.8671     0.8894     52.5491
07100     0.3156      0.8966     0.8894     53.4863
07200     0.4134      0.8671     0.8894     53.8823
07300     0.3554      0.8776     0.8894     51.3333
07400     0.3604      0.8861     0.8894     51.8397
07500     0.4200      0.8586     0.8894     52.8661
07600     0.3558      0.8945     0.8894     51.8651
07700     0.2871      0.9093     0.8894     54.2999
07800     0.3560      0.8861     0.8894     53.7561
07900     0.4266      0.8608     0.8894     52.7473
08000     0.3928      0.8671     0.8894     51.1659
08100     0.3758      0.8734     0.8894     53.1468
08200     0.3951      0.8755     0.8894     52.3936
08300     0.3571      0.8903     0.8894     54.2731
08400     0.3954      0.8755     0.8894     53.7880
08500     0.4498      0.8502     0.8894     54.1273
08600     0.4063      0.8861     0.8894     53.7584
08700     0.3846      0.8671     0.8894     51.6885
08800     0.3477      0.8903     0.8894     52.6641
08900     0.3653      0.8882     0.8894     53.3642
09000     0.3555      0.8945     0.8894     52.4162
09100     0.3505      0.8861     0.8894     52.1491
09200     0.3680      0.8840     0.8894     50.7878
09300     0.3691      0.8713     0.8894     50.0003
09400     0.4328      0.8692     0.8894     51.2586
09500     0.4453      0.8608     0.8894     50.9274
09600     0.4543      0.8713     0.8894     51.6783
09700     0.3938      0.8755     0.8894     54.4076
09800     0.3521      0.8819     0.8894     53.3900
09900     0.3632      0.8966     0.8894     52.8402
Start testing:
Test Accuracy: 0.8788
