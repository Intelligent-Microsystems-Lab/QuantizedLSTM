Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=108, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=0.1, method=1, n_mfcc=40, n_msb=6, noise_injectionI=0.1, noise_injectionT=0.16, pact_a=True, quant_actMVM=6, quant_actNM=8, quant_inp=4, quant_w=None, random_seed=235899598, rows_bias=6, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
77355682-2c08-415b-b734-caf36ce8c7e9
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 167, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 212, in forward
    gates = quant_pass(pact_a_bmm( quant_pass(pact_a_bmm(part1, self.a12), self.abMVM, self.a12) + quant_pass(pact_a_bmm(part2, self.a13), self.abMVM, self.a13), self.a14), self.abNM, self.a14)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 89, in forward
    x01q =  torch.round(x01 * step_d ) / step_d
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 9.70 GiB already allocated; 11.12 MiB free; 9.79 GiB reserved in total by PyTorch)
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
usage: KWS_LSTM.py [-h] [--random-seed RANDOM_SEED] [--method METHOD]
                   [--dataset-path-train DATASET_PATH_TRAIN]
                   [--dataset-path-test DATASET_PATH_TEST]
                   [--word-list WORD_LIST [WORD_LIST ...]]
                   [--batch-size BATCH_SIZE] [--training-steps TRAINING_STEPS]
                   [--learning-rate LEARNING_RATE]
                   [--finetuning-epochs FINETUNING_EPOCHS]
                   [--dataloader-num-workers DATALOADER_NUM_WORKERS]
                   [--validation-percentage VALIDATION_PERCENTAGE]
                   [--testing-percentage TESTING_PERCENTAGE]
                   [--sample-rate SAMPLE_RATE]
                   [--canonical-testing CANONICAL_TESTING]
                   [--background-volume BACKGROUND_VOLUME]
                   [--background-frequency BACKGROUND_FREQUENCY]
                   [--silence-percentage SILENCE_PERCENTAGE]
                   [--unknown-percentage UNKNOWN_PERCENTAGE]
                   [--time-shift-ms TIME_SHIFT_MS] [--win-length WIN_LENGTH]
                   [--hop-length HOP_LENGTH] [--hidden HIDDEN]
                   [--n-mfcc N_MFCC] [--noise-injectionT NOISE_INJECTIONT]
                   [--noise-injectionI NOISE_INJECTIONI]
                   [--quant-actMVM QUANT_ACTMVM] [--quant-actNM QUANT_ACTNM]
                   [--quant-inp QUANT_INP] [--quant-w QUANT_W] [--l2 L2]
                   [--n-msb N_MSB] [--cs CS] [--max-w MAX_W] [--drop-p DROP_P]
                   [--pact-a PACT_A] [--rows-bias ROWS_BIAS]
                   [--gain-blocks GAIN_BLOCKS]
KWS_LSTM.py: error: argument --method: expected one argument
