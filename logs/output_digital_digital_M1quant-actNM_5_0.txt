Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
7cc69a1a-4979-4a79-9f67-ec184580fdf8
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
faa5d35d-cccc-43cf-b200-a0a71ad85808
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 373, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
32541828-d037-4449-9a66-f3057e99289e
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     4.0968      0.0781     0.0797     10.7194
00100     2.6082      0.0970     0.1017     72.5722
00200     2.5194      0.1034     0.1039     71.8557
00300     2.3182      0.1688     0.1039     73.2723
00400     2.2458      0.2215     0.1558     73.2987
00500     2.1099      0.3101     0.3243     72.4000
00600     1.9487      0.3734     0.3611     73.6670
00700     2.0029      0.3418     0.3614     72.2651
00800     2.0213      0.3608     0.3966     73.2749
00900     2.0323      0.3776     0.4051     72.9428
01000     2.0045      0.3903     0.4183     72.4916
01100     1.6861      0.4241     0.4563     72.7704
01200     1.8591      0.4262     0.4563     73.0071
01300     1.9500      0.3945     0.4771     73.8718
01400     1.6566      0.4536     0.4831     72.8465
01500     1.6407      0.4430     0.4831     73.7271
01600     1.6479      0.4726     0.4839     74.7005
01700     1.5492      0.5127     0.5057     74.3471
01800     1.6743      0.4620     0.5057     74.4355
01900     1.5752      0.4008     0.5152     74.2177
02000     1.5567      0.5000     0.5347     73.4073
02100     1.6143      0.5084     0.5347     72.7909
02200     1.7698      0.3586     0.5347     74.6014
02300     1.5833      0.4873     0.5347     76.4206
02400     1.6821      0.4346     0.5471     75.6751
02500     1.5298      0.4494     0.5471     74.9043
02600     1.6013      0.4810     0.5471     73.5918
02700     1.4422      0.5148     0.5480     74.0061
02800     1.4044      0.4684     0.5699     73.9138
02900     1.5745      0.4726     0.5699     74.1409
03000     1.4767      0.4852     0.5699     73.8189
03100     1.5503      0.4958     0.5699     74.8795
03200     1.6109      0.5084     0.5699     74.5611
03300     1.4405      0.4747     0.5699     72.5757
03400     1.5880      0.5042     0.5729     73.0880
03500     1.5724      0.4641     0.5729     72.5402
03600     1.3378      0.5169     0.5729     73.3133
03700     1.2826      0.5190     0.5729     72.8735
03800     1.5575      0.5084     0.5775     73.1953
03900     1.4753      0.5063     0.5775     72.5957
04000     1.3243      0.4852     0.5775     73.7119
04100     1.2478      0.5527     0.5775     72.3290
04200     1.5315      0.4768     0.5818     72.4898
04300     1.3837      0.4895     0.5818     73.3760
04400     1.4111      0.5105     0.5835     72.3537
04500     1.3250      0.5253     0.5835     72.7944
04600     1.3296      0.5380     0.5887     72.8980
04700     1.2657      0.5401     0.5903     72.7036
04800     1.2511      0.5443     0.5933     73.6036
04900     1.3794      0.5253     0.6028     72.8570
05000     1.3880      0.5338     0.6028     73.1194
05100     1.3947      0.5422     0.6028     73.0299
05200     1.3200      0.5443     0.6028     73.1905
05300     1.1973      0.5907     0.6160     74.2543
05400     1.3285      0.5675     0.6160     72.1080
05500     1.4173      0.4662     0.6160     72.8781
05600     1.1931      0.5802     0.6160     73.8750
05700     1.3536      0.5316     0.6160     72.9898
05800     1.4078      0.5316     0.6173     72.4759
05900     1.2254      0.6097     0.6173     73.3629
06000     1.2002      0.5823     0.6173     72.7477
06100     1.3661      0.5549     0.6173     72.8792
06200     1.3015      0.5443     0.6173     72.7741
06300     1.0852      0.6224     0.6173     73.4787
06400     1.2468      0.5464     0.6173     73.0694
06500     1.3456      0.5485     0.6267     72.3690
06600     1.2207      0.5506     0.6267     73.1327
06700     1.2435      0.5928     0.6267     72.5601
06800     1.2294      0.6308     0.6267     73.0492
06900     1.2753      0.5738     0.6275     73.5076
07000     1.3568      0.5422     0.6275     73.1698
07100     1.2367      0.5232     0.6275     73.3973
07200     1.3255      0.5464     0.6275     73.9348
07300     1.3506      0.5295     0.6275     73.0049
07400     1.2644      0.5717     0.6310     73.3286
07500     1.3770      0.5570     0.6326     74.0845
07600     1.2108      0.5865     0.6326     73.3294
07700     1.3877      0.5422     0.6326     73.6864
07800     1.3120      0.5338     0.6326     73.6603
07900     1.3482      0.5190     0.6326     73.3494
08000     1.3653      0.5654     0.6409     73.1840
08100     1.2199      0.5675     0.6409     72.5680
08200     1.3310      0.5443     0.6409     73.6384
08300     1.1996      0.5380     0.6442     72.7263
08400     1.3620      0.5527     0.6451     72.5514
08500     1.3249      0.5633     0.6524     73.2996
08600     1.2845      0.6055     0.6593     73.2142
08700     1.2970      0.5886     0.6593     72.8462
08800     1.4457      0.5591     0.6593     73.8844
08900     1.1812      0.6118     0.6593     73.3379
09000     1.2094      0.5928     0.6593     72.8888
09100     1.2605      0.5443     0.6593     72.2450
09200     1.3148      0.5781     0.6598     72.6214
09300     1.1801      0.5570     0.6598     73.1144
09400     1.2452      0.5970     0.6598     72.7703
09500     1.3330      0.5633     0.6598     73.7339
09600     1.2055      0.6203     0.6598     73.5516
09700     1.3071      0.5696     0.6598     73.3230
09800     1.0499      0.5696     0.6598     73.6086
09900     1.1804      0.6055     0.6598     73.8447
10000     1.1768      0.6435     0.6632     74.4539
10100     1.2984      0.5738     0.6669     73.2221
10200     1.1128      0.6519     0.6669     73.2676
10300     1.1780      0.6013     0.6669     73.8387
10400     1.1719      0.6055     0.6685     74.0007
10500     1.1636      0.5928     0.6717     73.3852
10600     1.2773      0.5907     0.6717     73.4335
10700     1.2293      0.5907     0.6717     74.3132
10800     1.3418      0.5970     0.6717     73.6583
10900     1.2743      0.5844     0.6717     74.0887
11000     1.2648      0.5823     0.6717     73.9149
11100     1.2302      0.6097     0.6717     72.8942
11200     1.1573      0.5738     0.6717     74.6170
11300     1.1140      0.6055     0.6717     74.0570
11400     1.1159      0.6118     0.6717     74.2820
11500     1.1887      0.5781     0.6742     74.4231
11600     1.1825      0.5844     0.6742     74.3546
11700     1.1239      0.6245     0.6742     74.8783
11800     1.2119      0.5992     0.6793     74.4568
11900     1.3241      0.5823     0.6793     73.6117
12000     1.1199      0.6245     0.6793     74.5151
12100     1.2076      0.6034     0.6793     74.0481
12200     1.2330      0.5696     0.6793     75.0678
12300     1.2086      0.5928     0.6793     74.5310
12400     1.1356      0.6160     0.6793     74.2168
12500     1.2150      0.5844     0.6793     73.7881
12600     1.1272      0.6287     0.6793     73.6571
12700     1.1792      0.5970     0.6793     74.4170
12800     1.2517      0.5886     0.6793     74.8109
12900     1.2188      0.5738     0.6793     73.5660
13000     1.3032      0.5759     0.6793     73.7630
13100     1.1144      0.6350     0.6793     73.2309
13200     1.1808      0.5844     0.6793     74.8906
13300     1.1159      0.6435     0.6793     73.5496
13400     1.0920      0.6498     0.6793     73.7663
13500     1.1825      0.5949     0.6793     73.7444
13600     0.9609      0.6350     0.6793     74.1999
13700     1.1498      0.5675     0.6793     74.1761
13800     1.2414      0.6013     0.6793     74.6746
13900     1.0942      0.6392     0.6793     73.8318
14000     1.0820      0.6350     0.6793     74.2850
14100     1.1304      0.6118     0.6793     74.9413
14200     1.3249      0.6034     0.6793     73.6984
14300     1.1503      0.6371     0.6793     73.0178
14400     1.2213      0.6097     0.6793     74.1244
14500     1.1078      0.6287     0.6793     74.6566
14600     1.1430      0.5844     0.6793     74.8251
14700     1.0890      0.6329     0.6793     74.9669
14800     1.2222      0.5907     0.6793     74.0627
14900     1.2648      0.5844     0.6897     73.9080
15000     1.1565      0.5949     0.6897     73.7718
15100     1.0870      0.5970     0.6897     74.1363
15200     1.0985      0.6160     0.6897     75.6758
15300     1.2556      0.5781     0.6897     73.8280
15400     1.2268      0.6139     0.6897     74.5846
15500     1.2390      0.5992     0.6897     74.5334
15600     1.1498      0.6287     0.6897     74.6360
15700     1.2002      0.5612     0.6897     73.8671
15800     1.1302      0.6034     0.6897     74.0433
15900     1.2756      0.5738     0.6897     74.5697
16000     1.2352      0.6266     0.6897     75.1539
16100     1.1729      0.6371     0.6897     73.9927
16200     1.1726      0.5949     0.6897     74.0455
16300     1.2485      0.6076     0.6897     75.8631
16400     1.1323      0.6245     0.6897     75.3635
16500     1.3184      0.5422     0.6897     74.3168
16600     1.1127      0.6076     0.6897     75.1410
16700     1.1277      0.6076     0.6897     73.8778
16800     1.1627      0.6646     0.6897     75.0089
16900     1.3114      0.6266     0.6897     74.3206
17000     1.2000      0.5886     0.6897     74.7022
17100     1.1128      0.5949     0.6897     74.1753
17200     1.0647      0.6034     0.6897     75.5012
17300     1.2806      0.5865     0.6897     74.5096
17400     1.1359      0.5928     0.6897     75.0224
17500     1.2658      0.5633     0.6897     73.9269
17600     1.0683      0.6561     0.6897     74.5553
17700     1.1406      0.6055     0.6897     74.5754
17800     1.1044      0.6139     0.6897     75.2454
17900     1.1099      0.6350     0.6897     75.2509
18000     1.0598      0.6097     0.6897     74.3290
18100     1.2589      0.5802     0.6897     74.3255
18200     1.1752      0.5992     0.6897     75.4851
18300     1.0781      0.6139     0.6897     74.4099
18400     1.1848      0.6139     0.6897     74.4266
18500     1.1696      0.5970     0.6897     74.4354
18600     1.0418      0.6371     0.6897     73.8259
18700     1.1435      0.6329     0.6897     74.8033
18800     1.1606      0.6076     0.6897     74.0746
18900     1.1339      0.5949     0.6897     73.6866
19000     1.1193      0.5949     0.6897     75.0234
19100     1.1892      0.5865     0.6897     74.6208
19200     1.1742      0.6203     0.6897     75.6506
19300     1.2273      0.5970     0.6897     74.1745
19400     1.1517      0.5907     0.6897     74.8761
19500     1.2318      0.6181     0.6897     75.2101
19600     1.2412      0.6076     0.6897     73.4791
19700     1.0557      0.6287     0.6897     75.1406
19800     1.2394      0.5886     0.6897     74.4656
19900     1.3006      0.5865     0.6897     73.9597
20000     1.1597      0.6013     0.6897     74.3679
20100     1.1323      0.6582     0.6897     74.5452
20199     1.0737      0.6308     0.6897     73.9527
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     1.1340      0.6477     0.6767     10.5204
00100     1.0535      0.6456     0.6839     71.6171
00200     1.1212      0.6414     0.6839     71.7173
00300     1.1397      0.6329     0.6839     72.7246
00400     1.0365      0.6498     0.6839     72.2960
00500     1.0659      0.6667     0.6845     72.2593
00600     1.1585      0.6245     0.6845     72.0614
00700     1.1675      0.6688     0.6845     73.0516
00800     1.0776      0.6772     0.6845     73.3813
00900     1.1851      0.6371     0.6845     73.5222
01000     0.9758      0.6878     0.6845     73.4665
01100     0.9837      0.6709     0.6845     73.9308
01200     1.0660      0.6519     0.6845     73.0417
01300     1.1029      0.6519     0.6845     71.9873
01400     1.0085      0.6519     0.6845     72.6064
01500     1.1736      0.6055     0.6845     73.4629
01600     1.0402      0.6540     0.6845     72.4613
01700     0.9347      0.6730     0.6845     72.0023
01800     1.1046      0.6224     0.6845     72.8170
01900     1.2039      0.6013     0.6845     73.1298
02000     1.0594      0.6561     0.6845     72.7953
02100     1.0886      0.6477     0.6845     73.0326
02200     0.9782      0.6688     0.6845     73.8538
02300     0.9846      0.6646     0.6845     73.3883
02400     1.1083      0.6498     0.6845     73.3892
02500     1.0067      0.6371     0.6845     73.6886
02600     1.1228      0.6245     0.6845     73.2489
02700     1.0517      0.6435     0.6845     74.0370
02800     1.0559      0.6435     0.6845     73.1837
02900     1.1710      0.6118     0.6845     73.9906
03000     1.1057      0.6603     0.6845     72.8314
03100     1.1233      0.6097     0.6858     73.6069
03200     1.1417      0.6224     0.6858     73.4509
03300     1.1096      0.6435     0.6902     73.1113
03400     1.1026      0.5802     0.6902     73.9902
03500     1.0380      0.6371     0.6902     74.2455
03600     0.9656      0.6667     0.6902     72.9094
03700     1.1554      0.6076     0.6902     73.4392
03800     1.0640      0.6034     0.6902     73.7182
03900     1.1100      0.6477     0.6931     73.8561
04000     1.1066      0.6519     0.6931     75.0744
04100     1.0680      0.6329     0.6931     74.6499
04200     1.1764      0.6118     0.6931     75.1281
04300     1.1152      0.6160     0.6931     75.1243
04400     1.1002      0.6287     0.6931     75.3284
04500     1.0764      0.6329     0.6931     75.5984
04600     1.1649      0.6350     0.6931     74.7090
04700     1.1598      0.6013     0.6946     74.8106
04800     1.0436      0.6498     0.6946     75.4271
04900     1.0995      0.6414     0.6946     74.9977
05000     1.1031      0.6245     0.6946     73.4618
05100     1.0205      0.6540     0.6946     75.2242
05200     1.1184      0.6435     0.6946     74.9376
05300     1.0973      0.6308     0.6946     75.8899
05400     1.0113      0.6414     0.6946     75.4163
05500     1.1302      0.6308     0.6946     76.1480
05600     1.0297      0.6308     0.6946     76.9850
05700     1.0045      0.6414     0.6946     76.0993
05800     1.0262      0.6603     0.6946     76.0742
05900     1.0869      0.6203     0.6946     74.5689
06000     0.9550      0.6709     0.6946     75.2227
06100     0.9752      0.6751     0.6946     76.5436
06200     1.0322      0.6181     0.6946     75.8920
06300     1.0075      0.6498     0.6946     74.1381
06400     1.1484      0.6498     0.6946     75.4592
06500     1.1283      0.6329     0.6946     76.2645
06600     0.9773      0.6582     0.6946     76.3117
06700     1.0838      0.6392     0.6946     75.6075
06800     1.0726      0.6245     0.6946     75.9529
06900     1.0729      0.6160     0.6946     75.2167
07000     1.0835      0.6350     0.6946     74.1178
07100     1.0951      0.6519     0.6946     75.3329
07200     1.1242      0.6498     0.6946     76.2399
07300     1.2238      0.6203     0.6946     77.0822
07400     1.1263      0.6287     0.6946     76.9324
07500     1.1589      0.6266     0.6946     77.4762
07600     1.1400      0.6076     0.6946     75.5587
07700     1.0963      0.6308     0.6946     76.6403
07800     0.9719      0.6646     0.6946     73.4369
07900     0.9964      0.6371     0.6946     75.4273
08000     1.0919      0.6350     0.6946     75.5021
08100     1.0505      0.6540     0.6946     76.7773
08200     1.0320      0.6371     0.6946     77.8417
08300     0.9768      0.6498     0.6946     76.0205
08400     1.1332      0.6181     0.6946     76.0062
08500     1.1065      0.6224     0.6946     76.5806
08600     1.1506      0.6350     0.6946     74.5324
08700     1.2377      0.5823     0.6946     76.3372
08800     1.0832      0.6181     0.6946     77.1503
08900     1.0515      0.6329     0.6946     76.9361
09000     1.2077      0.6224     0.6946     76.7732
09100     1.0100      0.6793     0.6946     75.4781
09200     1.1539      0.6414     0.6946     75.0684
09300     1.0694      0.6624     0.6946     74.9471
09400     1.0872      0.6160     0.6946     76.5988
09500     1.0038      0.6350     0.6946     78.6088
09600     1.1031      0.5970     0.6946     77.5019
09700     1.0924      0.6477     0.6946     74.7900
09800     1.1125      0.6414     0.6946     77.7830
09900     1.1454      0.6477     0.6946     76.4026
Start testing:
Test Accuracy: 0.6703
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=1, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=5, quant_actNM=5, quant_inp=5, quant_w=5, random_seed=193012823, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
dfadff10-2445-4f2b-a18b-a598546a63b0
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     4.0968      0.0781     0.0797     10.1215
00100     2.6082      0.0970     0.1017     55.1671
00200     2.5194      0.1034     0.1039     54.3980
00300     2.3182      0.1688     0.1039     55.5741
00400     2.2458      0.2215     0.1558     54.8703
00500     2.1099      0.3101     0.3243     54.7064
00600     1.9487      0.3734     0.3611     55.2657
00700     2.0029      0.3418     0.3614     55.1161
00800     2.0213      0.3608     0.3966     54.9584
00900     2.0323      0.3776     0.4051     54.5965
01000     2.0045      0.3903     0.4183     54.7044
01100     1.6861      0.4241     0.4563     55.4475
01200     1.7610      0.4451     0.4563     54.2514
01300     1.7887      0.4367     0.4840     54.4699
01400     1.6760      0.4494     0.4840     55.7018
01500     1.8708      0.3966     0.4863     55.0315
01600     1.6317      0.4262     0.4863     55.3124
01700     1.5677      0.4684     0.4950     54.7101
01800     1.7346      0.4536     0.4950     55.2312
01900     1.6374      0.4051     0.5219     55.3795
02000     1.5519      0.4620     0.5219     54.9990
02100     1.5930      0.4219     0.5219     55.5692
02200     1.6055      0.4135     0.5219     55.3729
02300     1.4736      0.5169     0.5281     55.3259
02400     1.6500      0.4346     0.5281     55.3224
02500     1.5076      0.4494     0.5281     54.5353
02600     1.6821      0.4451     0.5328     54.8605
02700     1.5189      0.4705     0.5333     55.6230
02800     1.3993      0.4726     0.5405     54.8469
02900     1.5455      0.4916     0.5405     55.2420
03000     1.4753      0.5253     0.5432     55.2530
03100     1.4941      0.5042     0.5432     55.1593
03200     1.4761      0.4684     0.5432     54.9969
03300     1.4018      0.5084     0.5631     55.4148
03400     1.4973      0.5190     0.5631     55.1429
03500     1.4639      0.4810     0.5631     55.1747
03600     1.2867      0.5000     0.5631     54.7480
03700     1.3605      0.5063     0.5639     54.3976
03800     1.6582      0.4810     0.5795     55.0222
03900     1.4586      0.4937     0.5795     53.6866
04000     1.3683      0.4958     0.5833     55.3250
04100     1.3262      0.5549     0.5835     54.7339
04200     1.4324      0.5105     0.5998     54.3203
04300     1.4833      0.5000     0.5998     55.4870
04400     1.3758      0.5105     0.5998     54.7632
04500     1.3802      0.5169     0.5998     54.4237
04600     1.3959      0.5401     0.6209     54.6601
04700     1.3444      0.5084     0.6209     54.5986
04800     1.3041      0.5443     0.6209     54.6960
04900     1.2777      0.5570     0.6256     54.3620
05000     1.4086      0.5443     0.6256     54.5910
05100     1.2983      0.5295     0.6256     55.3190
05200     1.2762      0.5865     0.6264     55.0980
05300     1.1565      0.5759     0.6353     54.3129
05400     1.1685      0.5823     0.6353     54.9109
05500     1.2503      0.5485     0.6353     54.6438
05600     1.3186      0.5443     0.6353     54.9003
05700     1.3136      0.5907     0.6353     54.4143
05800     1.3486      0.5443     0.6378     54.5479
05900     1.1930      0.5970     0.6378     55.0940
06000     1.2072      0.6203     0.6378     55.1391
06100     1.3492      0.5823     0.6378     54.0773
06200     1.2542      0.5759     0.6378     54.6670
06300     1.1619      0.6118     0.6378     54.4628
06400     1.2529      0.5907     0.6530     55.6054
06500     1.2479      0.5844     0.6530     55.3504
06600     1.2108      0.5570     0.6530     55.2861
06700     1.2113      0.6097     0.6542     55.3561
06800     1.1426      0.6287     0.6542     54.7491
06900     1.2123      0.5992     0.6542     55.0156
07000     1.2139      0.5443     0.6542     55.8237
07100     1.2294      0.5464     0.6542     54.4829
07200     1.1330      0.6055     0.6542     54.9350
07300     1.2804      0.5823     0.6542     54.8290
07400     1.2021      0.5759     0.6542     54.5859
07500     1.2829      0.6034     0.6610     55.2166
07600     1.1505      0.5970     0.6610     54.0576
07700     1.1492      0.5759     0.6610     54.8355
07800     1.1272      0.5970     0.6610     55.2661
07900     1.3426      0.5675     0.6610     55.1511
08000     1.2834      0.5823     0.6610     55.9237
08100     1.1156      0.5970     0.6739     54.1560
08200     1.3086      0.5759     0.6739     54.3312
08300     1.1500      0.6287     0.6739     55.2196
08400     1.2485      0.6034     0.6739     54.5871
08500     1.1524      0.6160     0.6739     54.1193
08600     1.2106      0.6371     0.6739     55.3362
08700     1.2496      0.5633     0.6739     54.7525
08800     1.2072      0.6055     0.6739     55.2383
08900     1.0658      0.6667     0.6739     54.6554
09000     1.1713      0.6013     0.6739     54.8792
09100     1.1362      0.5907     0.6739     54.9278
09200     1.2952      0.5696     0.6739     54.4523
09300     1.1409      0.6097     0.6739     54.6333
09400     1.2268      0.6350     0.6739     55.2277
09500     1.2275      0.5865     0.6739     54.5994
09600     1.0760      0.6055     0.6739     55.5299
09700     1.2137      0.5865     0.6739     55.2245
09800     1.0144      0.6308     0.6769     54.9558
09900     1.1722      0.6118     0.6769     54.5613
10000     1.1356      0.6603     0.6769     54.2746
10100     1.1425      0.6245     0.6819     55.5268
10200     1.1601      0.6245     0.6819     55.0223
10300     1.0887      0.6118     0.6819     54.3232
10400     1.2130      0.5781     0.6819     54.5979
