Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
2b51fea3-2668-4ced-afff-c7eeb041d65a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
73261be2-9475-4c93-bc78-c91c731e9056
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
6adc8513-8969-47d7-a136-ad58720e5759
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.9655      0.0865     0.0751     11.1784
00100     2.0463      0.3671     0.4026     74.2010
00200     1.6730      0.4684     0.5073     74.0189
00300     1.3935      0.5738     0.5763     74.5173
00400     1.1903      0.6076     0.6334     73.4800
00500     1.0743      0.6835     0.6601     74.7039
00600     1.0533      0.6878     0.7029     74.4694
00700     1.0005      0.6730     0.7288     74.8746
00800     0.9418      0.7110     0.7303     75.2538
00900     0.8819      0.7257     0.7509     73.8461
01000     0.8428      0.7468     0.7577     73.2416
01100     0.8450      0.7426     0.7667     72.0714
01200     0.8728      0.7194     0.7678     72.5493
01300     0.9019      0.7131     0.7811     71.8525
01400     0.7907      0.7553     0.7811     73.1423
01500     0.7525      0.7890     0.7811     72.4955
01600     0.7618      0.7574     0.7811     73.5313
01700     0.7473      0.7848     0.7866     72.6108
01800     0.7636      0.7700     0.7898     74.4911
01900     0.7164      0.7869     0.7898     72.2519
02000     0.7067      0.7743     0.7924     72.1615
02100     0.7442      0.7743     0.7924     72.4802
02200     0.7080      0.7954     0.7924     73.0555
02300     0.6473      0.8312     0.7949     74.1231
02400     0.6681      0.7890     0.7949     73.6775
02500     0.7402      0.7722     0.7949     74.3963
02600     0.7282      0.7869     0.8008     74.0178
02700     0.6404      0.8059     0.8014     74.3591
02800     0.6827      0.7954     0.8055     73.7313
02900     0.6742      0.8122     0.8055     72.8786
03000     0.6290      0.7954     0.8055     71.8487
03100     0.7039      0.7911     0.8059     74.7458
03200     0.6524      0.8080     0.8099     74.1779
03300     0.6843      0.7911     0.8144     72.6169
03400     0.7192      0.7806     0.8177     72.4651
03500     0.7511      0.7764     0.8177     72.4831
03600     0.5925      0.8101     0.8177     72.6306
03700     0.6456      0.7975     0.8177     71.2772
03800     0.6269      0.8122     0.8180     71.1727
03900     0.6910      0.7848     0.8225     74.3509
04000     0.7022      0.7911     0.8225     72.9997
04100     0.6574      0.7954     0.8225     74.7844
04200     0.6624      0.7954     0.8225     72.5716
04300     0.6102      0.8101     0.8225     74.9062
04400     0.6559      0.8017     0.8225     74.0165
04500     0.6521      0.8038     0.8225     72.8854
04600     0.7221      0.7848     0.8225     74.2117
04700     0.6200      0.8165     0.8225     72.4833
04800     0.6479      0.8059     0.8225     74.1626
04900     0.6294      0.8186     0.8225     74.5125
05000     0.6979      0.7975     0.8261     73.3472
05100     0.5593      0.8291     0.8288     74.1115
05200     0.7123      0.7890     0.8288     73.2190
05300     0.5505      0.8312     0.8288     73.2503
05400     0.5519      0.8354     0.8288     73.2813
05500     0.5935      0.8228     0.8288     74.2650
05600     0.6468      0.8017     0.8288     72.1895
05700     0.6656      0.8101     0.8288     72.9402
05800     0.6105      0.8122     0.8288     73.1701
05900     0.5382      0.8397     0.8288     73.8350
06000     0.6415      0.8143     0.8288     73.3125
06100     0.5845      0.8186     0.8288     73.2329
06200     0.6067      0.8312     0.8288     74.9299
06300     0.5814      0.8376     0.8288     74.2378
06400     0.6713      0.8059     0.8288     75.0140
06500     0.5617      0.8460     0.8289     74.5007
06600     0.7036      0.7806     0.8331     74.0797
06700     0.6667      0.8186     0.8331     76.1124
06800     0.6430      0.7975     0.8367     73.6401
06900     0.5367      0.8291     0.8367     73.4033
07000     0.5863      0.8312     0.8367     73.8943
07100     0.5808      0.8186     0.8367     72.9929
07200     0.6535      0.7996     0.8367     72.4994
07300     0.5666      0.8101     0.8367     73.3819
07400     0.5717      0.8249     0.8367     72.3224
07500     0.5598      0.8544     0.8367     74.5095
07600     0.5875      0.8312     0.8367     73.7957
07700     0.5928      0.8122     0.8367     74.6220
07800     0.6069      0.8186     0.8367     72.5507
07900     0.5876      0.8249     0.8367     73.4814
08000     0.5298      0.8439     0.8367     74.8703
08100     0.6136      0.8122     0.8367     73.4548
08200     0.6173      0.7954     0.8390     71.9163
08300     0.6034      0.8228     0.8390     73.9630
08400     0.6042      0.8207     0.8390     72.3358
08500     0.5395      0.8439     0.8390     73.2712
08600     0.5726      0.8333     0.8390     74.7325
08700     0.5686      0.8397     0.8390     71.5798
08800     0.5663      0.8270     0.8390     73.0608
08900     0.5230      0.8586     0.8390     73.7616
09000     0.5556      0.8249     0.8390     74.1111
09100     0.5574      0.8333     0.8390     72.4859
09200     0.6046      0.8101     0.8390     72.2462
09300     0.5884      0.7996     0.8390     73.6767
09400     0.6708      0.7996     0.8390     73.9248
09500     0.6057      0.8101     0.8390     73.5521
09600     0.6192      0.8080     0.8390     73.5908
09700     0.5969      0.8143     0.8390     74.8666
09800     0.5877      0.8101     0.8390     75.6879
09900     0.6076      0.8122     0.8390     73.5472
10000     0.6248      0.8101     0.8390     72.9640
10100     0.5382      0.8439     0.8390     73.0611
10200     0.5345      0.8376     0.8390     74.2794
10300     0.5289      0.8481     0.8390     73.5215
10400     0.5919      0.8418     0.8390     73.9191
10500     0.5091      0.8586     0.8390     74.9997
10600     0.4853      0.8460     0.8390     73.5263
10700     0.5502      0.8291     0.8390     73.4236
10800     0.5997      0.8333     0.8390     75.3787
10900     0.5207      0.8460     0.8390     73.8504
11000     0.5003      0.8523     0.8423     73.1552
11100     0.4711      0.8671     0.8423     73.0629
11200     0.4956      0.8354     0.8423     73.9447
11300     0.5221      0.8333     0.8466     72.2445
11400     0.5381      0.8354     0.8466     74.4184
11500     0.6048      0.8207     0.8466     73.8615
11600     0.6164      0.8143     0.8466     74.6379
11700     0.5868      0.8101     0.8466     73.4195
11800     0.6216      0.8207     0.8466     72.9779
11900     0.5735      0.8038     0.8466     72.9248
12000     0.4876      0.8523     0.8466     73.3893
12100     0.5799      0.8186     0.8466     73.3701
12200     0.5438      0.8418     0.8466     73.0276
12300     0.5161      0.8460     0.8466     73.2176
12400     0.5550      0.8249     0.8475     73.6097
12500     0.5330      0.8291     0.8475     73.2021
12600     0.6128      0.8143     0.8475     73.7949
12700     0.4918      0.8523     0.8475     74.3379
12800     0.5401      0.8439     0.8475     74.5365
12900     0.4862      0.8397     0.8475     75.5603
13000     0.5231      0.8608     0.8475     74.1238
13100     0.4815      0.8629     0.8475     73.3396
13200     0.5193      0.8481     0.8475     74.0847
13300     0.5348      0.8291     0.8475     72.9762
13400     0.5323      0.8523     0.8475     75.5803
13500     0.5222      0.8418     0.8475     72.6283
13600     0.4754      0.8671     0.8475     74.2576
13700     0.5271      0.8460     0.8475     72.1190
13800     0.5355      0.8354     0.8475     74.4339
13900     0.5224      0.8354     0.8475     74.3931
14000     0.5353      0.8481     0.8475     73.3527
14100     0.5128      0.8481     0.8475     74.2792
14200     0.4604      0.8755     0.8475     76.6457
14300     0.4743      0.8776     0.8475     74.5013
14400     0.5061      0.8586     0.8475     73.7760
14500     0.5038      0.8523     0.8475     74.1889
14600     0.5860      0.8312     0.8475     71.6251
14700     0.5274      0.8439     0.8475     73.6333
14800     0.4418      0.8629     0.8475     74.2898
14900     0.5239      0.8481     0.8475     75.7825
15000     0.5210      0.8397     0.8475     73.2398
15100     0.5335      0.8418     0.8475     73.8266
15200     0.5103      0.8586     0.8475     73.8657
15300     0.5177      0.8460     0.8475     74.3672
15400     0.5529      0.8270     0.8475     74.1542
15500     0.4767      0.8713     0.8475     73.9394
15600     0.4802      0.8629     0.8475     72.5528
15700     0.5530      0.8439     0.8475     72.6646
15800     0.5203      0.8418     0.8475     73.7502
15900     0.5648      0.8249     0.8475     74.7077
16000     0.5422      0.8333     0.8475     75.2926
16100     0.5328      0.8397     0.8475     72.7503
16200     0.5592      0.8312     0.8475     73.2652
16300     0.4874      0.8502     0.8475     72.7015
16400     0.5723      0.8565     0.8475     73.2396
16500     0.4294      0.8861     0.8475     73.0186
16600     0.4511      0.8797     0.8475     72.6300
16700     0.4668      0.8692     0.8475     73.1940
16800     0.5130      0.8586     0.8475     74.3728
16900     0.5056      0.8376     0.8475     72.1127
17000     0.5340      0.8439     0.8475     73.5833
17100     0.5268      0.8333     0.8475     71.6605
17200     0.5174      0.8586     0.8475     73.6255
17300     0.5104      0.8629     0.8475     72.7752
17400     0.5318      0.8544     0.8475     75.2623
17500     0.5049      0.8481     0.8475     75.3419
17600     0.5130      0.8608     0.8475     73.4809
17700     0.5475      0.8376     0.8475     74.2084
17800     0.5868      0.8080     0.8475     72.6493
17900     0.5077      0.8418     0.8475     74.5608
18000     0.5201      0.8523     0.8475     74.7029
18100     0.5460      0.8418     0.8475     72.6344
18200     0.5627      0.8439     0.8512     74.8873
18300     0.5357      0.8333     0.8512     74.6640
18400     0.4932      0.8397     0.8512     73.5469
18500     0.5542      0.8312     0.8512     72.8186
18600     0.6014      0.8397     0.8512     72.7636
18700     0.5166      0.8523     0.8512     74.8082
18800     0.4644      0.8523     0.8512     73.7496
18900     0.6144      0.8080     0.8512     73.1472
19000     0.5464      0.8460     0.8512     73.8969
19100     0.5183      0.8397     0.8512     74.0458
19200     0.5654      0.8165     0.8512     73.3906
19300     0.4855      0.8460     0.8512     73.4780
19400     0.5643      0.8376     0.8512     73.2799
19500     0.4726      0.8819     0.8512     74.3157
19600     0.5296      0.8481     0.8512     73.9370
19700     0.5101      0.8376     0.8512     72.7027
19800     0.5415      0.8460     0.8512     72.1041
19900     0.4893      0.8544     0.8512     73.3069
20000     0.4823      0.8565     0.8512     74.1222
20100     0.6719      0.8059     0.8512     75.1738
20199     0.5146      0.8460     0.8512     73.0130
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4299      0.8713     0.8434     10.3713
00100     0.4290      0.8734     0.8458     73.3378
00200     0.4558      0.8629     0.8465     73.3785
00300     0.4201      0.8650     0.8475     73.2215
00400     0.4495      0.8544     0.8475     73.2199
00500     0.4636      0.8565     0.8515     72.0278
00600     0.4891      0.8565     0.8515     72.9974
00700     0.4544      0.8797     0.8515     74.0934
00800     0.3992      0.8966     0.8515     73.0977
00900     0.4800      0.8586     0.8515     74.7938
01000     0.4691      0.8565     0.8515     73.1664
01100     0.4265      0.8861     0.8515     72.9898
01200     0.5044      0.8376     0.8515     73.0791
01300     0.4932      0.8671     0.8515     73.2704
01400     0.4295      0.8629     0.8515     73.0720
01500     0.3825      0.8776     0.8515     74.1121
01600     0.4503      0.8650     0.8515     74.6321
01700     0.4359      0.8840     0.8515     74.8843
01800     0.4026      0.8776     0.8515     73.4697
01900     0.4127      0.8819     0.8515     72.6176
02000     0.4059      0.8882     0.8515     72.5728
02100     0.4385      0.8650     0.8515     72.4554
02200     0.4843      0.8608     0.8515     74.5485
02300     0.4883      0.8523     0.8515     73.4264
02400     0.3629      0.9030     0.8515     73.9053
02500     0.4554      0.8692     0.8515     74.4974
02600     0.4148      0.8713     0.8515     73.8017
02700     0.4436      0.8650     0.8515     74.2905
02800     0.4387      0.8776     0.8515     73.8886
02900     0.3661      0.9030     0.8515     72.8478
03000     0.4681      0.8523     0.8515     75.0356
03100     0.4573      0.8502     0.8515     75.5319
03200     0.4149      0.8776     0.8515     73.6389
03300     0.4411      0.8734     0.8515     73.6513
03400     0.4752      0.8523     0.8515     74.5530
03500     0.4437      0.8734     0.8515     73.9712
03600     0.3876      0.8797     0.8517     74.6337
03700     0.4344      0.8755     0.8517     73.4490
03800     0.4622      0.8608     0.8517     74.6686
03900     0.4943      0.8523     0.8517     74.1005
04000     0.4342      0.8671     0.8517     73.3238
04100     0.3732      0.9051     0.8517     74.0104
04200     0.4505      0.8629     0.8517     73.1203
04300     0.4716      0.8608     0.8517     75.2800
04400     0.4555      0.8713     0.8529     73.9487
04500     0.4423      0.8650     0.8529     75.9245
04600     0.5011      0.8544     0.8529     75.3490
04700     0.4398      0.8608     0.8529     75.5796
04800     0.4070      0.8755     0.8529     75.1232
04900     0.4491      0.8629     0.8529     73.7149
05000     0.4870      0.8460     0.8529     73.8993
05100     0.5132      0.8523     0.8529     73.1505
05200     0.3673      0.8903     0.8529     73.5955
05300     0.4592      0.8650     0.8529     73.2590
05400     0.5420      0.8481     0.8529     72.4679
05500     0.4897      0.8544     0.8529     72.4058
05600     0.4407      0.8629     0.8529     74.1868
05700     0.3965      0.8840     0.8529     75.6298
05800     0.4581      0.8565     0.8529     72.7812
05900     0.4854      0.8460     0.8529     73.0600
06000     0.4519      0.8629     0.8529     73.4538
06100     0.3840      0.8945     0.8529     74.8216
06200     0.4016      0.8776     0.8529     75.1582
06300     0.4177      0.8734     0.8529     74.9502
06400     0.4500      0.8586     0.8529     74.2468
06500     0.4257      0.8650     0.8529     74.8209
06600     0.5216      0.8354     0.8529     73.8702
06700     0.4307      0.8629     0.8529     73.7133
06800     0.4066      0.8776     0.8529     72.6943
06900     0.4205      0.8840     0.8529     73.6176
07000     0.4204      0.8776     0.8529     74.0161
07100     0.4344      0.8734     0.8529     73.5747
07200     0.4584      0.8608     0.8529     73.9670
07300     0.4330      0.8861     0.8529     76.2281
07400     0.4122      0.8840     0.8529     73.7061
07500     0.5335      0.8565     0.8529     73.1856
07600     0.4403      0.8713     0.8529     75.1053
07700     0.4424      0.8755     0.8529     75.9693
07800     0.4255      0.8755     0.8529     73.4650
07900     0.3945      0.8903     0.8529     74.8629
08000     0.4187      0.8755     0.8529     73.1655
08100     0.3560      0.8882     0.8529     73.4654
08200     0.3986      0.8840     0.8529     72.8743
08300     0.4642      0.8439     0.8529     75.7623
08400     0.4275      0.8819     0.8529     73.2368
08500     0.5230      0.8544     0.8529     77.3715
08600     0.5515      0.8439     0.8529     74.9912
08700     0.4490      0.8629     0.8529     73.1485
08800     0.4644      0.8544     0.8529     72.8496
08900     0.4666      0.8713     0.8529     73.5043
09000     0.4654      0.8608     0.8529     72.7851
09100     0.4818      0.8418     0.8529     72.4544
09200     0.5105      0.8565     0.8529     74.4533
09300     0.3893      0.8924     0.8529     72.4700
09400     0.4361      0.8629     0.8529     73.7697
09500     0.4208      0.8797     0.8529     73.5239
09600     0.3918      0.8903     0.8529     72.6879
09700     0.4354      0.8819     0.8529     72.8350
09800     0.4702      0.8544     0.8529     73.2639
09900     0.3709      0.8945     0.8529     72.9825
Start testing:
Test Accuracy: 0.8498
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=11, quant_actNM=11, quant_inp=11, quant_w=11, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
db1037dd-3514-4187-b028-fa8bb854104b
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.9655      0.0865     0.0751     10.0953
00100     2.0463      0.3671     0.4026     69.6670
00200     1.6730      0.4684     0.5073     69.4143
00300     1.3935      0.5738     0.5763     70.9959
00400     1.1903      0.6076     0.6334     69.2922
00500     1.0743      0.6835     0.6601     70.5058
00600     1.0533      0.6878     0.7029     69.6305
00700     1.0005      0.6730     0.7288     69.5423
00800     0.9418      0.7110     0.7303     69.7250
00900     0.8819      0.7257     0.7509     69.3222
01000     0.8428      0.7468     0.7577     70.5240
01100     0.8450      0.7426     0.7667     70.6513
01200     0.8728      0.7194     0.7678     70.2732
01300     0.9019      0.7131     0.7811     69.5340
01400     0.7907      0.7553     0.7811     68.2941
01500     0.7525      0.7890     0.7811     69.8840
01600     0.7618      0.7574     0.7811     69.2920
01700     0.7473      0.7848     0.7866     70.8751
01800     0.7636      0.7700     0.7898     70.8624
01900     0.7164      0.7869     0.7898     68.8458
02000     0.7067      0.7743     0.7924     70.0497
02100     0.7442      0.7743     0.7924     70.2994
02200     0.7080      0.7954     0.7924     69.8604
02300     0.6473      0.8312     0.7949     69.5811
02400     0.6681      0.7890     0.7949     70.2681
02500     0.7402      0.7722     0.7949     68.9929
02600     0.7282      0.7869     0.8008     70.0652
02700     0.6404      0.8059     0.8014     71.1525
02800     0.6827      0.7954     0.8055     69.8213
02900     0.6742      0.8122     0.8055     69.5520
03000     0.6290      0.7954     0.8055     69.3161
03100     0.7039      0.7911     0.8059     69.7747
03200     0.6524      0.8080     0.8099     70.4465
03300     0.6843      0.7911     0.8144     69.7455
03400     0.7192      0.7806     0.8177     69.6995
03500     0.7511      0.7764     0.8177     68.5686
03600     0.5925      0.8101     0.8177     72.5954
03700     0.6456      0.7975     0.8177     69.5917
03800     0.6269      0.8122     0.8180     70.6378
03900     0.6910      0.7848     0.8225     71.3099
04000     0.7022      0.7911     0.8225     71.0083
04100     0.6574      0.7954     0.8225     70.5453
04200     0.6624      0.7954     0.8225     70.2699
04300     0.6102      0.8101     0.8225     69.2128
04400     0.6559      0.8017     0.8225     70.2723
04500     0.6521      0.8038     0.8225     69.3476
04600     0.7221      0.7848     0.8225     70.8148
04700     0.6200      0.8165     0.8225     70.2874
04800     0.6479      0.8059     0.8225     70.7648
04900     0.6294      0.8186     0.8225     69.5864
05000     0.6979      0.7975     0.8261     69.5102
05100     0.5593      0.8291     0.8288     70.7744
05200     0.7123      0.7890     0.8288     69.0071
05300     0.5505      0.8312     0.8288     70.6967
05400     0.5519      0.8354     0.8288     69.7352
05500     0.5935      0.8228     0.8288     70.1988
05600     0.6468      0.8017     0.8288     69.5935
05700     0.6656      0.8101     0.8288     70.2306
05800     0.6105      0.8122     0.8288     70.9453
05900     0.5382      0.8397     0.8288     71.1444
06000     0.6415      0.8143     0.8288     70.4771
06100     0.5845      0.8186     0.8288     72.0279
06200     0.6067      0.8312     0.8288     70.1516
06300     0.5814      0.8376     0.8288     71.9925
06400     0.6713      0.8059     0.8288     70.6000
06500     0.5617      0.8460     0.8289     71.0169
06600     0.7036      0.7806     0.8331     69.2928
06700     0.6667      0.8186     0.8331     71.7593
06800     0.6430      0.7975     0.8367     71.4026
06900     0.5367      0.8291     0.8367     70.0244
07000     0.5863      0.8312     0.8367     70.2512
07100     0.5808      0.8186     0.8367     70.2377
07200     0.6535      0.7996     0.8367     70.4540
07300     0.5666      0.8101     0.8367     71.1092
07400     0.5717      0.8249     0.8367     69.9826
07500     0.5598      0.8544     0.8367     70.0412
07600     0.5875      0.8312     0.8367     69.8778
07700     0.5928      0.8122     0.8367     69.6054
07800     0.6069      0.8186     0.8367     70.8265
07900     0.5876      0.8249     0.8367     70.9814
08000     0.5298      0.8439     0.8367     71.1756
08100     0.6136      0.8122     0.8367     70.4033
08200     0.6173      0.7954     0.8390     69.5382
08300     0.6034      0.8228     0.8390     69.8513
08400     0.6042      0.8207     0.8390     70.8402
08500     0.5395      0.8439     0.8390     70.8159
08600     0.5726      0.8333     0.8390     69.7812
08700     0.5686      0.8397     0.8390     69.8632
08800     0.5663      0.8270     0.8390     70.7433
08900     0.5230      0.8586     0.8390     71.1330
09000     0.5556      0.8249     0.8390     70.7080
09100     0.5574      0.8333     0.8390     70.3036
09200     0.6046      0.8101     0.8390     72.5391
09300     0.5884      0.7996     0.8390     70.0774
09400     0.6708      0.7996     0.8390     70.6401
09500     0.6057      0.8101     0.8390     70.0483
09600     0.6192      0.8080     0.8390     70.6848
