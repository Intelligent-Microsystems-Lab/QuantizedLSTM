Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
4e77d116-49ec-477d-a587-bfb8672ed21a
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, 1.)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 82, in forward
    if len(x_range) > 1:
TypeError: object of type 'float' has no len()
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
840eb154-efee-4ec4-a10e-8b6beaaf4a8c
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
Traceback (most recent call last):
  File "KWS_LSTM.py", line 147, in <module>
    output = model(x_data)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 289, in forward
    lstm_out, _ = self.lstmBlocks(inputs, self.hidden_state)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 65, in forward
    out, state = self.cell(inputs[i], state, w_mask)
  File "/afs/crc.nd.edu/user/c/cschaef6/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 209, in forward
    part1 = CustomMM_bmm.apply(quant_pass(pact_a_bmm(input.repeat(self.n_blocks, 1, 1), self.a1), self.ib, self.a1), self.weight_ih, self.bias_ih, self.noise_level, self.wb, self.bias_r)
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 145, in forward
    wq = quant_pass(weight, wb, torch.tensor([1.]))
  File "/afs/crc.nd.edu/user/c/cschaef6/QuantizedLSTM/model.py", line 94, in forward
    x_scaled = x/x_range
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Loading python/3.7.3
  Loading requirement: tcl/8.6.8 gcc/8.3.0
Namespace(background_frequency=0.8, background_volume=0.1, batch_size=474, canonical_testing=False, cs=0.1, dataloader_num_workers=8, dataset_path_test='data.nosync/speech_commands_test_set_v0.02', dataset_path_train='data.nosync/speech_commands_v0.02', drop_p=0.125, finetuning_epochs=10000, gain_blocks=2, hidden=14, hop_length=320, l2=0.01, learning_rate='0.002,0.0005,0.00008', max_w=1.0, method=0, n_mfcc=40, n_msb=4, noise_injectionI=0.0, noise_injectionT=0.0, pact_a=True, quant_actMVM=9, quant_actNM=9, quant_inp=9, quant_w=9, random_seed=8627169, rows_bias=100, sample_rate=16000, silence_percentage=0.1, testing_percentage=10, time_shift_ms=100.0, training_steps='10000,10000,200', unknown_percentage=0.1, validation_percentage=10, win_length=641, word_list=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown', 'silence'])
4dc6365e-038d-4775-b9d5-535b2a1e8556
Start training with DropConnect:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     2.9612      0.0865     0.0755     9.8687
00100     2.0676      0.3565     0.3814     56.0004
00200     1.6659      0.4515     0.5091     54.6279
00300     1.4020      0.5696     0.5791     54.6933
00400     1.1825      0.6076     0.6286     55.2848
00500     1.1389      0.6857     0.6629     54.3573
00600     1.0440      0.6582     0.7022     55.8118
00700     1.0057      0.6962     0.7182     55.8530
00800     0.9656      0.6920     0.7216     57.5711
00900     0.9501      0.7152     0.7395     54.2304
01000     0.9020      0.7173     0.7607     54.4846
01100     0.8494      0.7426     0.7660     55.4970
01200     0.8369      0.7257     0.7660     55.5238
01300     0.8458      0.7447     0.7772     54.4367
01400     0.7596      0.7658     0.7772     54.4306
01500     0.7955      0.7574     0.7802     55.7317
01600     0.7953      0.7637     0.7812     54.6973
01700     0.7846      0.7426     0.7880     54.2671
01800     0.7908      0.7700     0.7880     54.7794
01900     0.6658      0.7996     0.7909     54.7604
02000     0.7107      0.7954     0.7909     54.1023
02100     0.7829      0.7848     0.7909     55.4093
02200     0.7097      0.7806     0.7909     54.7856
02300     0.6487      0.8122     0.8010     55.3097
02400     0.7208      0.7743     0.8010     55.8054
02500     0.7135      0.8017     0.8010     54.9854
02600     0.6520      0.8080     0.8010     55.9748
02700     0.5827      0.8101     0.8010     55.2233
02800     0.6820      0.7869     0.8010     55.2837
02900     0.6971      0.7827     0.8041     54.5454
03000     0.6177      0.8038     0.8041     54.9572
03100     0.7066      0.7890     0.8041     54.2859
03200     0.6628      0.8038     0.8041     54.2714
03300     0.6889      0.7890     0.8041     55.3147
03400     0.7063      0.7848     0.8087     55.4740
03500     0.6856      0.7806     0.8100     56.0524
03600     0.6566      0.7954     0.8100     56.6000
03700     0.6920      0.7911     0.8100     55.0774
03800     0.6612      0.8080     0.8100     57.0562
03900     0.7121      0.7806     0.8116     57.0422
04000     0.6401      0.8101     0.8123     56.8657
04100     0.6192      0.8038     0.8136     55.3879
04200     0.6630      0.8038     0.8156     55.1595
04300     0.6478      0.7954     0.8156     55.4440
04400     0.6552      0.8038     0.8173     54.6655
04500     0.6404      0.8038     0.8173     54.7559
04600     0.6948      0.7848     0.8173     55.5179
04700     0.6260      0.8038     0.8173     55.7761
04800     0.6640      0.7975     0.8188     55.4096
04900     0.6496      0.7996     0.8188     55.8889
05000     0.6224      0.8354     0.8188     54.8058
05100     0.5913      0.8291     0.8188     55.0816
05200     0.7126      0.7954     0.8188     55.2404
05300     0.5948      0.8228     0.8188     54.5004
05400     0.5778      0.8270     0.8188     54.4101
05500     0.5893      0.8165     0.8202     55.7754
05600     0.6522      0.8017     0.8202     55.3472
05700     0.6548      0.8101     0.8202     54.0375
05800     0.6888      0.7954     0.8223     53.8497
05900     0.5618      0.8249     0.8223     54.6693
06000     0.6323      0.8143     0.8223     55.6032
06100     0.5873      0.8143     0.8223     54.9882
06200     0.5628      0.8354     0.8223     54.0290
06300     0.5542      0.8186     0.8240     53.7319
06400     0.6617      0.7996     0.8245     55.9147
06500     0.6579      0.8249     0.8245     54.7661
06600     0.6766      0.8080     0.8245     55.1552
06700     0.7147      0.7869     0.8245     54.5720
06800     0.6408      0.8038     0.8245     54.4027
06900     0.5507      0.8333     0.8245     54.5217
07000     0.6024      0.8291     0.8245     55.1650
07100     0.6259      0.8101     0.8245     54.6084
07200     0.6860      0.7785     0.8245     56.6714
07300     0.6000      0.8080     0.8245     54.7319
07400     0.6161      0.8059     0.8245     55.0347
07500     0.5856      0.8333     0.8290     55.3683
07600     0.5639      0.8312     0.8309     54.3643
07700     0.5773      0.8312     0.8309     54.1805
07800     0.5394      0.8523     0.8309     54.6868
07900     0.5749      0.8228     0.8309     54.2695
08000     0.5287      0.8460     0.8309     54.4180
08100     0.5858      0.8122     0.8309     55.2266
08200     0.5824      0.8270     0.8309     55.8077
08300     0.6307      0.7975     0.8309     55.7702
08400     0.5678      0.8270     0.8309     54.8123
08500     0.5961      0.8186     0.8309     53.8102
08600     0.6623      0.8038     0.8309     54.9306
08700     0.6008      0.8249     0.8309     54.6941
08800     0.5994      0.8143     0.8309     54.9344
08900     0.5549      0.8333     0.8309     54.2740
09000     0.5981      0.8165     0.8309     54.8065
09100     0.5819      0.8059     0.8309     55.1566
09200     0.5887      0.8059     0.8309     54.0183
09300     0.6332      0.8038     0.8309     54.7096
09400     0.6595      0.7890     0.8309     55.1003
09500     0.5482      0.8228     0.8309     55.0783
09600     0.5992      0.8291     0.8309     55.5480
09700     0.6005      0.8122     0.8320     55.4391
09800     0.5343      0.8586     0.8320     55.4520
09900     0.5993      0.8165     0.8320     55.2367
10000     0.6748      0.7679     0.8329     54.7802
10100     0.5326      0.8502     0.8329     54.0097
10200     0.5697      0.8228     0.8329     55.3085
10300     0.5807      0.8291     0.8329     55.0723
10400     0.5736      0.8376     0.8377     55.5060
10500     0.5040      0.8565     0.8377     53.8595
10600     0.5495      0.8333     0.8377     54.5457
10700     0.5560      0.8333     0.8377     54.9557
10800     0.5715      0.8291     0.8377     54.4769
10900     0.4621      0.8671     0.8377     55.1670
11000     0.5248      0.8460     0.8377     54.9677
11100     0.5068      0.8608     0.8377     54.8263
11200     0.4858      0.8629     0.8377     54.5860
11300     0.5243      0.8291     0.8377     53.5711
11400     0.5362      0.8713     0.8377     54.6391
11500     0.5982      0.8143     0.8377     53.8136
11600     0.6133      0.7996     0.8377     60.2831
11700     0.6159      0.8143     0.8377     58.6748
11800     0.6245      0.7932     0.8377     58.1342
11900     0.6232      0.8038     0.8377     56.9603
12000     0.5769      0.8376     0.8377     58.0606
12100     0.5915      0.8207     0.8377     56.8979
12200     0.5349      0.8397     0.8377     56.9294
12300     0.5154      0.8523     0.8377     58.1379
12400     0.5423      0.8186     0.8377     57.8080
12500     0.5721      0.8354     0.8377     58.4648
12600     0.5745      0.8249     0.8377     58.1624
12700     0.5731      0.8249     0.8377     56.8677
12800     0.5955      0.8228     0.8377     57.6004
12900     0.4767      0.8565     0.8377     57.3983
13000     0.5337      0.8228     0.8377     57.2329
13100     0.5086      0.8376     0.8377     57.7000
13200     0.5681      0.8312     0.8377     56.9785
13300     0.5372      0.8439     0.8377     57.3278
13400     0.5479      0.8376     0.8377     58.0484
13500     0.5624      0.8249     0.8377     57.7798
13600     0.4828      0.8523     0.8377     57.7449
13700     0.5114      0.8376     0.8377     57.1666
13800     0.5731      0.8333     0.8377     57.2730
13900     0.5374      0.8418     0.8377     57.8699
14000     0.4917      0.8460     0.8377     57.5208
14100     0.5983      0.8165     0.8377     57.4717
14200     0.5037      0.8502     0.8377     57.4608
14300     0.4938      0.8418     0.8377     57.0204
14400     0.5296      0.8502     0.8377     57.8478
14500     0.5432      0.8481     0.8377     57.3110
14600     0.5951      0.8101     0.8377     57.5201
14700     0.5437      0.8418     0.8377     57.7299
14800     0.5132      0.8544     0.8377     56.7202
14900     0.5357      0.8312     0.8377     57.5425
15000     0.5436      0.8333     0.8377     58.1092
15100     0.5420      0.8291     0.8394     57.2714
15200     0.5288      0.8291     0.8394     57.8279
15300     0.5277      0.8397     0.8394     56.8748
15400     0.5661      0.8143     0.8394     56.7962
15500     0.5129      0.8502     0.8394     57.6872
15600     0.4969      0.8502     0.8394     57.4257
15700     0.6477      0.8186     0.8394     58.0199
15800     0.5145      0.8629     0.8413     57.9593
15900     0.5328      0.8523     0.8413     58.1087
16000     0.5719      0.8418     0.8414     58.1345
16100     0.6102      0.8059     0.8414     58.0829
16200     0.5356      0.8312     0.8414     57.7279
16300     0.5300      0.8502     0.8414     57.2225
16400     0.5587      0.8523     0.8414     56.9899
16500     0.4440      0.8671     0.8414     57.1188
16600     0.5140      0.8439     0.8414     57.3250
16700     0.4835      0.8502     0.8414     57.0274
16800     0.4757      0.8755     0.8414     57.4382
16900     0.5054      0.8523     0.8414     57.1932
17000     0.4944      0.8544     0.8414     57.4181
17100     0.5654      0.8291     0.8414     57.8620
17200     0.5664      0.8270     0.8414     57.1521
17300     0.5226      0.8565     0.8414     57.5306
17400     0.5756      0.8270     0.8414     59.3936
17500     0.5165      0.8460     0.8414     59.2209
17600     0.5679      0.8333     0.8414     60.2572
17700     0.5250      0.8418     0.8414     60.5056
17800     0.5550      0.8143     0.8414     59.1963
17900     0.5362      0.8228     0.8414     59.8432
18000     0.5135      0.8586     0.8414     59.4875
18100     0.6037      0.8207     0.8414     58.2068
18200     0.5857      0.8228     0.8414     59.7916
18300     0.5731      0.8228     0.8414     59.3602
18400     0.4927      0.8629     0.8414     59.8285
18500     0.6071      0.8165     0.8414     59.2975
18600     0.5830      0.8186     0.8414     59.6891
18700     0.5288      0.8397     0.8414     59.0389
18800     0.5140      0.8544     0.8414     58.5745
18900     0.6118      0.7975     0.8414     58.3070
19000     0.5289      0.8586     0.8414     61.0587
19100     0.5616      0.8228     0.8414     58.5303
19200     0.5386      0.8418     0.8414     58.7288
19300     0.4887      0.8629     0.8425     60.6508
19400     0.5446      0.8460     0.8425     60.6361
19500     0.5008      0.8565     0.8437     60.2619
19600     0.5444      0.8565     0.8437     58.5259
19700     0.5627      0.8249     0.8437     59.0485
19800     0.5334      0.8207     0.8437     59.1390
19900     0.5306      0.8502     0.8437     61.4706
20000     0.5467      0.8059     0.8437     59.7371
20100     0.5242      0.8418     0.8437     58.5425
20199     0.5208      0.8439     0.8437     59.4517
Start finetuning with noise:
Epoch     Train Loss  Train Acc  Vali. Acc  Time (s)
00000     0.4157      0.8734     0.8354     10.1365
00100     0.4370      0.8692     0.8449     60.2468
00200     0.4549      0.8565     0.8468     58.5608
00300     0.4120      0.8608     0.8468     59.1789
00400     0.4942      0.8502     0.8468     59.7048
00500     0.4747      0.8544     0.8468     58.8819
00600     0.4918      0.8650     0.8468     60.6944
00700     0.4661      0.8734     0.8468     59.9025
00800     0.4362      0.8692     0.8470     59.4752
00900     0.5640      0.8333     0.8470     59.7564
01000     0.4592      0.8650     0.8470     58.2525
01100     0.4605      0.8671     0.8470     60.4680
01200     0.5097      0.8270     0.8470     60.1159
01300     0.5013      0.8312     0.8470     60.2249
01400     0.4826      0.8692     0.8474     60.3534
01500     0.4243      0.8671     0.8474     58.9059
01600     0.4759      0.8397     0.8474     58.3478
01700     0.4930      0.8439     0.8474     60.7040
01800     0.4210      0.8797     0.8474     58.5158
01900     0.4503      0.8713     0.8474     59.1269
02000     0.4214      0.8755     0.8474     58.8326
02100     0.4794      0.8671     0.8474     58.9478
02200     0.4337      0.8776     0.8474     58.5253
02300     0.4494      0.8713     0.8474     59.9874
02400     0.4033      0.8987     0.8474     58.9844
02500     0.4557      0.8734     0.8474     60.1710
02600     0.4175      0.8945     0.8489     59.8300
02700     0.4554      0.8819     0.8489     60.4432
02800     0.5139      0.8565     0.8489     59.9755
02900     0.3994      0.8797     0.8489     59.1200
03000     0.4774      0.8629     0.8489     58.8070
03100     0.4662      0.8734     0.8489     57.9655
03200     0.4809      0.8481     0.8489     60.0505
03300     0.4567      0.8692     0.8489     59.1579
03400     0.4608      0.8544     0.8489     59.6679
03500     0.4781      0.8629     0.8489     59.7503
03600     0.4044      0.8797     0.8489     58.3358
03700     0.4908      0.8523     0.8489     59.2294
03800     0.4269      0.8692     0.8489     59.4519
03900     0.5344      0.8397     0.8489     59.1707
04000     0.4737      0.8376     0.8489     59.2314
04100     0.4514      0.8692     0.8499     59.5562
04200     0.4939      0.8460     0.8499     59.7460
04300     0.4635      0.8650     0.8499     59.5866
04400     0.4792      0.8565     0.8499     59.1952
04500     0.4232      0.8692     0.8499     57.2694
04600     0.4443      0.8713     0.8499     59.5937
04700     0.4696      0.8565     0.8499     59.0664
04800     0.4449      0.8797     0.8499     59.1369
04900     0.4271      0.8776     0.8520     60.1706
05000     0.5476      0.8439     0.8520     59.0731
05100     0.4818      0.8544     0.8520     61.2324
05200     0.4288      0.8608     0.8520     60.5049
05300     0.4858      0.8671     0.8520     58.8234
05400     0.4868      0.8565     0.8520     59.9046
05500     0.5011      0.8354     0.8520     59.0019
05600     0.4292      0.8840     0.8520     59.6313
05700     0.4159      0.8650     0.8520     59.1310
05800     0.4672      0.8586     0.8520     57.7330
05900     0.4694      0.8586     0.8520     60.7431
06000     0.4768      0.8460     0.8520     58.4881
06100     0.4146      0.8797     0.8520     57.5122
06200     0.4267      0.8797     0.8520     60.2073
06300     0.4343      0.8755     0.8520     59.2552
06400     0.5081      0.8544     0.8520     57.7244
06500     0.4412      0.8882     0.8520     57.9275
06600     0.5121      0.8481     0.8520     58.0544
06700     0.3969      0.8882     0.8520     59.1022
06800     0.4146      0.8671     0.8520     59.5442
06900     0.4606      0.8544     0.8520     58.5455
07000     0.4365      0.8713     0.8520     60.0739
07100     0.4622      0.8586     0.8520     59.9439
07200     0.5099      0.8376     0.8520     59.1933
07300     0.3919      0.9030     0.8520     59.5018
07400     0.3870      0.8861     0.8520     58.9208
07500     0.5773      0.8270     0.8520     59.1776
07600     0.4455      0.8734     0.8520     57.7866
07700     0.4781      0.8734     0.8520     58.9845
07800     0.3998      0.8671     0.8520     57.7000
07900     0.4288      0.8734     0.8520     57.1092
08000     0.4830      0.8460     0.8520     56.9839
08100     0.3742      0.8819     0.8520     57.8423
08200     0.4081      0.8840     0.8520     55.9873
08300     0.4676      0.8629     0.8520     57.9839
08400     0.4386      0.8734     0.8520     57.0360
08500     0.4867      0.8460     0.8520     55.7937
08600     0.5594      0.8397     0.8520     56.4525
08700     0.4654      0.8755     0.8520     56.7687
08800     0.4922      0.8544     0.8520     55.0874
08900     0.5055      0.8586     0.8520     54.6955
09000     0.4579      0.8776     0.8520     56.2298
09100     0.5256      0.8354     0.8520     55.9157
09200     0.4852      0.8650     0.8520     55.4922
09300     0.4314      0.8776     0.8520     56.7485
09400     0.4680      0.8523     0.8520     55.4990
09500     0.4134      0.8776     0.8520     56.7928
09600     0.3875      0.8966     0.8520     56.3151
09700     0.4613      0.8608     0.8520     55.7462
09800     0.4978      0.8586     0.8520     54.7241
09900     0.3984      0.8755     0.8520     57.5927
Start testing:
Test Accuracy: 0.8270
